{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrender\n",
    "import os\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "import skimage.measure as sk\n",
    "\n",
    "import h5py\n",
    "\n",
    "import time\n",
    "import pymesh\n",
    "import trimesh\n",
    "\n",
    "#%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f98861a96b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# reproducible.\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChairDepthDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, h5_file):\n",
    "        \n",
    "        self.hf = h5py.File(h5_file, 'r')\n",
    "        self.keys = list(self.hf.keys())\n",
    "        \n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        group = self.hf[self.keys[idx]]\n",
    "        \n",
    "        model_id = str(self.keys[idx])\n",
    "        depth_img = self.to_tensor(Image.fromarray(np.array(group['depth_img'])))\n",
    "        azimuth = float(group['azimuth'][()])\n",
    "        elevation = float(group['elevation'][()])\n",
    "        distance = float(group['distance'][()])\n",
    "        target_vox = torch.tensor(group['target_vox'], dtype=torch.float)\n",
    "        \n",
    "        sample = {'model_id': model_id,\n",
    "                  'depth_img': depth_img,\n",
    "                  'azimuth': azimuth,\n",
    "                  'elevation': elevation,\n",
    "                  'distance': distance,\n",
    "                  'target_vox': target_vox, \n",
    "                 }\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '/home/ankbzpx/datasets/ShapeNet/ShapeNetRenderingh5_v1/03001627/data_test_rescale.h5'\n",
    "\n",
    "test_depth_dataset = ChairDepthDataset(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot vox or img\n",
    "from vis_utils import plotFromVoxels, plotImg, plot_image_list\n",
    "# generate with continuous model\n",
    "from render_utils import generate_mesh, get_relative_transform_matrix\n",
    "# render mesh with pyrender\n",
    "from render_utils import render\n",
    "# mesh from ground truth vox\n",
    "from render_utils import RotateAlongAxis\n",
    "# transfrom sdf\n",
    "from render_utils import get_transformed_indices, sdf2Voxel, get_meshgrid, get_transformed_meshgrid, get_relative_transformed_vox\n",
    "# get cd, emd, iou from 2 pymesh\n",
    "from render_utils import get_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-trained Model path\n",
    "discrete_encoder_path = 'discrete_encoder.pth'\n",
    "mapping_path = 'mapping.pth'\n",
    "discrete_decoder_path = 'discrete_decoder.pth'\n",
    "unet_path = 'con_unet_full.pth'\n",
    "continuous_model_path = 'continuous_model.pth'\n",
    "\n",
    "\n",
    "from models import Discrete_encoder, Mapping, Discrete_decoder, Conditional_UNET, Continuous\n",
    "\n",
    "####################\n",
    "# Discrete Encoder #\n",
    "####################\n",
    "\n",
    "discrete_encoder = Discrete_encoder().to(device)\n",
    "discrete_encoder.load_state_dict(torch.load(discrete_encoder_path))\n",
    "discrete_encoder.eval()\n",
    "\n",
    "for child in discrete_encoder.children():\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "# ###########\n",
    "# # Mapping #\n",
    "# ###########\n",
    "\n",
    "\n",
    "mapping = Mapping().to(device)\n",
    "mapping.load_state_dict(torch.load(mapping_path))\n",
    "mapping.eval()\n",
    "\n",
    "for child in mapping.children():\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "# ####################\n",
    "# # Discrete Decoder #\n",
    "# ####################\n",
    "\n",
    "discrete_decoder = Discrete_decoder().to(device)\n",
    "discrete_decoder.load_state_dict(torch.load(discrete_decoder_path))\n",
    "discrete_decoder.eval()\n",
    "########\n",
    "# UNET #\n",
    "########\n",
    "\n",
    "# pre-trained model is loaded within the model\n",
    "unet = Conditional_UNET(unet_path).to(device)\n",
    "\n",
    "unet.eval()\n",
    "\n",
    "for child in unet.children():\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "        \n",
    "##############\n",
    "# Continuous #\n",
    "##############\n",
    "\n",
    "continuous = Continuous().to(device)\n",
    "continuous.load_state_dict(torch.load(continuous_model_path))\n",
    "continuous.eval()\n",
    "\n",
    "for child in continuous.children():\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxsize = 32\n",
    "D2R = np.pi/180.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom depth consistency loss\n",
    "\n",
    "from torch.autograd import Function\n",
    "from torch.autograd.function import once_differentiable\n",
    "\n",
    "class DepthConsistencyLoss(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, out_vox, depth_index, close_index):\n",
    "        \n",
    "        # out_vox shape n x 1 x 32 x 32 x 32\n",
    "        # depth_index shape n x 32 x 32 x 32\n",
    "        # close_index shape n x 32 x 32 x 32\n",
    "        \n",
    "        ctx.save_for_backward(out_vox)\n",
    "        \n",
    "        vox = out_vox.squeeze(1)\n",
    "        ctx.depth_index = depth_index\n",
    "        ctx.close_index = close_index\n",
    "        \n",
    "        loss = torch.zeros_like(depth_index, dtype=torch.float).to(device)\n",
    "        \n",
    "        #bce form\n",
    "        loss[depth_index.bool()] = -torch.log(vox[depth_index.bool()])\n",
    "        loss[close_index.bool()] = -torch.log(1-vox[close_index.bool()])\n",
    "        \n",
    "        return torch.sum(loss) / (torch.sum(depth_index) + torch.sum(close_index))\n",
    "        \n",
    "    @staticmethod\n",
    "    @once_differentiable\n",
    "    def backward(ctx, grad_output):\n",
    "        \n",
    "        out_vox, = ctx.saved_tensors\n",
    "        \n",
    "        vox = out_vox.squeeze(1)\n",
    "        grad = torch.zeros_like(ctx.depth_index, dtype=torch.float).to(device)\n",
    "        \n",
    "        #bce form\n",
    "        grad[ctx.depth_index.bool()] = -1/vox[ctx.depth_index.bool()]\n",
    "        grad[ctx.close_index.bool()] = 1/(1-vox[ctx.close_index.bool()])\n",
    "        \n",
    "        return grad.unsqueeze(1), None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from refine_utils import get_radius, get_depth_close_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from render_utils import mesh_from_voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "mesh_grid_res = 64\n",
    "mesh_batch_size = 32\n",
    "\n",
    "def depth_refine_three_imgs(idx, lr = 1e-3, iter_count = 30):\n",
    "    \n",
    "    data_from = test_depth_dataset[24*idx]\n",
    "    depth_img_from = data_from['depth_img'].unsqueeze(0)\n",
    "    target_vox_from = data_from['target_vox']\n",
    "    distance_from = data_from['distance']\n",
    "    azimuth_from = data_from['azimuth']\n",
    "    elevation_from = data_from['elevation']\n",
    "    \n",
    "    #plotFromVoxels(target_vox_from[0])\n",
    "    \n",
    "    ########### initial depth ##########\n",
    "    \n",
    "    radius = get_radius(depth_img_from, distance_from)\n",
    "    depth_index_from, close_index_from = get_depth_close_idx(depth_img_from, distance_from, radius)\n",
    "    \n",
    "    ########### gt mesh ##########\n",
    "    \n",
    "    model_dir = path_model + test_depth_dataset[24*idx]['model_id'].split('_')[0] + '/model.obj'\n",
    "    mesh_py = pymesh.load_mesh(model_dir)\n",
    "    transformed_vertices = get_transformed_indices(mesh_py.vertices, azimuth_from, elevation_from, 1)\n",
    "    gt_radius = np.max(np.linalg.norm(transformed_vertices, axis = 1))\n",
    "    mesh_gt = pymesh.form_mesh(transformed_vertices/gt_radius, mesh_py.faces)\n",
    "    \n",
    "    #plotImg(depth_img_from[0, 0].detach().cpu().numpy())\n",
    "    \n",
    "    z = discrete_encoder(depth_img_from.to(device))\n",
    "    w = mapping(z)\n",
    "    \n",
    "    w = w.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    w.requires_grad = True\n",
    "    \n",
    "    optimizer = torch.optim.SGD([w], lr=lr, momentum=0.8)\n",
    "    \n",
    "    out_vox = torch.sigmoid(discrete_decoder(w))\n",
    "    #plotFromVoxels(out_vox[0, 0].detach().cpu().numpy() > 0.5)\n",
    "    \n",
    "    mesh_vox_before = mesh_from_voxel(out_vox[0, 0])\n",
    "    \n",
    "    mesh_before = generate_mesh(continuous, unet, out_vox, z, device, vox_res = 32, grid_res = mesh_grid_res, batch_size = mesh_batch_size, \n",
    "                                azimuth = 0, elevation = 0, isosurface = 0.0)\n",
    "    \n",
    "    ran = np.random.choice(np.arange(1, 24), 2)\n",
    "    \n",
    "    ########### first depth ##########\n",
    "    \n",
    "    idx_to_1 = 24*idx + ran[0]\n",
    "    data_to_1 = test_depth_dataset[idx_to_1]\n",
    "    depth_img_to_1 = data_to_1['depth_img'].unsqueeze(0)\n",
    "    distance_to_1 = data_to_1['distance']\n",
    "    azimuth_to_1 = data_to_1['azimuth']\n",
    "    elevation_to_1 = data_to_1['elevation']\n",
    "    depth_index_to_1, close_index_to_1 = get_depth_close_idx(depth_img_to_1, distance_to_1, radius)\n",
    "    \n",
    "    ########### second depth ##########\n",
    "    \n",
    "    idx_to_2 = 24*idx + ran[1]\n",
    "    data_to_2 = test_depth_dataset[idx_to_2]\n",
    "    depth_img_to_2 = data_to_2['depth_img'].unsqueeze(0)\n",
    "    distance_to_2 = data_to_2['distance']\n",
    "    azimuth_to_2 = data_to_2['azimuth']\n",
    "    elevation_to_2 = data_to_2['elevation']\n",
    "    depth_index_to_2, close_index_to_2 = get_depth_close_idx(depth_img_to_2, distance_to_2, radius)\n",
    "    \n",
    "    # Optimize with depth consistency loss\n",
    "    for i in range(iter_count):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        relative_transformed_vox_1 = get_relative_transformed_vox(out_vox, -azimuth_from, -elevation_from, azimuth_to_1, elevation_to_1, \n",
    "                                                            device, voxsize = 32, align_mode = 'zeros')\n",
    "        \n",
    "        relative_transformed_vox_2 = get_relative_transformed_vox(out_vox, -azimuth_from, -elevation_from, azimuth_to_2, elevation_to_2, \n",
    "                                                            device, voxsize = 32, align_mode = 'zeros')\n",
    "        \n",
    "        loss_0 = DepthConsistencyLoss.apply(out_vox, depth_index_from.unsqueeze(0).to(device), close_index_from.unsqueeze(0).to(device))\n",
    "        loss_1 = DepthConsistencyLoss.apply(relative_transformed_vox_1, depth_index_to_1.unsqueeze(0).to(device), close_index_to_1.unsqueeze(0).to(device))\n",
    "        loss_2 = DepthConsistencyLoss.apply(relative_transformed_vox_2, depth_index_to_2.unsqueeze(0).to(device), close_index_to_2.unsqueeze(0).to(device))\n",
    "        \n",
    "        loss = 2*loss_0 + loss_1 + loss_2\n",
    "        \n",
    "#         if i == 0:\n",
    "#             print(\"Initial loss: \", loss.item())\n",
    "#         else:\n",
    "#             print(loss.item())\n",
    "        \n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        out_vox = torch.sigmoid(discrete_decoder(w))\n",
    "        \n",
    "    #plotFromVoxels(out_vox[0, 0].detach().cpu().numpy() > 0.5)    \n",
    "    \n",
    "    mesh_after = generate_mesh(continuous, unet, out_vox, z, device, vox_res = 32, grid_res = mesh_grid_res, batch_size = mesh_batch_size, \n",
    "                               azimuth = 0, elevation = 0, isosurface = 0.0)\n",
    "    \n",
    "    mesh_vox_after = mesh_from_voxel(out_vox[0, 0])\n",
    "    \n",
    "    return mesh_gt, mesh_vox_before, mesh_vox_after, mesh_before, mesh_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_mesh(mesh_py, vox_size = 64):\n",
    "    \n",
    "    normalized_vertices = mesh_py.vertices - (vox_size/2)\n",
    "    normalized_vertices /= np.max(np.linalg.norm(normalized_vertices, axis = 1))\n",
    "    \n",
    "    return pymesh.form_mesh(normalized_vertices, mesh_py.faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "--- 9.288309335708618 seconds ---\n"
     ]
    }
   ],
   "source": [
    "path_model = '/home/ankbzpx/datasets/ShapeNet/ShapeNetCore.v1/03001627/'\n",
    "\n",
    "cd_gt_v_b_list = []\n",
    "emd_gt_v_b_list = []\n",
    "iou_gt_v_b_list = []\n",
    "\n",
    "cd_gt_v_a_list = []\n",
    "emd_gt_v_a_list = []\n",
    "iou_gt_v_a_list = []\n",
    "\n",
    "cd_gt_m_b_list = []\n",
    "emd_gt_m_b_list = []\n",
    "iou_gt_m_b_list = []\n",
    "\n",
    "cd_gt_m_a_list = []\n",
    "emd_gt_m_a_list = []\n",
    "iou_gt_m_a_list = []\n",
    "\n",
    "failed_idx = []\n",
    "\n",
    "# int(len(test_depth_dataset)/24)\n",
    "for idx in range(1):\n",
    "    \n",
    "    idx = 9\n",
    "    print(idx)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    mesh_gt, mesh_vox_before, mesh_vox_after, mesh_before, mesh_after = depth_refine_three_imgs(idx)\n",
    "    \n",
    "    if mesh_gt is None or mesh_vox_before is None or mesh_vox_after is None or mesh_before is None or mesh_after is None:\n",
    "        print('Failed case')\n",
    "        failed_idx.append(idx)\n",
    "        continue\n",
    "        \n",
    "    #mesh_gt = normalize_mesh(mesh_gt)\n",
    "    mesh_vox_before = normalize_mesh(mesh_vox_before, 64)\n",
    "    mesh_vox_after = normalize_mesh(mesh_vox_after, 64)\n",
    "    mesh_before = normalize_mesh(mesh_before, mesh_grid_res)\n",
    "    mesh_after = normalize_mesh(mesh_after, mesh_grid_res)\n",
    "    \n",
    "    cd_gt_v_b, emd_gt_v_b, iou_gt_v_b = get_test_results(mesh_gt, mesh_vox_before)\n",
    "    cd_gt_v_a, emd_gt_v_a, iou_gt_v_a = get_test_results(mesh_gt, mesh_vox_after)\n",
    "    cd_gt_m_b, emd_gt_m_b, iou_gt_m_b = get_test_results(mesh_gt, mesh_before)\n",
    "    cd_gt_m_a, emd_gt_m_a, iou_gt_m_a = get_test_results(mesh_gt, mesh_after)\n",
    "    \n",
    "    cd_gt_v_b_list.append(cd_gt_v_b)\n",
    "    emd_gt_v_b_list.append(emd_gt_v_b)\n",
    "    iou_gt_v_b_list.append(iou_gt_v_b)\n",
    "    \n",
    "    cd_gt_v_a_list.append(cd_gt_v_a)\n",
    "    emd_gt_v_a_list.append(emd_gt_v_a)\n",
    "    iou_gt_v_a_list.append(iou_gt_v_a)\n",
    "    \n",
    "    cd_gt_m_b_list.append(cd_gt_m_b)\n",
    "    emd_gt_m_b_list.append(emd_gt_m_b)\n",
    "    iou_gt_m_b_list.append(iou_gt_m_b)\n",
    "    \n",
    "    cd_gt_m_a_list.append(cd_gt_m_a)\n",
    "    emd_gt_m_a_list.append(emd_gt_m_a)\n",
    "    iou_gt_m_a_list.append(iou_gt_m_a)\n",
    "    \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- vox before ---\n",
      "Chamfer Distacne: m_ 0.023153866  s_ 0.0\n",
      "\n",
      "Earth Movers Distance: m_ 0.03522126032949716  s_ 0.0\n",
      "\n",
      "Intersection over Union: m_ 0.4936515221049411  s_ 0.0\n",
      "\n",
      "--- vox after ---\n",
      "Chamfer Distacne: m_ 0.031153146  s_ 0.0\n",
      "\n",
      "Earth Movers Distance: m_ 0.059598144858630395  s_ 0.0\n",
      "\n",
      "Intersection over Union: m_ 0.5201126307320998  s_ 0.0\n",
      "\n",
      "--- mesh before ---\n",
      "Chamfer Distacne: m_ 0.043591686  s_ 0.0\n",
      "\n",
      "Earth Movers Distance: m_ 0.05835052227436874  s_ 0.0\n",
      "\n",
      "Intersection over Union: m_ 0.27140740740740743  s_ 0.0\n",
      "\n",
      "--- mesh after ---\n",
      "Chamfer Distacne: m_ 0.020056762  s_ 0.0\n",
      "\n",
      "Earth Movers Distance: m_ 0.023883654749501555  s_ 0.0\n",
      "\n",
      "Intersection over Union m_ 0.6353162281418533  s_ 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('--- vox before ---')\n",
    "print('Chamfer Distacne: m_', np.mean(cd_gt_v_b_list), ' s_', np.std(cd_gt_v_b_list))\n",
    "print()\n",
    "print('Earth Movers Distance: m_', np.mean(emd_gt_v_b_list), ' s_', np.std(emd_gt_v_b_list))\n",
    "print()\n",
    "print('Intersection over Union: m_', np.mean(iou_gt_v_b_list), ' s_', np.std(iou_gt_v_b_list))\n",
    "print()\n",
    "\n",
    "print('--- vox after ---')\n",
    "print('Chamfer Distacne: m_', np.mean(cd_gt_v_a_list), ' s_', np.std(cd_gt_v_a_list))\n",
    "print()\n",
    "print('Earth Movers Distance: m_', np.mean(emd_gt_v_a_list), ' s_', np.std(emd_gt_v_a_list))\n",
    "print()\n",
    "print('Intersection over Union: m_', np.mean(iou_gt_v_a_list), ' s_', np.std(iou_gt_v_a_list))\n",
    "print()\n",
    "\n",
    "print('--- mesh before ---')\n",
    "print('Chamfer Distacne: m_', np.mean(cd_gt_m_b_list), ' s_', np.std(cd_gt_m_b_list))\n",
    "print()\n",
    "print('Earth Movers Distance: m_', np.mean(emd_gt_m_b_list), ' s_', np.std(emd_gt_m_b_list))\n",
    "print()\n",
    "print('Intersection over Union: m_', np.mean(iou_gt_m_b_list), ' s_', np.std(iou_gt_m_b_list))\n",
    "print()\n",
    "\n",
    "print('--- mesh after ---')\n",
    "print('Chamfer Distacne: m_', np.mean(cd_gt_m_a_list), ' s_', np.std(cd_gt_m_a_list))\n",
    "print()\n",
    "print('Earth Movers Distance: m_', np.mean(emd_gt_m_a_list), ' s_', np.std(emd_gt_m_a_list))\n",
    "print()\n",
    "print('Intersection over Union m_', np.mean(iou_gt_m_a_list), ' s_', np.std(iou_gt_m_a_list))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "render(mesh_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "render(mesh_vox_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "render(mesh_vox_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "render(mesh_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "render(mesh_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1311"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(test_depth_dataset)/24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
