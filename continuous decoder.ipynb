{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "uuid": "f30eb3b7-dbf6-4c48-adee-9610f3cd58d0"
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "uuid": "74cdc08c-592b-4737-bd37-cd75401707b6"
   },
   "outputs": [],
   "source": [
    "# models\n",
    "MODEL_PATH = '/home/ankbzpx/Documents/'\n",
    "\n",
    "discrete_encoder_path = MODEL_PATH + 'discrete continuous shape/discrete_encoder.pth'\n",
    "discrete_decoder_path = MODEL_PATH + 'discrete continuous shape/discrete_decoder.pth'\n",
    "unet_path = MODEL_PATH + 'discrete continuous shape/con_unet_full.pth'\n",
    "continuous_model_path = MODEL_PATH + 'discrete continuous shape/continuous_model.pth'\n",
    "\n",
    "hidden_dim_discrete = 128\n",
    "\n",
    "# data preparation\n",
    "data_file = '/home/ankbzpx/datasets/ShapeNet/ShapeNetRenderingh5_v1/03001627/sdf_train_core.h5'\n",
    "sample_size = 2048\n",
    "batch_size = 12\n",
    "split_ratio = 0.9\n",
    "depth_size = 256\n",
    "num_of_workers = 12\n",
    "# training\n",
    "num_epoch = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "uuid": "c10b2893-a503-482e-95bb-2554e96864ba"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "uuid": "6b4c7bac-058e-4eb6-b0cd-a9f21f24ad9e"
   },
   "outputs": [],
   "source": [
    "# reproducible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    " \n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "uuid": "b8cefb09-7a78-4ae7-b9ea-001858c59003"
   },
   "outputs": [],
   "source": [
    "class ChairSDFDataset(Dataset):\n",
    "     \n",
    "    def __init__(self, h5_file):\n",
    "        \n",
    "        self.file_path = h5_file\n",
    "        self.dataset = None\n",
    "        \n",
    "        with h5py.File(self.file_path, 'r') as file:\n",
    "            self.dataset_len = len(file)\n",
    "            self.keys = list(file.keys())\n",
    "            \n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "     \n",
    "    def __len__(self):\n",
    "        return self.dataset_len\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        #start_time = time.time()\n",
    "        \n",
    "        if self.dataset is None:\n",
    "            self.dataset = h5py.File(self.file_path, 'r')\n",
    "         \n",
    "        group = self.dataset[self.keys[idx]]\n",
    "        \n",
    "        depth_img = self.to_tensor(Image.fromarray(np.array(group['depth_img'])))\n",
    "        \n",
    "        #print(\"--- depth preprocessing %s seconds ---\" % (time.time() - start_time))\n",
    "        \n",
    "        sample_pt_np = np.array(group['sample_pt']).reshape(-1, 3)\n",
    "        sample_sdf_np = np.array(group['sample_sdf']).reshape(-1, 1)\n",
    "        \n",
    "        # check size correctness and fix incorrect data\n",
    "        if sample_pt_np.shape[0] != 2048:\n",
    "            sample_pt_np = np.pad(sample_pt_np, ((0, 2048 - sample_pt_np.shape[0]), (0, 0)), 'reflect')\n",
    "        if sample_sdf_np.shape[0] != 2048:\n",
    "            sample_sdf_np = np.pad(sample_sdf_np, ((0, 2048 - sample_sdf_np.shape[0]), (0, 0)), 'reflect')\n",
    "            \n",
    "        \n",
    "        sample_pt = torch.from_numpy(sample_pt_np).float()\n",
    "        sample_sdf = torch.from_numpy(sample_sdf_np).float()\n",
    "        # scale sdf\n",
    "        sample_sdf = torch.sign(sample_sdf)*torch.pow(torch.abs(sample_sdf), 0.25)\n",
    "        \n",
    "        #print(\"--- subsampling %s seconds ---\" % (time.time() - start_time))\n",
    "        \n",
    "        target_vox = torch.from_numpy(np.array(group['target_vox'])).float()\n",
    "        \n",
    "        sample = { 'depth_img': depth_img,\n",
    "                   'sample_pt':sample_pt,\n",
    "                   'sample_sdf':sample_sdf,\n",
    "                   'target_vox':target_vox,\n",
    "                  }\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "uuid": "2f44af65-5139-4d46-ac93-2f620eaceb79"
   },
   "outputs": [],
   "source": [
    "train_sdf_dataset = ChairSDFDataset(data_file)\n",
    "\n",
    "train_sdf_dataloader = DataLoader(train_sdf_dataset, batch_size=batch_size, shuffle=True, num_workers=num_of_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "latent_dim = 256\n",
    "\n",
    "from models import Discrete_encoder, Discrete_decoder, Conditional_UNET, Continuous\n",
    "\n",
    "####################\n",
    "# Discrete Encoder #\n",
    "####################\n",
    "\n",
    "discrete_encoder = Discrete_encoder(256).to(device)\n",
    "discrete_encoder.load_state_dict(torch.load(discrete_encoder_path))\n",
    "discrete_encoder.eval()\n",
    "\n",
    "for child in discrete_encoder.children():\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "        \n",
    "# ####################\n",
    "# # Discrete Decoder #\n",
    "# ####################\n",
    "        \n",
    "discrete_decoder = Discrete_decoder(256).to(device)\n",
    "discrete_decoder.load_state_dict(torch.load(discrete_decoder_path))\n",
    "discrete_decoder.eval()\n",
    "\n",
    "for child in discrete_decoder.children():\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "########\n",
    "# UNET #\n",
    "########\n",
    "\n",
    "# pre-trained model is loaded within the model\n",
    "unet = Conditional_UNET(unet_path).to(device)\n",
    "unet.eval()\n",
    "\n",
    "for child in unet.children():\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleNect1D(nn.Module):\n",
    "    def __init__(self, input_dim, expand = 5):\n",
    "        super(BottleNect1D, self).__init__()\n",
    "        \n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(input_dim, expand*input_dim),\n",
    "            nn.BatchNorm1d(expand*input_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(expand*input_dim, input_dim),\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class Continuous(nn.Module):\n",
    "    def __init__(self, pt_dim = 3, con_dim = 32, latent_dim = 256):\n",
    "        super(Continuous, self).__init__()\n",
    "        \n",
    "        self.de_pt =  nn.Sequential(\n",
    "            nn.Linear(pt_dim + con_dim, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            BottleNect1D(64),\n",
    "            nn.Linear(64, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            BottleNect1D(latent_dim),\n",
    "        )\n",
    "        \n",
    "        self.de_1 = nn.Sequential(\n",
    "            nn.Linear(2*latent_dim, 2*latent_dim),\n",
    "            nn.BatchNorm1d(2*latent_dim),\n",
    "            BottleNect1D(2*latent_dim),\n",
    "            nn.Linear(2*latent_dim, 2*latent_dim),\n",
    "            nn.BatchNorm1d(2*latent_dim),\n",
    "            BottleNect1D(2*latent_dim),\n",
    "        )\n",
    "        \n",
    "        self.de_2 = nn.Sequential(\n",
    "            nn.Linear(4*latent_dim, 2*latent_dim),\n",
    "            nn.BatchNorm1d(2*latent_dim),\n",
    "            BottleNect1D(2*latent_dim),\n",
    "            nn.Linear(2*latent_dim, 2*latent_dim),\n",
    "            nn.BatchNorm1d(2*latent_dim),\n",
    "            BottleNect1D(2*latent_dim),\n",
    "            nn.Linear(2*latent_dim, 1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, pt, con, z):\n",
    "        \n",
    "        cat = torch.cat((self.de_pt(torch.cat((pt, con), 1)), z), 1)\n",
    "        out = self.de_1(cat)\n",
    "        out = self.de_2(torch.cat((out, cat), 1))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "continuous = Continuous().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1loss = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "uuid": "66f2e463-b1d4-4d52-bd69-503dee235960"
   },
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "\n",
    "model = continuous\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state):\n",
    "    torch.save(state, 'continuous_model_checkpoint.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load('continuous_model_checkpoint.pth.tar')\n",
    "start_epoch = checkpoint['epoch']\n",
    "model.load_state_dict(checkpoint['continuous_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# advanced indexing 2x2x2 context from voxel\n",
    "def getContext(sample_pt_query, vox):\n",
    "    \n",
    "    # sample_pt bxmx3\n",
    "    # vox bxcxdimxdimxdim\n",
    "    \n",
    "    channel_size = vox.shape[1]\n",
    "    batch_size, sample_size, _ = sample_pt_query.shape\n",
    "    meshgrid_base = torch.Tensor(np.meshgrid(np.arange(0, batch_size), np.arange(0, channel_size), np.arange(0, 2), np.arange(0, 2), np.arange(0, 2))).int()\n",
    "    context = torch.empty((batch_size, sample_size, channel_size, 2, 2, 2))\n",
    "    \n",
    "    for j in range(context.shape[1]):\n",
    "        context[:, j, :, :, :, :] = vox[\n",
    "                    meshgrid_base[0].long(),\n",
    "                    meshgrid_base[1].long(),\n",
    "                    (meshgrid_base[2] + sample_pt_query[:, j, 0].reshape(1, -1, 1, 1, 1)).long(), \n",
    "                    (meshgrid_base[3] + sample_pt_query[:, j, 1].reshape(1, -1, 1, 1, 1)).long(), \n",
    "                    (meshgrid_base[4] + sample_pt_query[:, j, 2].reshape(1, -1, 1, 1, 1)).long()\n",
    "                ].transpose(0, 1)\n",
    "    \n",
    "    # b x c x m x 2 x 2 x 2\n",
    "    return context.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trilinearInterpolation(context, dx, dy, dz):\n",
    "    \n",
    "    v0 = context[:, :, :, 0, 0, 0]*(1-dx)*(1-dy)*(1-dz)\n",
    "    v1 = context[:, :, :, 1, 0, 0]*dx*(1-dy)*(1-dz)\n",
    "    v2 = context[:, :, :, 0, 1, 0]*(1-dx)*dy*(1-dz)\n",
    "    v3 = context[:, :, :, 1, 1, 0]*dx*dy*(1-dz)\n",
    "    v4 = context[:, :, :, 0, 0, 1]*(1-dx)*(1-dy)*dz\n",
    "    v5 = context[:, :, :, 1, 0, 1]*dx*(1-dy)*dz\n",
    "    v6 = context[:, :, :, 0, 1, 1]*(1-dx)*dy*dz\n",
    "    v7 = context[:, :, :, 1, 1, 1]*dx*dy*dz\n",
    "    \n",
    "    # b x c x m 1\n",
    "    return v0 + v1 + v2 + v3 + v4 + v5 + v6 + v7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "Epoch:  0\n",
      "Batch:  10 , l1 Loss:  0.6222708333622325 , Time: 14.060269832611084 s\n",
      "Batch:  20 , l1 Loss:  0.33097506910562513 , Time: 26.45430064201355 s\n",
      "Batch:  30 , l1 Loss:  0.28993759155273435 , Time: 38.93435883522034 s\n",
      "Batch:  40 , l1 Loss:  0.23616625517606735 , Time: 51.451082706451416 s\n",
      "Batch:  50 , l1 Loss:  0.22275505512952803 , Time: 64.02029180526733 s\n",
      "Batch:  60 , l1 Loss:  0.20075249671936035 , Time: 76.67286324501038 s\n",
      "Batch:  70 , l1 Loss:  0.18069818019866943 , Time: 89.28528094291687 s\n",
      "Batch:  80 , l1 Loss:  0.18161795437335967 , Time: 101.93931722640991 s\n",
      "Batch:  90 , l1 Loss:  0.17924284785985947 , Time: 114.61278223991394 s\n",
      "Batch:  100 , l1 Loss:  0.14637547731399536 , Time: 127.29287838935852 s\n",
      "Batch:  110 , l1 Loss:  0.1511179819703102 , Time: 140.0021674633026 s\n",
      "Batch:  120 , l1 Loss:  0.1369858279824257 , Time: 152.76185870170593 s\n",
      "Batch:  130 , l1 Loss:  0.14808819741010665 , Time: 165.49697756767273 s\n",
      "Batch:  140 , l1 Loss:  0.15525051057338715 , Time: 178.26380252838135 s\n",
      "Batch:  150 , l1 Loss:  0.15947917848825455 , Time: 191.00462412834167 s\n",
      "Batch:  160 , l1 Loss:  0.1595846876502037 , Time: 203.76625609397888 s\n",
      "Batch:  170 , l1 Loss:  0.1543131336569786 , Time: 216.5240569114685 s\n",
      "Batch:  180 , l1 Loss:  0.16106243133544923 , Time: 229.28950905799866 s\n",
      "Batch:  190 , l1 Loss:  0.1357437178492546 , Time: 242.0803370475769 s\n",
      "Batch:  200 , l1 Loss:  0.1324436217546463 , Time: 254.8626389503479 s\n",
      "Batch:  210 , l1 Loss:  0.12962250784039497 , Time: 267.6750464439392 s\n",
      "Batch:  220 , l1 Loss:  0.12410068809986115 , Time: 280.4500572681427 s\n",
      "Batch:  230 , l1 Loss:  0.1284841440618038 , Time: 292.97645926475525 s\n",
      "Batch:  240 , l1 Loss:  0.13052710816264151 , Time: 305.5322165489197 s\n",
      "Batch:  250 , l1 Loss:  0.1270122766494751 , Time: 318.20374822616577 s\n",
      "Batch:  260 , l1 Loss:  0.12564114406704902 , Time: 330.92052388191223 s\n",
      "Batch:  270 , l1 Loss:  0.12261968851089478 , Time: 343.64193058013916 s\n",
      "Batch:  280 , l1 Loss:  0.1199809543788433 , Time: 356.36812233924866 s\n",
      "Batch:  290 , l1 Loss:  0.11944924741983413 , Time: 369.06723523139954 s\n",
      "Batch:  300 , l1 Loss:  0.12109037935733795 , Time: 381.804892539978 s\n",
      "Batch:  310 , l1 Loss:  0.11857215464115142 , Time: 394.56340765953064 s\n",
      "Batch:  320 , l1 Loss:  0.12687416076660157 , Time: 407.30415749549866 s\n",
      "Batch:  330 , l1 Loss:  0.12314146980643273 , Time: 420.0488557815552 s\n",
      "Batch:  340 , l1 Loss:  0.12048433423042297 , Time: 432.7754077911377 s\n",
      "Batch:  350 , l1 Loss:  0.12663331851363183 , Time: 445.55189871788025 s\n",
      "Batch:  360 , l1 Loss:  0.128383556753397 , Time: 458.34673857688904 s\n",
      "Batch:  370 , l1 Loss:  0.12379184439778328 , Time: 471.116247177124 s\n",
      "Batch:  380 , l1 Loss:  0.12703742012381553 , Time: 483.90833163261414 s\n",
      "Batch:  390 , l1 Loss:  0.12652131021022797 , Time: 496.6806490421295 s\n",
      "Batch:  400 , l1 Loss:  0.12294336408376694 , Time: 509.5563471317291 s\n",
      "Batch:  410 , l1 Loss:  0.12167339473962784 , Time: 522.400416135788 s\n",
      "Batch:  420 , l1 Loss:  0.12223624736070633 , Time: 535.2354876995087 s\n",
      "Batch:  430 , l1 Loss:  0.12089817598462105 , Time: 548.0254669189453 s\n",
      "Batch:  440 , l1 Loss:  0.12734139263629912 , Time: 560.843049287796 s\n",
      "Batch:  450 , l1 Loss:  0.12469094842672349 , Time: 573.6432428359985 s\n",
      "Batch:  460 , l1 Loss:  0.12043600007891656 , Time: 586.4828729629517 s\n",
      "Batch:  470 , l1 Loss:  0.12129314094781876 , Time: 599.358286857605 s\n",
      "Batch:  480 , l1 Loss:  0.11745795533061028 , Time: 612.1972463130951 s\n",
      "Batch:  490 , l1 Loss:  0.11667503044009209 , Time: 625.024631023407 s\n",
      "Batch:  500 , l1 Loss:  0.11737885475158691 , Time: 637.9170184135437 s\n",
      "Batch:  510 , l1 Loss:  0.11138498559594154 , Time: 650.8514888286591 s\n",
      "Batch:  520 , l1 Loss:  0.11711185276508332 , Time: 663.7328042984009 s\n",
      "Batch:  530 , l1 Loss:  0.11698834821581841 , Time: 676.5667097568512 s\n",
      "Batch:  540 , l1 Loss:  0.11993067264556885 , Time: 689.4262750148773 s\n",
      "Batch:  550 , l1 Loss:  0.11906878873705865 , Time: 702.2685263156891 s\n",
      "Batch:  560 , l1 Loss:  0.11370526626706123 , Time: 715.1388785839081 s\n",
      "Batch:  570 , l1 Loss:  0.11633454114198685 , Time: 727.9598293304443 s\n",
      "Batch:  580 , l1 Loss:  0.11668526604771615 , Time: 740.8341414928436 s\n",
      "Batch:  590 , l1 Loss:  0.11314037963747978 , Time: 753.7508246898651 s\n",
      "Batch:  600 , l1 Loss:  0.11485414505004883 , Time: 766.6092345714569 s\n",
      "Batch:  610 , l1 Loss:  0.1191729798913002 , Time: 779.5019044876099 s\n",
      "Batch:  620 , l1 Loss:  0.11480918154120445 , Time: 792.3439345359802 s\n",
      "Batch:  630 , l1 Loss:  0.11409389600157738 , Time: 805.2499277591705 s\n",
      "Batch:  640 , l1 Loss:  0.1128156378865242 , Time: 818.1310172080994 s\n",
      "Batch:  650 , l1 Loss:  0.1142256423830986 , Time: 831.0052845478058 s\n",
      "Batch:  660 , l1 Loss:  0.11385564357042313 , Time: 843.8547217845917 s\n",
      "Batch:  670 , l1 Loss:  0.11052967309951782 , Time: 856.7315900325775 s\n",
      "Batch:  680 , l1 Loss:  0.11420622393488884 , Time: 869.6622226238251 s\n",
      "Batch:  690 , l1 Loss:  0.12181481942534447 , Time: 882.5453660488129 s\n",
      "Batch:  700 , l1 Loss:  0.11570352911949158 , Time: 895.3787045478821 s\n",
      "Batch:  710 , l1 Loss:  0.11559970378875732 , Time: 908.2807567119598 s\n",
      "Batch:  720 , l1 Loss:  0.1116719588637352 , Time: 921.1668825149536 s\n",
      "Batch:  730 , l1 Loss:  0.11520776599645614 , Time: 934.043265581131 s\n",
      "Batch:  740 , l1 Loss:  0.11424735262989998 , Time: 946.8818697929382 s\n",
      "Batch:  750 , l1 Loss:  0.11276064440608025 , Time: 959.7761178016663 s\n",
      "Batch:  760 , l1 Loss:  0.1169322095811367 , Time: 972.6707100868225 s\n",
      "Batch:  770 , l1 Loss:  0.11575489491224289 , Time: 985.5462141036987 s\n",
      "Batch:  780 , l1 Loss:  0.11396307200193405 , Time: 998.5051488876343 s\n",
      "Batch:  790 , l1 Loss:  0.11512259468436241 , Time: 1011.3781461715698 s\n",
      "Batch:  800 , l1 Loss:  0.11226943582296371 , Time: 1024.2527678012848 s\n",
      "Batch:  810 , l1 Loss:  0.11304607912898064 , Time: 1037.1246266365051 s\n",
      "Batch:  820 , l1 Loss:  0.11452733352780342 , Time: 1050.01993393898 s\n",
      "Batch:  830 , l1 Loss:  0.1142491154372692 , Time: 1062.9186518192291 s\n",
      "Batch:  840 , l1 Loss:  0.11760416775941848 , Time: 1075.8314385414124 s\n",
      "Batch:  850 , l1 Loss:  0.11671404242515564 , Time: 1088.7073028087616 s\n",
      "Batch:  860 , l1 Loss:  0.11741971597075462 , Time: 1101.6274964809418 s\n",
      "Batch:  870 , l1 Loss:  0.1134342148900032 , Time: 1114.6074452400208 s\n",
      "Batch:  880 , l1 Loss:  0.11174534931778908 , Time: 1127.5044729709625 s\n",
      "Batch:  890 , l1 Loss:  0.11232490241527557 , Time: 1140.669278383255 s\n",
      "Batch:  900 , l1 Loss:  0.11177055388689042 , Time: 1153.5884521007538 s\n",
      "Batch:  910 , l1 Loss:  0.10886968374252319 , Time: 1166.5445623397827 s\n",
      "Batch:  920 , l1 Loss:  0.11326287165284157 , Time: 1179.503380537033 s\n",
      "Batch:  930 , l1 Loss:  0.11062509045004845 , Time: 1192.4667377471924 s\n",
      "Batch:  940 , l1 Loss:  0.11277708560228347 , Time: 1205.4236040115356 s\n",
      "Batch:  950 , l1 Loss:  0.11184564009308814 , Time: 1218.3977627754211 s\n",
      "Batch:  960 , l1 Loss:  0.10771298855543136 , Time: 1231.4224605560303 s\n",
      "Batch:  970 , l1 Loss:  0.11073440536856652 , Time: 1244.4387922286987 s\n",
      "Batch:  980 , l1 Loss:  0.11259249150753022 , Time: 1257.4008476734161 s\n",
      "Batch:  990 , l1 Loss:  0.11696580573916435 , Time: 1270.4599940776825 s\n",
      "Batch:  1000 , l1 Loss:  0.11167867481708527 , Time: 1283.5969893932343 s\n",
      "Batch:  1010 , l1 Loss:  0.10957196205854416 , Time: 1296.812622308731 s\n",
      "Batch:  1020 , l1 Loss:  0.11551046147942542 , Time: 1309.9082374572754 s\n",
      "Batch:  1030 , l1 Loss:  0.11240599825978279 , Time: 1322.9979345798492 s\n",
      "Batch:  1040 , l1 Loss:  0.11496334373950959 , Time: 1336.0967659950256 s\n",
      "Batch:  1050 , l1 Loss:  0.11451679691672326 , Time: 1349.244769334793 s\n",
      "Batch:  1060 , l1 Loss:  0.11294878125190735 , Time: 1362.345960855484 s\n",
      "Batch:  1070 , l1 Loss:  0.12008213326334953 , Time: 1375.4118010997772 s\n",
      "Batch:  1080 , l1 Loss:  0.11694763228297234 , Time: 1388.527302980423 s\n",
      "Batch:  1090 , l1 Loss:  0.11439043805003166 , Time: 1401.5905866622925 s\n",
      "Batch:  1100 , l1 Loss:  0.1154140703380108 , Time: 1414.6856236457825 s\n",
      "Batch:  1110 , l1 Loss:  0.11383036971092224 , Time: 1427.7616760730743 s\n",
      "Batch:  1120 , l1 Loss:  0.11249354332685471 , Time: 1440.8728847503662 s\n",
      "Batch:  1130 , l1 Loss:  0.11064082309603691 , Time: 1453.9552965164185 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  1140 , l1 Loss:  0.11564047709107399 , Time: 1467.037314414978 s\n",
      "Batch:  1150 , l1 Loss:  0.11183306947350502 , Time: 1480.110852241516 s\n",
      "Batch:  1160 , l1 Loss:  0.10603501051664352 , Time: 1493.1291942596436 s\n",
      "Batch:  1170 , l1 Loss:  0.10788829177618027 , Time: 1506.0277047157288 s\n",
      "Batch:  1180 , l1 Loss:  0.10977548584342003 , Time: 1518.9243104457855 s\n",
      "Batch:  1190 , l1 Loss:  0.11410747244954109 , Time: 1531.8259069919586 s\n",
      "Batch:  1200 , l1 Loss:  0.11226021870970726 , Time: 1544.7649977207184 s\n",
      "Batch:  1210 , l1 Loss:  0.11147228777408599 , Time: 1557.6638133525848 s\n",
      "Batch:  1220 , l1 Loss:  0.11225007697939873 , Time: 1570.6371417045593 s\n",
      "Batch:  1230 , l1 Loss:  0.11264226734638214 , Time: 1583.596331357956 s\n",
      "Batch:  1240 , l1 Loss:  0.11193570867180824 , Time: 1596.6141147613525 s\n",
      "Batch:  1250 , l1 Loss:  0.11199744269251824 , Time: 1609.555477142334 s\n",
      "Batch:  1260 , l1 Loss:  0.11478796526789665 , Time: 1622.5303087234497 s\n",
      "Batch:  1270 , l1 Loss:  0.11278395131230354 , Time: 1635.4884121418 s\n",
      "Batch:  1280 , l1 Loss:  0.11452077925205231 , Time: 1648.44886302948 s\n",
      "Batch:  1290 , l1 Loss:  0.11351245567202568 , Time: 1661.4446449279785 s\n",
      "Batch:  1300 , l1 Loss:  0.111721121519804 , Time: 1674.387440443039 s\n",
      "Batch:  1310 , l1 Loss:  0.10939170867204666 , Time: 1687.3572793006897 s\n",
      "Batch:  1320 , l1 Loss:  0.1133209802210331 , Time: 1700.3017477989197 s\n",
      "Batch:  1330 , l1 Loss:  0.1122894488275051 , Time: 1713.3806009292603 s\n",
      "Batch:  1340 , l1 Loss:  0.10869044363498688 , Time: 1726.3599145412445 s\n",
      "Batch:  1350 , l1 Loss:  0.10821337029337882 , Time: 1739.3818514347076 s\n",
      "Batch:  1360 , l1 Loss:  0.11084680557250977 , Time: 1752.4772024154663 s\n",
      "Batch:  1370 , l1 Loss:  0.11011880412697791 , Time: 1765.5534837245941 s\n",
      "Batch:  1380 , l1 Loss:  0.10826595053076744 , Time: 1778.609539270401 s\n",
      "Batch:  1390 , l1 Loss:  0.11305873692035676 , Time: 1791.6269316673279 s\n",
      "Batch:  1400 , l1 Loss:  0.10796726197004318 , Time: 1804.6678609848022 s\n",
      "Batch:  1410 , l1 Loss:  0.10817244946956635 , Time: 1817.7429444789886 s\n",
      "Batch:  1420 , l1 Loss:  0.1138694442808628 , Time: 1830.9711892604828 s\n",
      "Batch:  1430 , l1 Loss:  0.10759648382663727 , Time: 1844.0959072113037 s\n",
      "Batch:  1440 , l1 Loss:  0.10868279114365578 , Time: 1857.179955482483 s\n",
      "Batch:  1450 , l1 Loss:  0.10912379175424576 , Time: 1870.2801814079285 s\n",
      "Batch:  1460 , l1 Loss:  0.11108353435993194 , Time: 1883.3731977939606 s\n",
      "Batch:  1470 , l1 Loss:  0.10554201379418374 , Time: 1896.4595408439636 s\n",
      "Batch:  1480 , l1 Loss:  0.1088909849524498 , Time: 1909.5172336101532 s\n",
      "Batch:  1490 , l1 Loss:  0.10957823917269707 , Time: 1922.5644364356995 s\n",
      "Batch:  1500 , l1 Loss:  0.10810064598917961 , Time: 1935.6462111473083 s\n",
      "Batch:  1510 , l1 Loss:  0.1085422694683075 , Time: 1948.8070380687714 s\n",
      "Batch:  1520 , l1 Loss:  0.10964168086647988 , Time: 1961.8478162288666 s\n",
      "Batch:  1530 , l1 Loss:  0.11360648646950722 , Time: 1974.9395780563354 s\n",
      "Batch:  1540 , l1 Loss:  0.1173665888607502 , Time: 1988.036518573761 s\n",
      "Batch:  1550 , l1 Loss:  0.10992767065763473 , Time: 2001.1153123378754 s\n",
      "Batch:  1560 , l1 Loss:  0.1100025787949562 , Time: 2014.172841310501 s\n",
      "Batch:  1570 , l1 Loss:  0.11041978150606155 , Time: 2027.2465007305145 s\n",
      "Batch:  1580 , l1 Loss:  0.1111471712589264 , Time: 2040.3279941082 s\n",
      "Batch:  1590 , l1 Loss:  0.11400622278451919 , Time: 2053.4220793247223 s\n",
      "Batch:  1600 , l1 Loss:  0.11382462084293365 , Time: 2066.499696493149 s\n",
      "Batch:  1610 , l1 Loss:  0.10970993787050247 , Time: 2079.639530658722 s\n",
      "Batch:  1620 , l1 Loss:  0.11139845848083496 , Time: 2092.715865135193 s\n",
      "Batch:  1630 , l1 Loss:  0.10922569036483765 , Time: 2105.793291091919 s\n",
      "Batch:  1640 , l1 Loss:  0.11110709682106971 , Time: 2118.885217666626 s\n",
      "Batch:  1650 , l1 Loss:  0.11118193566799164 , Time: 2131.9433994293213 s\n",
      "Batch:  1660 , l1 Loss:  0.10660495683550834 , Time: 2145.0023550987244 s\n",
      "Batch:  1670 , l1 Loss:  0.10925958752632141 , Time: 2158.0928881168365 s\n",
      "Batch:  1680 , l1 Loss:  0.11097454726696014 , Time: 2171.176813364029 s\n",
      "Batch:  1690 , l1 Loss:  0.11124986857175827 , Time: 2184.2716088294983 s\n",
      "Batch:  1700 , l1 Loss:  0.10956711545586587 , Time: 2197.3691940307617 s\n",
      "Batch:  1710 , l1 Loss:  0.11187980994582176 , Time: 2210.4298655986786 s\n",
      "Batch:  1720 , l1 Loss:  0.11302959993481636 , Time: 2223.464209318161 s\n",
      "Batch:  1730 , l1 Loss:  0.10851619094610214 , Time: 2236.5236628055573 s\n",
      "Batch:  1740 , l1 Loss:  0.11374568715691566 , Time: 2249.5970780849457 s\n",
      "Batch:  1750 , l1 Loss:  0.10909330248832702 , Time: 2262.674798965454 s\n",
      "Batch:  1760 , l1 Loss:  0.11248920038342476 , Time: 2275.7485423088074 s\n",
      "Batch:  1770 , l1 Loss:  0.10954670459032059 , Time: 2288.828859090805 s\n",
      "Batch:  1780 , l1 Loss:  0.1076549232006073 , Time: 2301.922073841095 s\n",
      "Batch:  1790 , l1 Loss:  0.11009772568941116 , Time: 2315.077157497406 s\n",
      "Batch:  1800 , l1 Loss:  0.10922175049781799 , Time: 2328.171657562256 s\n",
      "Batch:  1810 , l1 Loss:  0.10933321192860604 , Time: 2341.258091211319 s\n",
      "Batch:  1820 , l1 Loss:  0.11104676648974418 , Time: 2354.3501987457275 s\n",
      "Batch:  1830 , l1 Loss:  0.1113476350903511 , Time: 2367.406902074814 s\n",
      "Batch:  1840 , l1 Loss:  0.1138104848563671 , Time: 2380.323080778122 s\n",
      "Batch:  1850 , l1 Loss:  0.10927987769246102 , Time: 2393.2626950740814 s\n",
      "Batch:  1860 , l1 Loss:  0.10971770286560059 , Time: 2406.238688468933 s\n",
      "Batch:  1870 , l1 Loss:  0.10889605358242989 , Time: 2419.1883730888367 s\n",
      "Batch:  1880 , l1 Loss:  0.10561365485191346 , Time: 2432.1781997680664 s\n",
      "Batch:  1890 , l1 Loss:  0.10942112728953361 , Time: 2445.1544160842896 s\n",
      "Batch:  1900 , l1 Loss:  0.10532679036259651 , Time: 2458.155566930771 s\n",
      "Batch:  1910 , l1 Loss:  0.1076860785484314 , Time: 2471.1543917655945 s\n",
      "Batch:  1920 , l1 Loss:  0.10591305196285247 , Time: 2484.1972045898438 s\n",
      "Batch:  1930 , l1 Loss:  0.10773560851812362 , Time: 2497.1962838172913 s\n",
      "Batch:  1940 , l1 Loss:  0.10528140589594841 , Time: 2510.170833826065 s\n",
      "Batch:  1950 , l1 Loss:  0.10705668181180954 , Time: 2523.1452145576477 s\n",
      "Batch:  1960 , l1 Loss:  0.10865653529763222 , Time: 2536.1647188663483 s\n",
      "Batch:  1970 , l1 Loss:  0.11005564928054809 , Time: 2549.210038661957 s\n",
      "Batch:  1980 , l1 Loss:  0.10612021535634994 , Time: 2562.2252130508423 s\n",
      "Batch:  1990 , l1 Loss:  0.11175319030880929 , Time: 2575.318779706955 s\n",
      "Batch:  2000 , l1 Loss:  0.10917807221412659 , Time: 2588.42142701149 s\n",
      "Batch:  2010 , l1 Loss:  0.10866871029138565 , Time: 2601.558709383011 s\n",
      "Batch:  2020 , l1 Loss:  0.10895030498504639 , Time: 2614.62597155571 s\n",
      "Batch:  2030 , l1 Loss:  0.11017969846725464 , Time: 2627.68279337883 s\n",
      "Batch:  2040 , l1 Loss:  0.10624393001198769 , Time: 2640.7993330955505 s\n",
      "Batch:  2050 , l1 Loss:  0.10771053209900856 , Time: 2653.812885761261 s\n",
      "Batch:  2060 , l1 Loss:  0.10804906114935875 , Time: 2666.9317483901978 s\n",
      "Batch:  2070 , l1 Loss:  0.10841821283102035 , Time: 2680.0303885936737 s\n",
      "Batch:  2080 , l1 Loss:  0.10543285980820656 , Time: 2693.1253373622894 s\n",
      "Batch:  2090 , l1 Loss:  0.10742100104689598 , Time: 2706.2044928073883 s\n",
      "Batch:  2100 , l1 Loss:  0.1056159868836403 , Time: 2719.2810056209564 s\n",
      "Batch:  2110 , l1 Loss:  0.10952061936259269 , Time: 2732.3778047561646 s\n",
      "Batch:  2120 , l1 Loss:  0.11390326619148254 , Time: 2745.471338033676 s\n",
      "Batch:  2130 , l1 Loss:  0.10742596611380577 , Time: 2758.56147313118 s\n",
      "Batch:  2140 , l1 Loss:  0.1115645334124565 , Time: 2771.6103920936584 s\n",
      "Batch:  2150 , l1 Loss:  0.10716646164655685 , Time: 2784.683624982834 s\n",
      "Batch:  2160 , l1 Loss:  0.1097071997821331 , Time: 2797.959996700287 s\n",
      "Batch:  2170 , l1 Loss:  0.10840715616941451 , Time: 2811.1990718841553 s\n",
      "Batch:  2180 , l1 Loss:  0.11205575987696648 , Time: 2824.418640613556 s\n",
      "Batch:  2190 , l1 Loss:  0.11329133585095405 , Time: 2837.6096529960632 s\n",
      "Batch:  2200 , l1 Loss:  0.11022915542125702 , Time: 2850.7745728492737 s\n",
      "Batch:  2210 , l1 Loss:  0.10850504040718079 , Time: 2863.945106983185 s\n",
      "Batch:  2220 , l1 Loss:  0.10851220041513443 , Time: 2877.103643655777 s\n",
      "Batch:  2230 , l1 Loss:  0.11030832007527351 , Time: 2890.264456987381 s\n",
      "Batch:  2240 , l1 Loss:  0.11088653728365898 , Time: 2903.3996303081512 s\n",
      "Batch:  2250 , l1 Loss:  0.10967635065317154 , Time: 2916.5791273117065 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  2260 , l1 Loss:  0.10759318098425866 , Time: 2929.718319416046 s\n",
      "Batch:  2270 , l1 Loss:  0.10892292857170105 , Time: 2942.836816072464 s\n",
      "Batch:  2280 , l1 Loss:  0.10942751243710518 , Time: 2955.9783675670624 s\n",
      "Batch:  2290 , l1 Loss:  0.10583948418498039 , Time: 2969.0882625579834 s\n",
      "Batch:  2300 , l1 Loss:  0.10686551779508591 , Time: 2982.184993505478 s\n",
      "Batch:  2310 , l1 Loss:  0.11189115643501282 , Time: 2995.226074695587 s\n",
      "Batch:  2320 , l1 Loss:  0.10833612233400344 , Time: 3008.2703187465668 s\n",
      "Batch:  2330 , l1 Loss:  0.11462832391262054 , Time: 3021.271742105484 s\n",
      "Batch:  2340 , l1 Loss:  0.11157186627388001 , Time: 3034.3496351242065 s\n",
      "Batch:  2350 , l1 Loss:  0.11146168783307076 , Time: 3047.395822286606 s\n",
      "Batch:  2360 , l1 Loss:  0.10777470543980598 , Time: 3060.4134299755096 s\n",
      "Batch:  2370 , l1 Loss:  0.10738113522529602 , Time: 3073.4846918582916 s\n",
      "Batch:  2380 , l1 Loss:  0.10889825224876404 , Time: 3086.5090782642365 s\n",
      "Batch:  2390 , l1 Loss:  0.10996963456273079 , Time: 3099.563766479492 s\n",
      "Batch:  2400 , l1 Loss:  0.10931394696235656 , Time: 3112.5797247886658 s\n",
      "Batch:  2410 , l1 Loss:  0.1064011849462986 , Time: 3125.6544003486633 s\n",
      "Batch:  2420 , l1 Loss:  0.11051969155669213 , Time: 3138.692509174347 s\n",
      "Batch:  2430 , l1 Loss:  0.10810201168060303 , Time: 3151.791992664337 s\n",
      "Batch:  2440 , l1 Loss:  0.10898258537054062 , Time: 3164.8759574890137 s\n",
      "Batch:  2450 , l1 Loss:  0.10525375902652741 , Time: 3177.9518847465515 s\n",
      "Batch:  2460 , l1 Loss:  0.10818228349089623 , Time: 3190.985583305359 s\n",
      "Batch:  2470 , l1 Loss:  0.10952885374426842 , Time: 3204.02690410614 s\n",
      "Batch:  2480 , l1 Loss:  0.11130087673664094 , Time: 3217.0605976581573 s\n",
      "Batch:  2490 , l1 Loss:  0.10619842335581779 , Time: 3230.0996379852295 s\n",
      "Batch:  2500 , l1 Loss:  0.10839051380753517 , Time: 3243.134020805359 s\n",
      "Batch:  2510 , l1 Loss:  0.11188632920384407 , Time: 3256.256479740143 s\n",
      "Batch:  2520 , l1 Loss:  0.10557872727513314 , Time: 3269.376511335373 s\n",
      "Batch:  2530 , l1 Loss:  0.10796482339501381 , Time: 3282.4382150173187 s\n",
      "Batch:  2540 , l1 Loss:  0.10639070868492126 , Time: 3295.514297246933 s\n",
      "Batch:  2550 , l1 Loss:  0.10589745342731476 , Time: 3308.5724964141846 s\n",
      "Batch:  2560 , l1 Loss:  0.10614493042230606 , Time: 3321.6471903324127 s\n",
      "Batch:  2570 , l1 Loss:  0.10750297084450722 , Time: 3334.7729592323303 s\n",
      "Batch:  2580 , l1 Loss:  0.10845401585102081 , Time: 3347.820628643036 s\n",
      "Batch:  2590 , l1 Loss:  0.10916300639510154 , Time: 3360.8567345142365 s\n",
      "Batch:  2600 , l1 Loss:  0.10896057933568955 , Time: 3373.9241676330566 s\n",
      "Batch:  2610 , l1 Loss:  0.11076664105057717 , Time: 3386.9892036914825 s\n",
      "Batch:  2620 , l1 Loss:  0.10889396592974662 , Time: 3400.085042953491 s\n",
      "Batch:  2630 , l1 Loss:  0.10862070843577384 , Time: 3413.1946637630463 s\n",
      "Batch:  2640 , l1 Loss:  0.1053423136472702 , Time: 3426.144485473633 s\n",
      "Batch:  2650 , l1 Loss:  0.10729295313358307 , Time: 3439.0999279022217 s\n",
      "Batch:  2660 , l1 Loss:  0.10576404333114624 , Time: 3452.0774133205414 s\n",
      "Batch:  2670 , l1 Loss:  0.10729102119803428 , Time: 3465.055154323578 s\n",
      "Batch:  2680 , l1 Loss:  0.10620037615299224 , Time: 3478.0951039791107 s\n",
      "Batch:  2690 , l1 Loss:  0.10706914439797402 , Time: 3491.1364998817444 s\n",
      "Batch:  2700 , l1 Loss:  0.10604531317949295 , Time: 3504.2135887145996 s\n",
      "Batch:  2710 , l1 Loss:  0.1052730217576027 , Time: 3517.353184223175 s\n",
      "Batch:  2720 , l1 Loss:  0.10890076085925102 , Time: 3530.391573905945 s\n",
      "Batch:  2730 , l1 Loss:  0.10722891539335251 , Time: 3543.507435798645 s\n",
      "Batch:  2740 , l1 Loss:  0.10804429948329926 , Time: 3556.6422493457794 s\n",
      "Batch:  2750 , l1 Loss:  0.10599103420972825 , Time: 3569.777202606201 s\n",
      "Batch:  2760 , l1 Loss:  0.1058222770690918 , Time: 3582.8875226974487 s\n",
      "Batch:  2770 , l1 Loss:  0.10759078934788704 , Time: 3596.0087835788727 s\n",
      "Batch:  2780 , l1 Loss:  0.10717764273285865 , Time: 3609.123143196106 s\n",
      "Batch:  2790 , l1 Loss:  0.10725689381361007 , Time: 3622.2396759986877 s\n",
      "Batch:  2800 , l1 Loss:  0.10743971392512322 , Time: 3635.396785259247 s\n",
      "Batch:  2810 , l1 Loss:  0.10583287626504898 , Time: 3648.4755580425262 s\n",
      "Batch:  2820 , l1 Loss:  0.11073182001709939 , Time: 3661.5900304317474 s\n",
      "Batch:  2830 , l1 Loss:  0.10560142472386361 , Time: 3674.7107207775116 s\n",
      "Batch:  2840 , l1 Loss:  0.1057758778333664 , Time: 3687.747423887253 s\n",
      "Batch:  2850 , l1 Loss:  0.10662726089358329 , Time: 3700.8488812446594 s\n",
      "Batch:  2860 , l1 Loss:  0.10688799098134041 , Time: 3713.926232814789 s\n",
      "Batch:  2870 , l1 Loss:  0.10494423508644105 , Time: 3727.0150129795074 s\n",
      "Batch:  2880 , l1 Loss:  0.11001785099506378 , Time: 3740.0751807689667 s\n",
      "Batch:  2890 , l1 Loss:  0.10515699610114097 , Time: 3753.1779928207397 s\n",
      "Batch:  2900 , l1 Loss:  0.10844805538654327 , Time: 3766.2520792484283 s\n",
      "Batch:  2910 , l1 Loss:  0.1121465340256691 , Time: 3779.3080554008484 s\n",
      "Batch:  2920 , l1 Loss:  0.10670452788472176 , Time: 3792.3836464881897 s\n",
      "Batch:  2930 , l1 Loss:  0.104721699655056 , Time: 3805.4234817028046 s\n",
      "Batch:  2940 , l1 Loss:  0.10808310210704804 , Time: 3818.477018594742 s\n",
      "Batch:  2950 , l1 Loss:  0.10597482323646545 , Time: 3831.540799856186 s\n",
      "Batch:  2960 , l1 Loss:  0.1077689565718174 , Time: 3844.598252058029 s\n",
      "Batch:  2970 , l1 Loss:  0.10913579761981965 , Time: 3857.6337654590607 s\n",
      "Batch:  2980 , l1 Loss:  0.10566259399056435 , Time: 3870.7294013500214 s\n",
      "Batch:  2990 , l1 Loss:  0.1104596272110939 , Time: 3883.7860736846924 s\n",
      "Batch:  3000 , l1 Loss:  0.11011818498373031 , Time: 3896.8282811641693 s\n",
      "Batch:  3010 , l1 Loss:  0.10566440373659133 , Time: 3909.9056928157806 s\n",
      "Batch:  3020 , l1 Loss:  0.10756468176841735 , Time: 3922.938136816025 s\n",
      "Batch:  3030 , l1 Loss:  0.1084398314356804 , Time: 3936.01881980896 s\n",
      "Batch:  3040 , l1 Loss:  0.10756895542144776 , Time: 3949.0698897838593 s\n",
      "Batch:  3050 , l1 Loss:  0.10692370608448983 , Time: 3962.098157644272 s\n",
      "Batch:  3060 , l1 Loss:  0.1064173586666584 , Time: 3975.1394460201263 s\n",
      "Batch:  3070 , l1 Loss:  0.10592674687504769 , Time: 3988.1780898571014 s\n",
      "Batch:  3080 , l1 Loss:  0.10577657669782639 , Time: 4001.211754798889 s\n",
      "Batch:  3090 , l1 Loss:  0.108493884652853 , Time: 4014.2516577243805 s\n",
      "Batch:  3100 , l1 Loss:  0.10574161410331726 , Time: 4027.318490743637 s\n",
      "Batch:  3110 , l1 Loss:  0.10735697150230408 , Time: 4040.351133823395 s\n",
      "Batch:  3120 , l1 Loss:  0.10752136930823326 , Time: 4053.446331501007 s\n",
      "Batch:  3130 , l1 Loss:  0.10541868209838867 , Time: 4066.4242899417877 s\n",
      "Batch:  3140 , l1 Loss:  0.10660918056964874 , Time: 4079.4581196308136 s\n",
      "Batch:  3150 , l1 Loss:  0.10796213075518608 , Time: 4092.4794883728027 s\n",
      "Batch:  3160 , l1 Loss:  0.10508697479963303 , Time: 4105.53983092308 s\n",
      "Batch:  3170 , l1 Loss:  0.10346940904855728 , Time: 4118.657867431641 s\n",
      "Batch:  3180 , l1 Loss:  0.10696437656879425 , Time: 4131.689564228058 s\n",
      "Batch:  3190 , l1 Loss:  0.10644216537475586 , Time: 4144.7458345890045 s\n",
      "Batch:  3200 , l1 Loss:  0.10984343886375428 , Time: 4157.84768652916 s\n",
      "Batch:  3210 , l1 Loss:  0.10930872932076455 , Time: 4170.923401117325 s\n",
      "Batch:  3220 , l1 Loss:  0.10817829221487045 , Time: 4184.021653413773 s\n",
      "Batch:  3230 , l1 Loss:  0.10786500796675683 , Time: 4197.116566419601 s\n",
      "Batch:  3240 , l1 Loss:  0.10715595632791519 , Time: 4210.235866785049 s\n",
      "Batch:  3250 , l1 Loss:  0.10489383786916733 , Time: 4223.335886716843 s\n",
      "Batch:  3260 , l1 Loss:  0.10545096695423126 , Time: 4236.499995708466 s\n",
      "Batch:  3270 , l1 Loss:  0.10463222414255142 , Time: 4249.620467424393 s\n",
      "Batch:  3280 , l1 Loss:  0.10491508543491364 , Time: 4262.779162406921 s\n",
      "Batch:  3290 , l1 Loss:  0.10510607361793518 , Time: 4275.917746782303 s\n",
      "Batch:  3300 , l1 Loss:  0.1050829567015171 , Time: 4289.036743402481 s\n",
      "Batch:  3310 , l1 Loss:  0.10533682778477668 , Time: 4302.178096294403 s\n",
      "Batch:  3320 , l1 Loss:  0.10593993663787842 , Time: 4315.293221235275 s\n",
      "Batch:  3330 , l1 Loss:  0.10580999180674552 , Time: 4328.414236783981 s\n",
      "Batch:  3340 , l1 Loss:  0.10761196091771126 , Time: 4341.510764837265 s\n",
      "Batch:  3350 , l1 Loss:  0.10665711015462875 , Time: 4354.611826181412 s\n",
      "Batch:  3360 , l1 Loss:  0.10784392058849335 , Time: 4367.655428647995 s\n",
      "Batch:  3370 , l1 Loss:  0.10761837586760521 , Time: 4380.733053684235 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  3380 , l1 Loss:  0.10498561933636666 , Time: 4393.810075998306 s\n",
      "Batch:  3390 , l1 Loss:  0.10814249664545059 , Time: 4406.872135877609 s\n",
      "Batch:  3400 , l1 Loss:  0.10975121781229973 , Time: 4419.924778461456 s\n",
      "Batch:  3410 , l1 Loss:  0.10419900193810464 , Time: 4433.002830982208 s\n",
      "Batch:  3420 , l1 Loss:  0.10834634006023407 , Time: 4446.078515052795 s\n",
      "Batch:  3430 , l1 Loss:  0.10692025274038315 , Time: 4459.1771504879 s\n",
      "Batch:  3440 , l1 Loss:  0.10774853900074959 , Time: 4472.474814891815 s\n",
      "Batch:  3450 , l1 Loss:  0.10331388339400291 , Time: 4485.553847551346 s\n",
      "Batch:  3460 , l1 Loss:  0.10835448205471039 , Time: 4498.632539510727 s\n",
      "Batch:  3470 , l1 Loss:  0.10801061168313027 , Time: 4511.690908670425 s\n",
      "Batch:  3480 , l1 Loss:  0.10764374509453774 , Time: 4524.768872976303 s\n",
      "Batch:  3490 , l1 Loss:  0.10752873122692108 , Time: 4537.801419496536 s\n",
      "Batch:  3500 , l1 Loss:  0.10892132669687271 , Time: 4550.838408708572 s\n",
      "Batch:  3510 , l1 Loss:  0.10953421369194985 , Time: 4563.98072385788 s\n",
      "Batch:  3520 , l1 Loss:  0.11000391319394112 , Time: 4577.012534856796 s\n",
      "Batch:  3530 , l1 Loss:  0.10575027540326118 , Time: 4590.109723806381 s\n",
      "Batch:  3540 , l1 Loss:  0.10849657952785492 , Time: 4603.162252902985 s\n",
      "Batch:  3550 , l1 Loss:  0.10802947655320168 , Time: 4616.189319849014 s\n",
      "Batch:  3560 , l1 Loss:  0.10527374148368836 , Time: 4629.2469046115875 s\n",
      "Batch:  3570 , l1 Loss:  0.10883463844656945 , Time: 4642.304621696472 s\n",
      "Batch:  3580 , l1 Loss:  0.10576390624046325 , Time: 4655.346588373184 s\n",
      "Batch:  3590 , l1 Loss:  0.10740599110722542 , Time: 4668.401909828186 s\n",
      "Batch:  3600 , l1 Loss:  0.10821180567145347 , Time: 4681.458788156509 s\n",
      "Batch:  3610 , l1 Loss:  0.10521318316459656 , Time: 4694.538508892059 s\n",
      "Batch:  3620 , l1 Loss:  0.10537762939929962 , Time: 4707.637006044388 s\n",
      "Batch:  3630 , l1 Loss:  0.1084569163620472 , Time: 4720.731184244156 s\n",
      "Batch:  3640 , l1 Loss:  0.10714899525046348 , Time: 4733.7892191410065 s\n",
      "Batch:  3650 , l1 Loss:  0.10667742863297462 , Time: 4746.922840595245 s\n",
      "Batch:  3660 , l1 Loss:  0.10777134224772453 , Time: 4760.036703586578 s\n",
      "Batch:  3670 , l1 Loss:  0.10645724534988403 , Time: 4773.153561592102 s\n",
      "Batch:  3680 , l1 Loss:  0.10718877911567688 , Time: 4786.28907251358 s\n",
      "Batch:  3690 , l1 Loss:  0.10757077857851982 , Time: 4799.365394115448 s\n",
      "Batch:  3700 , l1 Loss:  0.10477766543626785 , Time: 4812.485734939575 s\n",
      "Batch:  3710 , l1 Loss:  0.10677103027701378 , Time: 4825.595107793808 s\n",
      "Batch:  3720 , l1 Loss:  0.10749852061271667 , Time: 4838.763230085373 s\n",
      "Batch:  3730 , l1 Loss:  0.10497497916221618 , Time: 4851.835189342499 s\n",
      "Batch:  3740 , l1 Loss:  0.10675817206501961 , Time: 4864.93083190918 s\n",
      "Batch:  3750 , l1 Loss:  0.10545992404222489 , Time: 4877.948136091232 s\n",
      "Batch:  3760 , l1 Loss:  0.1066487766802311 , Time: 4890.965529680252 s\n",
      "Batch:  3770 , l1 Loss:  0.10246505811810494 , Time: 4903.986042499542 s\n",
      "Batch:  3780 , l1 Loss:  0.10296781510114669 , Time: 4917.064019918442 s\n",
      "Batch:  3790 , l1 Loss:  0.10421463623642921 , Time: 4930.138706445694 s\n",
      "Batch:  3800 , l1 Loss:  0.10714646503329277 , Time: 4943.21706867218 s\n",
      "Batch:  3810 , l1 Loss:  0.1084222987294197 , Time: 4956.378529071808 s\n",
      "Batch:  3820 , l1 Loss:  0.10767645984888077 , Time: 4969.461050748825 s\n",
      "Batch:  3830 , l1 Loss:  0.10592917948961258 , Time: 4982.61612701416 s\n",
      "Batch:  3840 , l1 Loss:  0.10543441101908683 , Time: 4995.732567310333 s\n",
      "Batch:  3850 , l1 Loss:  0.10686258673667907 , Time: 5008.870332479477 s\n",
      "Batch:  3860 , l1 Loss:  0.1051086165010929 , Time: 5021.985347747803 s\n",
      "Batch:  3870 , l1 Loss:  0.10502762049436569 , Time: 5035.100715398788 s\n",
      "Batch:  3880 , l1 Loss:  0.10479375347495079 , Time: 5048.24520611763 s\n",
      "Batch:  3890 , l1 Loss:  0.10560543909668922 , Time: 5061.361775398254 s\n",
      "Batch:  3900 , l1 Loss:  0.10612938329577445 , Time: 5074.380705356598 s\n",
      "Batch:  3910 , l1 Loss:  0.10596110001206398 , Time: 5087.459131002426 s\n",
      "Batch:  3920 , l1 Loss:  0.10953685715794563 , Time: 5100.520151376724 s\n",
      "Batch:  3930 , l1 Loss:  0.10720678940415382 , Time: 5113.544909954071 s\n",
      "Batch:  3940 , l1 Loss:  0.10646169558167458 , Time: 5126.6396589279175 s\n",
      "Batch:  3950 , l1 Loss:  0.10839573219418526 , Time: 5139.7786746025085 s\n",
      "Batch:  3960 , l1 Loss:  0.1097564235329628 , Time: 5152.9121861457825 s\n",
      "Batch:  3970 , l1 Loss:  0.10564783290028572 , Time: 5166.009029626846 s\n",
      "Batch:  3980 , l1 Loss:  0.10667463093996048 , Time: 5179.069705486298 s\n",
      "Batch:  3990 , l1 Loss:  0.10514450594782829 , Time: 5192.20517539978 s\n",
      "Batch:  4000 , l1 Loss:  0.10676598623394966 , Time: 5205.297731876373 s\n",
      "Batch:  4010 , l1 Loss:  0.10826201811432838 , Time: 5218.4340670108795 s\n",
      "Batch:  4020 , l1 Loss:  0.10447692200541496 , Time: 5231.5184717178345 s\n",
      "Batch:  4030 , l1 Loss:  0.1049126259982586 , Time: 5244.6545667648315 s\n",
      "Batch:  4040 , l1 Loss:  0.10426649823784828 , Time: 5257.787104606628 s\n",
      "Batch:  4050 , l1 Loss:  0.1063124842941761 , Time: 5270.904236316681 s\n",
      "Batch:  4060 , l1 Loss:  0.1057917296886444 , Time: 5284.022174358368 s\n",
      "Batch:  4070 , l1 Loss:  0.10610846132040024 , Time: 5297.121612071991 s\n",
      "Batch:  4080 , l1 Loss:  0.10477007851004601 , Time: 5310.268886089325 s\n",
      "Batch:  4090 , l1 Loss:  0.1068033143877983 , Time: 5323.410353422165 s\n",
      "Batch:  4100 , l1 Loss:  0.10650792196393014 , Time: 5336.55005812645 s\n",
      "Batch:  4110 , l1 Loss:  0.10967596992850304 , Time: 5349.687793970108 s\n",
      "Batch:  4120 , l1 Loss:  0.10470878183841706 , Time: 5362.825824260712 s\n",
      "Batch:  4130 , l1 Loss:  0.10813781097531319 , Time: 5375.967168331146 s\n",
      "Batch:  4140 , l1 Loss:  0.10856936722993851 , Time: 5389.080099582672 s\n",
      "Batch:  4150 , l1 Loss:  0.10614818930625916 , Time: 5402.217719554901 s\n",
      "Batch:  4160 , l1 Loss:  0.10370557233691216 , Time: 5415.514149427414 s\n",
      "Batch:  4170 , l1 Loss:  0.10634544417262078 , Time: 5428.798386335373 s\n",
      "Batch:  4180 , l1 Loss:  0.1045302540063858 , Time: 5442.018179655075 s\n",
      "Batch:  4190 , l1 Loss:  0.10770795568823814 , Time: 5455.152199268341 s\n",
      "Batch:  4200 , l1 Loss:  0.10719044059515 , Time: 5468.3233387470245 s\n",
      "Batch:  4210 , l1 Loss:  0.10809859558939934 , Time: 5481.439474821091 s\n",
      "Batch:  4220 , l1 Loss:  0.10439918339252471 , Time: 5494.576829433441 s\n",
      "Batch:  4230 , l1 Loss:  0.1048018679022789 , Time: 5507.720536470413 s\n",
      "Batch:  4240 , l1 Loss:  0.10290099456906318 , Time: 5521.015866518021 s\n",
      "Batch:  4250 , l1 Loss:  0.10502103939652443 , Time: 5534.171055555344 s\n",
      "Batch:  4260 , l1 Loss:  0.10459994226694107 , Time: 5547.528837680817 s\n",
      "Batch:  4270 , l1 Loss:  0.1048303060233593 , Time: 5560.842228889465 s\n",
      "Batch:  4280 , l1 Loss:  0.10802611112594604 , Time: 5573.882597923279 s\n",
      "Batch:  4290 , l1 Loss:  0.10482487082481384 , Time: 5586.862175703049 s\n",
      "Batch:  4300 , l1 Loss:  0.10676784664392472 , Time: 5599.920545101166 s\n",
      "Batch:  4310 , l1 Loss:  0.10669285207986831 , Time: 5612.974589347839 s\n",
      "Batch:  4320 , l1 Loss:  0.10629875585436821 , Time: 5626.253348827362 s\n",
      "Batch:  4330 , l1 Loss:  0.10511180311441422 , Time: 5639.516144752502 s\n",
      "Batch:  4340 , l1 Loss:  0.10646285489201546 , Time: 5652.67533493042 s\n",
      "Batch:  4350 , l1 Loss:  0.10766967833042144 , Time: 5665.813190460205 s\n",
      "Batch:  4360 , l1 Loss:  0.10571506917476654 , Time: 5679.008011341095 s\n",
      "Batch:  4370 , l1 Loss:  0.10230338647961616 , Time: 5692.145467996597 s\n",
      "Batch:  4380 , l1 Loss:  0.10541388243436814 , Time: 5705.360519886017 s\n",
      "Batch:  4390 , l1 Loss:  0.10701164901256562 , Time: 5718.523586034775 s\n",
      "Batch:  4400 , l1 Loss:  0.10783617198467255 , Time: 5731.645769357681 s\n",
      "Batch:  4410 , l1 Loss:  0.10934788435697555 , Time: 5744.757915973663 s\n",
      "Batch:  4420 , l1 Loss:  0.1082681231200695 , Time: 5757.86869764328 s\n",
      "Batch:  4430 , l1 Loss:  0.10488814041018486 , Time: 5770.949863910675 s\n",
      "Batch:  4440 , l1 Loss:  0.10682988688349723 , Time: 5784.089307546616 s\n",
      "Batch:  4450 , l1 Loss:  0.1063670352101326 , Time: 5797.265320301056 s\n",
      "Batch:  4460 , l1 Loss:  0.10921575352549553 , Time: 5810.399680376053 s\n",
      "Batch:  4470 , l1 Loss:  0.10393728539347649 , Time: 5823.55765914917 s\n",
      "Batch:  4480 , l1 Loss:  0.10753093063831329 , Time: 5836.668337106705 s\n",
      "Batch:  4490 , l1 Loss:  0.10636292845010757 , Time: 5849.89189863205 s\n",
      "Batch:  4500 , l1 Loss:  0.10807406902313232 , Time: 5863.03018450737 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  4510 , l1 Loss:  0.1072274774312973 , Time: 5876.233028411865 s\n",
      "Batch:  4520 , l1 Loss:  0.10630022436380386 , Time: 5889.348572254181 s\n",
      "Batch:  4530 , l1 Loss:  0.10596808195114135 , Time: 5902.486583948135 s\n",
      "Batch:  4540 , l1 Loss:  0.10552069991827011 , Time: 5915.667801856995 s\n",
      "Batch:  4550 , l1 Loss:  0.10414698347449303 , Time: 5928.802874326706 s\n",
      "Batch:  4560 , l1 Loss:  0.10569369941949844 , Time: 5941.8566081523895 s\n",
      "Batch:  4570 , l1 Loss:  0.1065135046839714 , Time: 5954.951425075531 s\n",
      "Batch:  4580 , l1 Loss:  0.1053469367325306 , Time: 5968.05441403389 s\n",
      "Batch:  4590 , l1 Loss:  0.10605354905128479 , Time: 5981.195420026779 s\n",
      "Batch:  4600 , l1 Loss:  0.10657467693090439 , Time: 5994.337844848633 s\n",
      "Batch:  4610 , l1 Loss:  0.1058957777917385 , Time: 6007.475194692612 s\n",
      "Batch:  4620 , l1 Loss:  0.10367530211806297 , Time: 6020.61604642868 s\n",
      "Batch:  4630 , l1 Loss:  0.10403775870800018 , Time: 6033.755775690079 s\n",
      "Batch:  4640 , l1 Loss:  0.1033033013343811 , Time: 6046.937043190002 s\n",
      "Batch:  4650 , l1 Loss:  0.10688088461756706 , Time: 6060.076485157013 s\n",
      "Batch:  4660 , l1 Loss:  0.10400756448507309 , Time: 6073.2297785282135 s\n",
      "Batch:  4670 , l1 Loss:  0.10692023485898972 , Time: 6086.353283882141 s\n",
      "Batch:  4680 , l1 Loss:  0.1074330136179924 , Time: 6099.471826076508 s\n",
      "Batch:  4690 , l1 Loss:  0.10701249986886978 , Time: 6112.613519668579 s\n",
      "Batch:  4700 , l1 Loss:  0.10418470427393914 , Time: 6125.757258892059 s\n",
      "Batch:  4710 , l1 Loss:  0.1087680585682392 , Time: 6138.895220518112 s\n",
      "Batch:  4720 , l1 Loss:  0.10433039292693139 , Time: 6152.096268415451 s\n",
      "Batch:  4730 , l1 Loss:  0.10727760791778565 , Time: 6165.236310005188 s\n",
      "Batch:  4740 , l1 Loss:  0.10624189227819443 , Time: 6178.337724685669 s\n",
      "Batch:  4750 , l1 Loss:  0.10583101138472557 , Time: 6191.496073961258 s\n",
      "Batch:  4760 , l1 Loss:  0.10536959022283554 , Time: 6204.811784029007 s\n",
      "Batch:  4770 , l1 Loss:  0.10555606856942176 , Time: 6218.089479207993 s\n",
      "Batch:  4780 , l1 Loss:  0.10636850148439407 , Time: 6231.304071903229 s\n",
      "Batch:  4790 , l1 Loss:  0.10718227401375771 , Time: 6244.418207883835 s\n",
      "Batch:  4800 , l1 Loss:  0.10917116105556487 , Time: 6257.692049741745 s\n",
      "Batch:  4810 , l1 Loss:  0.10699925795197487 , Time: 6270.877551317215 s\n",
      "Batch:  4820 , l1 Loss:  0.10634815469384193 , Time: 6283.969932079315 s\n",
      "Batch:  4830 , l1 Loss:  0.10691121146082878 , Time: 6297.0671100616455 s\n",
      "Batch:  4840 , l1 Loss:  0.1044826053082943 , Time: 6310.166255235672 s\n",
      "Batch:  4850 , l1 Loss:  0.10528873056173324 , Time: 6323.407474517822 s\n",
      "Batch:  4860 , l1 Loss:  0.10411262139678001 , Time: 6336.70361328125 s\n",
      "Batch:  4870 , l1 Loss:  0.10788442492485047 , Time: 6349.981729745865 s\n",
      "Batch:  4880 , l1 Loss:  0.10796292945742607 , Time: 6363.242002487183 s\n",
      "Batch:  4890 , l1 Loss:  0.10442039519548416 , Time: 6376.454764127731 s\n",
      "Batch:  4900 , l1 Loss:  0.10914142653346062 , Time: 6389.678007602692 s\n",
      "Batch:  4910 , l1 Loss:  0.10536236986517906 , Time: 6402.915839910507 s\n",
      "Batch:  4920 , l1 Loss:  0.10743215009570121 , Time: 6416.110510826111 s\n",
      "Batch:  4930 , l1 Loss:  0.10710572451353073 , Time: 6429.306180000305 s\n",
      "Batch:  4940 , l1 Loss:  0.10587981417775154 , Time: 6442.51907491684 s\n",
      "Batch:  4950 , l1 Loss:  0.10723349377512932 , Time: 6455.700687408447 s\n",
      "Batch:  4960 , l1 Loss:  0.10327811017632485 , Time: 6468.916026830673 s\n",
      "Batch:  4970 , l1 Loss:  0.10471915900707245 , Time: 6482.012787818909 s\n",
      "Batch:  4980 , l1 Loss:  0.1067031554877758 , Time: 6494.969118595123 s\n",
      "Batch:  4990 , l1 Loss:  0.10683537870645524 , Time: 6507.907616376877 s\n",
      "Batch:  5000 , l1 Loss:  0.10553385764360428 , Time: 6520.988404035568 s\n",
      "Batch:  5010 , l1 Loss:  0.10615545064210892 , Time: 6534.009965896606 s\n",
      "Batch:  5020 , l1 Loss:  0.10906267166137695 , Time: 6547.130649805069 s\n",
      "Batch:  5030 , l1 Loss:  0.10689720958471298 , Time: 6560.2613480091095 s\n",
      "Batch:  5040 , l1 Loss:  0.10794589594006539 , Time: 6573.361463308334 s\n",
      "Batch:  5050 , l1 Loss:  0.10724506974220276 , Time: 6586.420674800873 s\n",
      "Batch:  5060 , l1 Loss:  0.1069256342947483 , Time: 6599.496627569199 s\n",
      "Batch:  5070 , l1 Loss:  0.10793878436088562 , Time: 6612.594310998917 s\n",
      "Batch:  5080 , l1 Loss:  0.10651081651449204 , Time: 6625.672908067703 s\n",
      "Batch:  5090 , l1 Loss:  0.10532166510820389 , Time: 6638.83408331871 s\n",
      "Batch:  5100 , l1 Loss:  0.10661313384771347 , Time: 6651.959454059601 s\n",
      "Batch:  5110 , l1 Loss:  0.1057569332420826 , Time: 6665.099669933319 s\n",
      "Batch:  5120 , l1 Loss:  0.10562652349472046 , Time: 6678.216818809509 s\n",
      "Batch:  5130 , l1 Loss:  0.10741250813007355 , Time: 6691.356007814407 s\n",
      "Batch:  5140 , l1 Loss:  0.10336137562990189 , Time: 6704.4977288246155 s\n",
      "Batch:  5150 , l1 Loss:  0.10759960189461708 , Time: 6717.63874912262 s\n",
      "Batch:  5160 , l1 Loss:  0.10726767927408218 , Time: 6730.77595448494 s\n",
      "Batch:  5170 , l1 Loss:  0.1042716920375824 , Time: 6743.892966270447 s\n",
      "Batch:  5180 , l1 Loss:  0.10610924139618874 , Time: 6757.05238199234 s\n",
      "Batch:  5190 , l1 Loss:  0.10501271411776543 , Time: 6770.1909856796265 s\n",
      "Batch:  5200 , l1 Loss:  0.10492024049162865 , Time: 6783.329192399979 s\n",
      "Batch:  5210 , l1 Loss:  0.10304370373487473 , Time: 6796.430789232254 s\n",
      "Batch:  5220 , l1 Loss:  0.10311293080449105 , Time: 6809.547966480255 s\n",
      "Batch:  5230 , l1 Loss:  0.10385258197784424 , Time: 6822.663443565369 s\n",
      "Batch:  5240 , l1 Loss:  0.10451083034276962 , Time: 6835.761467695236 s\n",
      "Batch:  5250 , l1 Loss:  0.10471171960234642 , Time: 6848.92228102684 s\n",
      "Batch:  5260 , l1 Loss:  0.10594286248087884 , Time: 6862.002052307129 s\n",
      "Batch:  5270 , l1 Loss:  0.1029449537396431 , Time: 6875.258522510529 s\n",
      "Batch:  5280 , l1 Loss:  0.10790900513529778 , Time: 6888.457004070282 s\n",
      "Batch:  5290 , l1 Loss:  0.10763044357299804 , Time: 6901.612697839737 s\n",
      "Batch:  5300 , l1 Loss:  0.10334107428789138 , Time: 6914.749623775482 s\n",
      "Batch:  5310 , l1 Loss:  0.10477396175265312 , Time: 6927.890437602997 s\n",
      "Batch:  5320 , l1 Loss:  0.1050412930548191 , Time: 6941.048941850662 s\n",
      "Batch:  5330 , l1 Loss:  0.104409559071064 , Time: 6954.186477184296 s\n",
      "Batch:  5340 , l1 Loss:  0.10762382596731186 , Time: 6967.309018135071 s\n",
      "Batch:  5350 , l1 Loss:  0.10428578928112983 , Time: 6980.4495306015015 s\n",
      "Batch:  5360 , l1 Loss:  0.10854295566678047 , Time: 6993.6138281822205 s\n",
      "Batch:  5370 , l1 Loss:  0.10387654453516007 , Time: 7006.750029325485 s\n",
      "Batch:  5380 , l1 Loss:  0.10453260764479637 , Time: 7019.867072105408 s\n",
      "Batch:  5390 , l1 Loss:  0.10463919937610626 , Time: 7033.004012584686 s\n",
      "Batch:  5400 , l1 Loss:  0.10615424588322639 , Time: 7046.140978336334 s\n",
      "Batch:  5410 , l1 Loss:  0.10353568643331527 , Time: 7059.283034324646 s\n",
      "Batch:  5420 , l1 Loss:  0.10533815175294876 , Time: 7072.423005819321 s\n",
      "Batch:  5430 , l1 Loss:  0.10513546019792556 , Time: 7085.536116361618 s\n",
      "Batch:  5440 , l1 Loss:  0.10516177043318749 , Time: 7098.670603990555 s\n",
      "Batch:  5450 , l1 Loss:  0.10614807903766632 , Time: 7111.847407341003 s\n",
      "Batch:  5460 , l1 Loss:  0.1050086721777916 , Time: 7124.944662094116 s\n",
      "Batch:  5470 , l1 Loss:  0.10543068796396256 , Time: 7138.064521551132 s\n",
      "Batch:  5480 , l1 Loss:  0.1053262174129486 , Time: 7151.199320077896 s\n",
      "Batch:  5490 , l1 Loss:  0.10431870967149734 , Time: 7164.340212345123 s\n",
      "Batch:  5500 , l1 Loss:  0.10259514302015305 , Time: 7177.456621646881 s\n",
      "Batch:  5510 , l1 Loss:  0.10527425855398179 , Time: 7190.639595746994 s\n",
      "Batch:  5520 , l1 Loss:  0.10444364696741104 , Time: 7203.7701144218445 s\n",
      "Batch:  5530 , l1 Loss:  0.10573407411575317 , Time: 7216.8674347400665 s\n",
      "Batch:  5540 , l1 Loss:  0.10655699968338013 , Time: 7230.040313005447 s\n",
      "Batch:  5550 , l1 Loss:  0.10373004525899887 , Time: 7243.138686180115 s\n",
      "Batch:  5560 , l1 Loss:  0.10668734684586526 , Time: 7256.237043142319 s\n",
      "Batch:  5570 , l1 Loss:  0.10427725538611413 , Time: 7269.352902412415 s\n",
      "Batch:  5580 , l1 Loss:  0.10569174960255623 , Time: 7282.450860261917 s\n",
      "Batch:  5590 , l1 Loss:  0.10565302148461342 , Time: 7295.545824766159 s\n",
      "Batch:  5600 , l1 Loss:  0.10306268110871315 , Time: 7308.628096103668 s\n",
      "Batch:  5610 , l1 Loss:  0.10506932139396667 , Time: 7321.745997905731 s\n",
      "Batch:  5620 , l1 Loss:  0.10679055079817772 , Time: 7334.905561447144 s\n",
      "Batch:  5630 , l1 Loss:  0.1051545687019825 , Time: 7348.0039303302765 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  5640 , l1 Loss:  0.1024406410753727 , Time: 7361.138870954514 s\n",
      "Batch:  5650 , l1 Loss:  0.10955684334039688 , Time: 7374.250108003616 s\n",
      "Batch:  5660 , l1 Loss:  0.10661673173308372 , Time: 7387.355711698532 s\n",
      "Batch:  5670 , l1 Loss:  0.10515652671456337 , Time: 7400.548562526703 s\n",
      "Batch:  5680 , l1 Loss:  0.10380772948265075 , Time: 7413.685817480087 s\n",
      "Batch:  5690 , l1 Loss:  0.10943234711885452 , Time: 7426.845082759857 s\n",
      "Batch:  5700 , l1 Loss:  0.10539023503661156 , Time: 7440.001220703125 s\n",
      "Batch:  5710 , l1 Loss:  0.10632451847195626 , Time: 7453.135695934296 s\n",
      "Batch:  5720 , l1 Loss:  0.10382528826594353 , Time: 7466.312672138214 s\n",
      "Batch:  5730 , l1 Loss:  0.10651838630437852 , Time: 7479.527826309204 s\n",
      "Batch:  5740 , l1 Loss:  0.1057260848581791 , Time: 7492.665759801865 s\n",
      "Batch:  5750 , l1 Loss:  0.10255171209573746 , Time: 7505.795810222626 s\n",
      "Batch:  5760 , l1 Loss:  0.10603666007518768 , Time: 7518.938846349716 s\n",
      "Batch:  5770 , l1 Loss:  0.10523307621479035 , Time: 7532.062557935715 s\n",
      "Batch:  5780 , l1 Loss:  0.10279866456985473 , Time: 7545.198109865189 s\n",
      "Batch:  5790 , l1 Loss:  0.10417728275060653 , Time: 7558.356626033783 s\n",
      "Batch:  5800 , l1 Loss:  0.10268554836511612 , Time: 7571.473350763321 s\n",
      "Batch:  5810 , l1 Loss:  0.10389955937862397 , Time: 7584.588095188141 s\n",
      "Batch:  5820 , l1 Loss:  0.10546944588422776 , Time: 7597.769251823425 s\n",
      "Batch:  5830 , l1 Loss:  0.10544422939419747 , Time: 7610.922224283218 s\n",
      "Batch:  5840 , l1 Loss:  0.10399430990219116 , Time: 7624.059671640396 s\n",
      "Batch:  5850 , l1 Loss:  0.1051493339240551 , Time: 7637.169710636139 s\n",
      "Batch:  5860 , l1 Loss:  0.1042363129556179 , Time: 7650.311532258987 s\n",
      "Batch:  5870 , l1 Loss:  0.10714695602655411 , Time: 7663.462630748749 s\n",
      "Batch:  5880 , l1 Loss:  0.10332236140966415 , Time: 7676.620077610016 s\n",
      "Batch:  5890 , l1 Loss:  0.10550623461604118 , Time: 7689.759417057037 s\n",
      "Batch:  5900 , l1 Loss:  0.10568496957421303 , Time: 7702.912385225296 s\n",
      "Batch:  5910 , l1 Loss:  0.10616068691015243 , Time: 7716.0943830013275 s\n",
      "Batch:  5920 , l1 Loss:  0.10407233983278275 , Time: 7729.233861446381 s\n",
      "Batch:  5930 , l1 Loss:  0.10494932755827904 , Time: 7742.3678567409515 s\n",
      "Batch:  5940 , l1 Loss:  0.10168286710977555 , Time: 7755.4923775196075 s\n",
      "Batch:  5950 , l1 Loss:  0.10681271255016327 , Time: 7768.6425766944885 s\n",
      "Batch:  5960 , l1 Loss:  0.10675883069634437 , Time: 7781.755562067032 s\n",
      "Batch:  5970 , l1 Loss:  0.1026722952723503 , Time: 7794.881246805191 s\n",
      "Batch:  5980 , l1 Loss:  0.10583489388227463 , Time: 7808.017955303192 s\n",
      "Batch:  5990 , l1 Loss:  0.10637576431035996 , Time: 7821.154155015945 s\n",
      "Batch:  6000 , l1 Loss:  0.10330466032028199 , Time: 7834.332467794418 s\n",
      "Batch:  6010 , l1 Loss:  0.10429834797978402 , Time: 7847.5353400707245 s\n",
      "Batch:  6020 , l1 Loss:  0.10434638187289239 , Time: 7860.662037372589 s\n",
      "Batch:  6030 , l1 Loss:  0.10738221704959869 , Time: 7873.802882194519 s\n",
      "Batch:  6040 , l1 Loss:  0.10871730372309685 , Time: 7886.899688959122 s\n",
      "Batch:  6050 , l1 Loss:  0.10499232038855552 , Time: 7900.013403177261 s\n",
      "Batch:  6060 , l1 Loss:  0.10583451092243194 , Time: 7913.01093006134 s\n",
      "Batch:  6070 , l1 Loss:  0.10616580545902252 , Time: 7926.017877340317 s\n",
      "Batch:  6080 , l1 Loss:  0.10612250715494156 , Time: 7939.066873073578 s\n",
      "Batch:  6090 , l1 Loss:  0.1057334691286087 , Time: 7952.185585021973 s\n",
      "Batch:  6100 , l1 Loss:  0.10539820790290833 , Time: 7965.225172042847 s\n",
      "Batch:  6110 , l1 Loss:  0.10479797795414925 , Time: 7978.318711519241 s\n",
      "Batch:  6120 , l1 Loss:  0.10365617349743843 , Time: 7991.406362056732 s\n",
      "Batch:  6130 , l1 Loss:  0.10520846024155617 , Time: 8004.488353013992 s\n",
      "Batch:  6140 , l1 Loss:  0.10715267732739449 , Time: 8017.668338775635 s\n",
      "Batch:  6150 , l1 Loss:  0.10450366288423538 , Time: 8030.927013635635 s\n",
      "Batch:  6160 , l1 Loss:  0.10276656523346901 , Time: 8044.165078878403 s\n",
      "Batch:  6170 , l1 Loss:  0.10499941185116768 , Time: 8057.363518238068 s\n",
      "Batch:  6180 , l1 Loss:  0.10362124815583229 , Time: 8070.547273159027 s\n",
      "Batch:  6190 , l1 Loss:  0.10430173575878143 , Time: 8083.644423246384 s\n",
      "Batch:  6200 , l1 Loss:  0.10537583231925965 , Time: 8096.782107114792 s\n",
      "Batch:  6210 , l1 Loss:  0.10886470898985863 , Time: 8109.917440414429 s\n",
      "Batch:  6220 , l1 Loss:  0.10549012795090676 , Time: 8123.054646015167 s\n",
      "Batch:  6230 , l1 Loss:  0.10341490805149078 , Time: 8136.173344373703 s\n",
      "Batch:  6240 , l1 Loss:  0.10343087464570999 , Time: 8149.296515226364 s\n",
      "Batch:  6250 , l1 Loss:  0.10381369516253472 , Time: 8162.436234235764 s\n",
      "Batch:  6260 , l1 Loss:  0.10503491014242172 , Time: 8175.553143501282 s\n",
      "Batch:  6270 , l1 Loss:  0.10417442917823791 , Time: 8188.712809085846 s\n",
      "Batch:  6280 , l1 Loss:  0.10334006547927857 , Time: 8201.792227268219 s\n",
      "Batch:  6290 , l1 Loss:  0.10400589406490326 , Time: 8214.846830368042 s\n",
      "Batch:  6300 , l1 Loss:  0.10484622493386268 , Time: 8227.855241060257 s\n",
      "Batch:  6310 , l1 Loss:  0.10544221997261047 , Time: 8240.92895936966 s\n",
      "Batch:  6320 , l1 Loss:  0.10325231179594993 , Time: 8253.95986199379 s\n",
      "Batch:  6330 , l1 Loss:  0.10313748642802238 , Time: 8267.020161151886 s\n",
      "Batch:  6340 , l1 Loss:  0.10231765359640121 , Time: 8280.082034826279 s\n",
      "Batch:  6350 , l1 Loss:  0.10568295419216156 , Time: 8293.13676571846 s\n",
      "Batch:  6360 , l1 Loss:  0.10399101749062538 , Time: 8306.230342388153 s\n",
      "Batch:  6370 , l1 Loss:  0.10591361373662948 , Time: 8319.325063228607 s\n",
      "Batch:  6380 , l1 Loss:  0.10461160764098168 , Time: 8332.386617660522 s\n",
      "Batch:  6390 , l1 Loss:  0.10557248070836067 , Time: 8345.466138362885 s\n",
      "Batch:  6400 , l1 Loss:  0.10420275703072548 , Time: 8358.541276931763 s\n",
      "Batch:  6410 , l1 Loss:  0.1072462998330593 , Time: 8371.603216648102 s\n",
      "Batch:  6420 , l1 Loss:  0.10476476848125457 , Time: 8384.681516170502 s\n",
      "Batch:  6430 , l1 Loss:  0.10633059665560722 , Time: 8397.760318279266 s\n",
      "Batch:  6440 , l1 Loss:  0.10632734596729279 , Time: 8410.87993812561 s\n",
      "Batch:  6450 , l1 Loss:  0.10784360468387603 , Time: 8424.058741807938 s\n",
      "Batch:  6460 , l1 Loss:  0.105943513661623 , Time: 8437.39983677864 s\n",
      "Batch:  6470 , l1 Loss:  0.10391884818673133 , Time: 8450.55796289444 s\n",
      "Batch:  6480 , l1 Loss:  0.10479047894477844 , Time: 8463.672335863113 s\n",
      "Batch:  6490 , l1 Loss:  0.10324879586696625 , Time: 8476.773864030838 s\n",
      "Batch:  6500 , l1 Loss:  0.10534662529826164 , Time: 8489.869486093521 s\n",
      "Batch:  6510 , l1 Loss:  0.10678397640585899 , Time: 8503.204337358475 s\n",
      "Batch:  6520 , l1 Loss:  0.1080576904118061 , Time: 8516.324285507202 s\n",
      "Batch:  6530 , l1 Loss:  0.1075836569070816 , Time: 8529.405055046082 s\n",
      "Batch:  6540 , l1 Loss:  0.10784848257899285 , Time: 8542.479913949966 s\n",
      "Batch:  6550 , l1 Loss:  0.10337929651141167 , Time: 8555.65912103653 s\n",
      "Batch:  6560 , l1 Loss:  0.10665265023708344 , Time: 8568.73768401146 s\n",
      "Batch:  6570 , l1 Loss:  0.1047996610403061 , Time: 8581.854149103165 s\n",
      "Batch:  6580 , l1 Loss:  0.10665700063109398 , Time: 8594.99429488182 s\n",
      "Batch:  6590 , l1 Loss:  0.10583433359861374 , Time: 8608.11859703064 s\n",
      "Batch:  6600 , l1 Loss:  0.10687301456928253 , Time: 8621.233352899551 s\n",
      "Batch:  6610 , l1 Loss:  0.11063146293163299 , Time: 8634.371196269989 s\n",
      "Batch:  6620 , l1 Loss:  0.10188871771097183 , Time: 8647.464751243591 s\n",
      "Batch:  6630 , l1 Loss:  0.10366001054644584 , Time: 8660.566712856293 s\n",
      "Batch:  6640 , l1 Loss:  0.1028207890689373 , Time: 8673.730237722397 s\n",
      "Batch:  6650 , l1 Loss:  0.10322943031787872 , Time: 8686.842709302902 s\n",
      "Batch:  6660 , l1 Loss:  0.10386847704648972 , Time: 8699.930619001389 s\n",
      "Batch:  6670 , l1 Loss:  0.10530608743429185 , Time: 8713.064038515091 s\n",
      "Batch:  6680 , l1 Loss:  0.1056733138859272 , Time: 8726.179680585861 s\n",
      "Batch:  6690 , l1 Loss:  0.10722239464521408 , Time: 8739.26584815979 s\n",
      "Batch:  6700 , l1 Loss:  0.10603375360369682 , Time: 8752.385086536407 s\n",
      "Batch:  6710 , l1 Loss:  0.10505894124507904 , Time: 8765.503391981125 s\n",
      "Batch:  6720 , l1 Loss:  0.10601471960544587 , Time: 8778.602642297745 s\n",
      "Batch:  6730 , l1 Loss:  0.10264437198638916 , Time: 8791.757015705109 s\n",
      "Batch:  6740 , l1 Loss:  0.10476361066102982 , Time: 8804.857835292816 s\n",
      "Batch:  6750 , l1 Loss:  0.10463315472006798 , Time: 8817.959543943405 s\n",
      "Batch:  6760 , l1 Loss:  0.10499227792024612 , Time: 8831.061949968338 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  6770 , l1 Loss:  0.10537129342556 , Time: 8844.178131341934 s\n",
      "Batch:  6780 , l1 Loss:  0.10393856465816498 , Time: 8857.294424533844 s\n",
      "Batch:  6790 , l1 Loss:  0.10471213459968567 , Time: 8870.41519832611 s\n",
      "Batch:  6800 , l1 Loss:  0.1028789222240448 , Time: 8883.536967515945 s\n",
      "Batch:  6810 , l1 Loss:  0.10454447194933891 , Time: 8896.652315378189 s\n",
      "Batch:  6820 , l1 Loss:  0.1057123564183712 , Time: 8909.815384626389 s\n",
      "Batch:  6830 , l1 Loss:  0.10196040347218513 , Time: 8922.93256521225 s\n",
      "Batch:  6840 , l1 Loss:  0.10286107212305069 , Time: 8936.031563282013 s\n",
      "Batch:  6850 , l1 Loss:  0.10393947660923004 , Time: 8949.195801496506 s\n",
      "Batch:  6860 , l1 Loss:  0.10615792125463486 , Time: 8962.330397844315 s\n",
      "Batch:  6870 , l1 Loss:  0.10373349264264106 , Time: 8975.467922449112 s\n",
      "Batch:  6880 , l1 Loss:  0.10336619317531585 , Time: 8988.605613708496 s\n",
      "Batch:  6890 , l1 Loss:  0.10348541662096977 , Time: 9001.743015527725 s\n",
      "Batch:  6900 , l1 Loss:  0.10432492569088936 , Time: 9014.88297176361 s\n",
      "Batch:  6910 , l1 Loss:  0.10463434979319572 , Time: 9028.026898145676 s\n",
      "Batch:  6920 , l1 Loss:  0.10506886467337609 , Time: 9041.181891441345 s\n",
      "Batch:  6930 , l1 Loss:  0.10535201504826545 , Time: 9054.31535935402 s\n",
      "Batch:  6940 , l1 Loss:  0.10410989001393318 , Time: 9067.42959356308 s\n",
      "Batch:  6950 , l1 Loss:  0.10380599275231361 , Time: 9080.508947610855 s\n",
      "Batch:  6960 , l1 Loss:  0.10522180199623107 , Time: 9093.767053842545 s\n",
      "Batch:  6970 , l1 Loss:  0.1047927476465702 , Time: 9107.00186753273 s\n",
      "Batch:  6980 , l1 Loss:  0.10655718371272087 , Time: 9120.23692703247 s\n",
      "Batch:  6990 , l1 Loss:  0.10415607467293739 , Time: 9133.454626321793 s\n",
      "Batch:  7000 , l1 Loss:  0.10276669189333916 , Time: 9146.673688650131 s\n",
      "Batch:  7010 , l1 Loss:  0.10608731359243392 , Time: 9159.956453800201 s\n",
      "Batch:  7020 , l1 Loss:  0.10523143261671067 , Time: 9173.150533437729 s\n",
      "Epoch:  0 , l1 loss:  0.11107707029772851\n",
      "Epoch:  1\n",
      "Batch:  10 , l1 Loss:  0.10031325708736073 , Time: 9191.962783813477 s\n",
      "Batch:  20 , l1 Loss:  0.10448958501219749 , Time: 9204.920389413834 s\n",
      "Batch:  30 , l1 Loss:  0.10170193836092949 , Time: 9217.902334213257 s\n",
      "Batch:  40 , l1 Loss:  0.10759710296988487 , Time: 9230.940024614334 s\n",
      "Batch:  50 , l1 Loss:  0.10505487620830536 , Time: 9243.975699186325 s\n",
      "Batch:  60 , l1 Loss:  0.10150379166007042 , Time: 9257.035913944244 s\n",
      "Batch:  70 , l1 Loss:  0.107195133715868 , Time: 9270.160814762115 s\n",
      "Batch:  80 , l1 Loss:  0.10531339570879936 , Time: 9283.239303827286 s\n",
      "Batch:  90 , l1 Loss:  0.1028466708958149 , Time: 9296.296606302261 s\n",
      "Batch:  100 , l1 Loss:  0.10617506355047227 , Time: 9309.376802921295 s\n",
      "Batch:  110 , l1 Loss:  0.103854451328516 , Time: 9322.45602440834 s\n",
      "Batch:  120 , l1 Loss:  0.10550780072808266 , Time: 9335.496924161911 s\n",
      "Batch:  130 , l1 Loss:  0.10651256814599037 , Time: 9348.619774580002 s\n",
      "Batch:  140 , l1 Loss:  0.10596300140023232 , Time: 9361.70048379898 s\n",
      "Batch:  150 , l1 Loss:  0.10304524824023246 , Time: 9374.781940698624 s\n",
      "Batch:  160 , l1 Loss:  0.10434384420514106 , Time: 9387.861082077026 s\n",
      "Batch:  170 , l1 Loss:  0.10328576564788819 , Time: 9400.982206821442 s\n",
      "Batch:  180 , l1 Loss:  0.10245293602347375 , Time: 9414.05045056343 s\n",
      "Batch:  190 , l1 Loss:  0.10483419448137284 , Time: 9427.167902469635 s\n",
      "Batch:  200 , l1 Loss:  0.10388399213552475 , Time: 9440.227469444275 s\n",
      "Batch:  210 , l1 Loss:  0.10553842857480049 , Time: 9453.305534601212 s\n",
      "Batch:  220 , l1 Loss:  0.10238654538989067 , Time: 9466.402811288834 s\n",
      "Batch:  230 , l1 Loss:  0.10547422915697098 , Time: 9479.500964164734 s\n",
      "Batch:  240 , l1 Loss:  0.10601713731884957 , Time: 9492.560751914978 s\n",
      "Batch:  250 , l1 Loss:  0.10670164823532105 , Time: 9505.660154104233 s\n",
      "Batch:  260 , l1 Loss:  0.10499803870916366 , Time: 9518.860806941986 s\n",
      "Batch:  270 , l1 Loss:  0.10450382754206658 , Time: 9531.960824012756 s\n",
      "Batch:  280 , l1 Loss:  0.10110382363200188 , Time: 9545.102648735046 s\n",
      "Batch:  290 , l1 Loss:  0.10382360517978668 , Time: 9558.246612548828 s\n",
      "Batch:  300 , l1 Loss:  0.10236622244119645 , Time: 9571.374543905258 s\n",
      "Batch:  310 , l1 Loss:  0.1040765330195427 , Time: 9584.493611812592 s\n",
      "Batch:  320 , l1 Loss:  0.10220380276441574 , Time: 9597.609078168869 s\n",
      "Batch:  330 , l1 Loss:  0.10145118907094001 , Time: 9610.705753326416 s\n",
      "Batch:  340 , l1 Loss:  0.10439075380563737 , Time: 9623.810376644135 s\n",
      "Batch:  350 , l1 Loss:  0.10289743021130562 , Time: 9636.950992107391 s\n",
      "Batch:  360 , l1 Loss:  0.10222125723958016 , Time: 9650.067621946335 s\n",
      "Batch:  370 , l1 Loss:  0.10379674211144448 , Time: 9663.122002840042 s\n",
      "Batch:  380 , l1 Loss:  0.10207853242754936 , Time: 9676.181138515472 s\n",
      "Batch:  390 , l1 Loss:  0.10504045337438583 , Time: 9689.244400501251 s\n",
      "Batch:  400 , l1 Loss:  0.10392122194170952 , Time: 9702.299838542938 s\n",
      "Batch:  410 , l1 Loss:  0.10448811054229737 , Time: 9715.335915088654 s\n",
      "Batch:  420 , l1 Loss:  0.1038709506392479 , Time: 9728.410029888153 s\n",
      "Batch:  430 , l1 Loss:  0.10580871999263763 , Time: 9741.4487490654 s\n",
      "Batch:  440 , l1 Loss:  0.10417921841144562 , Time: 9754.529423236847 s\n",
      "Batch:  450 , l1 Loss:  0.10493483990430832 , Time: 9767.589181900024 s\n",
      "Batch:  460 , l1 Loss:  0.10417004823684692 , Time: 9780.620684146881 s\n",
      "Batch:  470 , l1 Loss:  0.10441374778747559 , Time: 9793.639300346375 s\n",
      "Batch:  480 , l1 Loss:  0.10347313582897186 , Time: 9806.63903093338 s\n",
      "Batch:  490 , l1 Loss:  0.10330183655023575 , Time: 9819.659565925598 s\n",
      "Batch:  500 , l1 Loss:  0.10262111872434616 , Time: 9832.667283773422 s\n",
      "Batch:  510 , l1 Loss:  0.10170120000839233 , Time: 9845.68539571762 s\n",
      "Batch:  520 , l1 Loss:  0.10531141236424446 , Time: 9858.650608301163 s\n",
      "Batch:  530 , l1 Loss:  0.10276316553354263 , Time: 9871.701712608337 s\n",
      "Batch:  540 , l1 Loss:  0.104486283659935 , Time: 9884.643242359161 s\n",
      "Batch:  550 , l1 Loss:  0.10279381722211837 , Time: 9897.582206010818 s\n",
      "Batch:  560 , l1 Loss:  0.10408890917897225 , Time: 9910.554603815079 s\n",
      "Batch:  570 , l1 Loss:  0.1035946749150753 , Time: 9923.507069587708 s\n",
      "Batch:  580 , l1 Loss:  0.10168160647153854 , Time: 9936.465318918228 s\n",
      "Batch:  590 , l1 Loss:  0.10415038540959358 , Time: 9949.444064855576 s\n",
      "Batch:  600 , l1 Loss:  0.10427994132041932 , Time: 9962.385247945786 s\n",
      "Batch:  610 , l1 Loss:  0.10625070929527283 , Time: 9975.321024656296 s\n",
      "Batch:  620 , l1 Loss:  0.10499830543994904 , Time: 9988.282653808594 s\n",
      "Batch:  630 , l1 Loss:  0.10940909236669541 , Time: 10001.198618412018 s\n",
      "Batch:  640 , l1 Loss:  0.10760260969400406 , Time: 10014.11928153038 s\n",
      "Batch:  650 , l1 Loss:  0.10479943603277206 , Time: 10027.036118745804 s\n",
      "Batch:  660 , l1 Loss:  0.10521090775728226 , Time: 10039.991970062256 s\n",
      "Batch:  670 , l1 Loss:  0.10903205275535584 , Time: 10052.87379360199 s\n",
      "Batch:  680 , l1 Loss:  0.10542752891778946 , Time: 10065.748522043228 s\n",
      "Batch:  690 , l1 Loss:  0.10351012200117111 , Time: 10078.630451440811 s\n",
      "Batch:  700 , l1 Loss:  0.10530239939689637 , Time: 10091.528087377548 s\n",
      "Batch:  710 , l1 Loss:  0.10500703603029252 , Time: 10104.404398679733 s\n",
      "Batch:  720 , l1 Loss:  0.10248596295714378 , Time: 10117.32197022438 s\n",
      "Batch:  730 , l1 Loss:  0.10348277539014816 , Time: 10130.197697877884 s\n",
      "Batch:  740 , l1 Loss:  0.10291026160120964 , Time: 10143.06194639206 s\n",
      "Batch:  750 , l1 Loss:  0.10536914691329002 , Time: 10155.951069831848 s\n",
      "Batch:  760 , l1 Loss:  0.10443426966667176 , Time: 10168.808958768845 s\n",
      "Batch:  770 , l1 Loss:  0.1039078675210476 , Time: 10181.704632282257 s\n",
      "Batch:  780 , l1 Loss:  0.1059371791779995 , Time: 10194.59927368164 s\n",
      "Batch:  790 , l1 Loss:  0.10342530161142349 , Time: 10207.494250535965 s\n",
      "Batch:  800 , l1 Loss:  0.10552239865064621 , Time: 10220.425290822983 s\n",
      "Batch:  810 , l1 Loss:  0.10257931128144264 , Time: 10233.372258901596 s\n",
      "Batch:  820 , l1 Loss:  0.1029060885310173 , Time: 10246.293179273605 s\n",
      "Batch:  830 , l1 Loss:  0.10307709500193596 , Time: 10259.198946714401 s\n",
      "Batch:  840 , l1 Loss:  0.10298155546188355 , Time: 10272.07698559761 s\n",
      "Batch:  850 , l1 Loss:  0.10452226400375367 , Time: 10284.973213672638 s\n",
      "Batch:  860 , l1 Loss:  0.10316186919808387 , Time: 10297.894612789154 s\n",
      "Batch:  870 , l1 Loss:  0.10490800365805626 , Time: 10310.985841989517 s\n",
      "Batch:  880 , l1 Loss:  0.10471469834446907 , Time: 10324.021286010742 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  890 , l1 Loss:  0.10234321877360344 , Time: 10337.017402887344 s\n",
      "Batch:  900 , l1 Loss:  0.10431804656982421 , Time: 10350.133598566055 s\n",
      "Batch:  910 , l1 Loss:  0.10298867970705032 , Time: 10363.130765676498 s\n",
      "Batch:  920 , l1 Loss:  0.1082956239581108 , Time: 10376.161674261093 s\n",
      "Batch:  930 , l1 Loss:  0.10528303012251854 , Time: 10389.121956586838 s\n",
      "Batch:  940 , l1 Loss:  0.10320260748267174 , Time: 10402.074187994003 s\n",
      "Batch:  950 , l1 Loss:  0.10965722724795342 , Time: 10415.043492555618 s\n",
      "Batch:  960 , l1 Loss:  0.10305386409163475 , Time: 10428.019608020782 s\n",
      "Batch:  970 , l1 Loss:  0.10790353566408158 , Time: 10440.956770420074 s\n",
      "Batch:  980 , l1 Loss:  0.10456297993659973 , Time: 10453.730530023575 s\n",
      "Batch:  990 , l1 Loss:  0.10593241825699806 , Time: 10466.544493198395 s\n",
      "Batch:  1000 , l1 Loss:  0.1028931774199009 , Time: 10479.418792009354 s\n",
      "Batch:  1010 , l1 Loss:  0.10792988017201424 , Time: 10492.934875011444 s\n",
      "Batch:  1020 , l1 Loss:  0.10244600474834442 , Time: 10507.214683294296 s\n",
      "Batch:  1030 , l1 Loss:  0.10174955129623413 , Time: 10521.227172851562 s\n",
      "Batch:  1040 , l1 Loss:  0.102756816893816 , Time: 10535.698792696 s\n",
      "Batch:  1050 , l1 Loss:  0.10329287722706795 , Time: 10550.334776639938 s\n",
      "Batch:  1060 , l1 Loss:  0.1030617043375969 , Time: 10565.34767127037 s\n",
      "Batch:  1070 , l1 Loss:  0.10212699100375175 , Time: 10579.98624253273 s\n",
      "Batch:  1080 , l1 Loss:  0.10244535580277443 , Time: 10594.160805940628 s\n",
      "Batch:  1090 , l1 Loss:  0.10454536974430084 , Time: 10608.736882686615 s\n",
      "Batch:  1100 , l1 Loss:  0.10478604733943939 , Time: 10623.1670358181 s\n",
      "Batch:  1110 , l1 Loss:  0.10429840683937072 , Time: 10637.96491599083 s\n",
      "Batch:  1120 , l1 Loss:  0.10638908818364143 , Time: 10653.877526760101 s\n",
      "Batch:  1130 , l1 Loss:  0.10915569216012955 , Time: 10668.163899183273 s\n",
      "Batch:  1140 , l1 Loss:  0.10795233100652694 , Time: 10682.463893651962 s\n",
      "Batch:  1150 , l1 Loss:  0.10666917264461517 , Time: 10697.519015789032 s\n",
      "Batch:  1160 , l1 Loss:  0.10574263259768486 , Time: 10711.931422472 s\n",
      "Batch:  1170 , l1 Loss:  0.10535735860466958 , Time: 10726.85636138916 s\n",
      "Batch:  1180 , l1 Loss:  0.10518218949437141 , Time: 10741.05040717125 s\n",
      "Batch:  1190 , l1 Loss:  0.10490251407027244 , Time: 10755.37032699585 s\n",
      "Batch:  1200 , l1 Loss:  0.10493432208895684 , Time: 10770.232999801636 s\n",
      "Batch:  1210 , l1 Loss:  0.10448461398482323 , Time: 10785.074923753738 s\n",
      "Batch:  1220 , l1 Loss:  0.10734846889972686 , Time: 10799.543250083923 s\n",
      "Batch:  1230 , l1 Loss:  0.10405381172895431 , Time: 10814.628724336624 s\n",
      "Batch:  1240 , l1 Loss:  0.10314410105347634 , Time: 10829.235388755798 s\n",
      "Batch:  1250 , l1 Loss:  0.10527669489383698 , Time: 10843.946424484253 s\n",
      "Batch:  1260 , l1 Loss:  0.10163675174117089 , Time: 10858.202891588211 s\n",
      "Batch:  1270 , l1 Loss:  0.10238049402832985 , Time: 10873.068552732468 s\n",
      "Batch:  1280 , l1 Loss:  0.1075083389878273 , Time: 10887.453964233398 s\n",
      "Batch:  1290 , l1 Loss:  0.10615091770887375 , Time: 10901.935605049133 s\n",
      "Batch:  1300 , l1 Loss:  0.10519994050264359 , Time: 10916.628223657608 s\n",
      "Batch:  1310 , l1 Loss:  0.10574594736099244 , Time: 10931.503077030182 s\n",
      "Batch:  1320 , l1 Loss:  0.10607577040791512 , Time: 10946.165702819824 s\n",
      "Batch:  1330 , l1 Loss:  0.10509630516171456 , Time: 10961.203079938889 s\n",
      "Batch:  1340 , l1 Loss:  0.10692097023129463 , Time: 10976.23363661766 s\n",
      "Batch:  1350 , l1 Loss:  0.10573438927531242 , Time: 10990.839903831482 s\n",
      "Batch:  1360 , l1 Loss:  0.10523651689291 , Time: 11005.079045534134 s\n",
      "Batch:  1370 , l1 Loss:  0.10640525370836258 , Time: 11019.204204797745 s\n",
      "Batch:  1380 , l1 Loss:  0.10388738811016082 , Time: 11033.437553167343 s\n",
      "Batch:  1390 , l1 Loss:  0.10349837243556977 , Time: 11047.539528608322 s\n",
      "Batch:  1400 , l1 Loss:  0.10354567244648934 , Time: 11061.801558494568 s\n",
      "Batch:  1410 , l1 Loss:  0.10250636711716651 , Time: 11076.057719945908 s\n",
      "Batch:  1420 , l1 Loss:  0.10693448707461357 , Time: 11090.30355334282 s\n",
      "Batch:  1430 , l1 Loss:  0.10409187823534012 , Time: 11104.223873615265 s\n",
      "Batch:  1440 , l1 Loss:  0.10370712950825692 , Time: 11118.33087849617 s\n",
      "Batch:  1450 , l1 Loss:  0.10355077311396599 , Time: 11132.458281993866 s\n",
      "Batch:  1460 , l1 Loss:  0.10453339591622353 , Time: 11146.455157518387 s\n",
      "Batch:  1470 , l1 Loss:  0.10397699028253556 , Time: 11160.55613732338 s\n",
      "Batch:  1480 , l1 Loss:  0.10382608696818352 , Time: 11174.75494670868 s\n",
      "Batch:  1490 , l1 Loss:  0.10219067260622978 , Time: 11188.982891082764 s\n",
      "Batch:  1500 , l1 Loss:  0.1043932557106018 , Time: 11203.337156772614 s\n",
      "Batch:  1510 , l1 Loss:  0.10281340107321739 , Time: 11217.708702802658 s\n",
      "Batch:  1520 , l1 Loss:  0.104282096773386 , Time: 11231.816456079483 s\n",
      "Batch:  1530 , l1 Loss:  0.10457130894064903 , Time: 11245.715208768845 s\n",
      "Batch:  1540 , l1 Loss:  0.10604062154889107 , Time: 11259.939067602158 s\n",
      "Batch:  1550 , l1 Loss:  0.10389309078454971 , Time: 11274.271401882172 s\n",
      "Batch:  1560 , l1 Loss:  0.10473741590976715 , Time: 11288.38574385643 s\n",
      "Batch:  1570 , l1 Loss:  0.10332820117473603 , Time: 11302.692504405975 s\n",
      "Batch:  1580 , l1 Loss:  0.10501945093274116 , Time: 11317.26904296875 s\n",
      "Batch:  1590 , l1 Loss:  0.10248309150338172 , Time: 11331.80229306221 s\n",
      "Batch:  1600 , l1 Loss:  0.10153174623847008 , Time: 11346.528533220291 s\n",
      "Batch:  1610 , l1 Loss:  0.10393141731619834 , Time: 11360.589195013046 s\n",
      "Batch:  1620 , l1 Loss:  0.10470219403505325 , Time: 11374.973510026932 s\n",
      "Batch:  1630 , l1 Loss:  0.10421420186758042 , Time: 11389.187793970108 s\n",
      "Batch:  1640 , l1 Loss:  0.1089853972196579 , Time: 11403.311231136322 s\n",
      "Batch:  1650 , l1 Loss:  0.10392727479338645 , Time: 11417.260347127914 s\n",
      "Batch:  1660 , l1 Loss:  0.10606172382831573 , Time: 11431.28122472763 s\n",
      "Batch:  1670 , l1 Loss:  0.10357178300619126 , Time: 11445.339438438416 s\n",
      "Batch:  1680 , l1 Loss:  0.10382106602191925 , Time: 11459.33548951149 s\n",
      "Batch:  1690 , l1 Loss:  0.10300025790929794 , Time: 11473.32153916359 s\n",
      "Batch:  1700 , l1 Loss:  0.10199836418032646 , Time: 11487.299371004105 s\n",
      "Batch:  1710 , l1 Loss:  0.10226546078920365 , Time: 11501.262386798859 s\n",
      "Batch:  1720 , l1 Loss:  0.10466643497347831 , Time: 11515.204803943634 s\n",
      "Batch:  1730 , l1 Loss:  0.10205436572432518 , Time: 11529.121773958206 s\n",
      "Batch:  1740 , l1 Loss:  0.10560503751039504 , Time: 11543.007497787476 s\n",
      "Batch:  1750 , l1 Loss:  0.10415275916457176 , Time: 11556.932474374771 s\n",
      "Batch:  1760 , l1 Loss:  0.10362889468669892 , Time: 11570.854291677475 s\n",
      "Batch:  1770 , l1 Loss:  0.10508790910243988 , Time: 11584.776999950409 s\n",
      "Batch:  1780 , l1 Loss:  0.10476382970809936 , Time: 11598.650307655334 s\n",
      "Batch:  1790 , l1 Loss:  0.10419587269425393 , Time: 11612.605583906174 s\n",
      "Batch:  1800 , l1 Loss:  0.10471336469054222 , Time: 11626.512512683868 s\n",
      "Batch:  1810 , l1 Loss:  0.10453726798295974 , Time: 11640.347347736359 s\n",
      "Batch:  1820 , l1 Loss:  0.10368902534246445 , Time: 11654.229359865189 s\n",
      "Batch:  1830 , l1 Loss:  0.10479266867041588 , Time: 11667.999962568283 s\n",
      "Batch:  1840 , l1 Loss:  0.10251328870654106 , Time: 11681.141498565674 s\n",
      "Batch:  1850 , l1 Loss:  0.10506476387381554 , Time: 11694.274957180023 s\n",
      "Batch:  1860 , l1 Loss:  0.10314946323633194 , Time: 11707.339346408844 s\n",
      "Batch:  1870 , l1 Loss:  0.10488455444574356 , Time: 11720.39741063118 s\n",
      "Batch:  1880 , l1 Loss:  0.10266405045986175 , Time: 11733.474927663803 s\n",
      "Batch:  1890 , l1 Loss:  0.10161330997943878 , Time: 11746.573636054993 s\n",
      "Batch:  1900 , l1 Loss:  0.1041600912809372 , Time: 11759.63460111618 s\n",
      "Batch:  1910 , l1 Loss:  0.10499228611588478 , Time: 11772.746765136719 s\n",
      "Batch:  1920 , l1 Loss:  0.10471791997551919 , Time: 11785.845975160599 s\n",
      "Batch:  1930 , l1 Loss:  0.10445829778909684 , Time: 11799.024354934692 s\n",
      "Batch:  1940 , l1 Loss:  0.10489358752965927 , Time: 11812.077080011368 s\n",
      "Batch:  1950 , l1 Loss:  0.10470255017280579 , Time: 11825.15317606926 s\n",
      "Batch:  1960 , l1 Loss:  0.10338135212659835 , Time: 11838.187919855118 s\n",
      "Batch:  1970 , l1 Loss:  0.10398277565836907 , Time: 11851.24724316597 s\n",
      "Batch:  1980 , l1 Loss:  0.10303715988993645 , Time: 11864.277768611908 s\n",
      "Batch:  1990 , l1 Loss:  0.10324023365974426 , Time: 11877.307779312134 s\n",
      "Batch:  2000 , l1 Loss:  0.10304487273097038 , Time: 11890.353815317154 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  2010 , l1 Loss:  0.10252778232097626 , Time: 11903.433548927307 s\n",
      "Batch:  2020 , l1 Loss:  0.10250156596302987 , Time: 11916.52677154541 s\n",
      "Batch:  2030 , l1 Loss:  0.10259456112980843 , Time: 11929.56952548027 s\n",
      "Batch:  2040 , l1 Loss:  0.10104589909315109 , Time: 11942.52896118164 s\n",
      "Batch:  2050 , l1 Loss:  0.10344970375299453 , Time: 11955.461243629456 s\n",
      "Batch:  2060 , l1 Loss:  0.10299953371286392 , Time: 11968.43947172165 s\n",
      "Batch:  2070 , l1 Loss:  0.1029331423342228 , Time: 11981.437920331955 s\n",
      "Batch:  2080 , l1 Loss:  0.10368879288434982 , Time: 11994.474351167679 s\n",
      "Batch:  2090 , l1 Loss:  0.1049007959663868 , Time: 12007.453614711761 s\n",
      "Batch:  2100 , l1 Loss:  0.10444119200110435 , Time: 12020.453511476517 s\n",
      "Batch:  2110 , l1 Loss:  0.10319137275218963 , Time: 12033.49183177948 s\n",
      "Batch:  2120 , l1 Loss:  0.10318803191184997 , Time: 12046.469720602036 s\n",
      "Batch:  2130 , l1 Loss:  0.10210988074541091 , Time: 12059.472611427307 s\n",
      "Batch:  2140 , l1 Loss:  0.10176787748932839 , Time: 12072.474096775055 s\n",
      "Batch:  2150 , l1 Loss:  0.10127064064145089 , Time: 12085.449156999588 s\n",
      "Batch:  2160 , l1 Loss:  0.10689144060015679 , Time: 12098.487142801285 s\n",
      "Batch:  2170 , l1 Loss:  0.10545760467648506 , Time: 12111.488592386246 s\n",
      "Batch:  2180 , l1 Loss:  0.10555464401841164 , Time: 12124.490708351135 s\n",
      "Batch:  2190 , l1 Loss:  0.10642168149352074 , Time: 12137.521936655045 s\n",
      "Batch:  2200 , l1 Loss:  0.1013050228357315 , Time: 12150.56534409523 s\n",
      "Batch:  2210 , l1 Loss:  0.10249182283878326 , Time: 12163.579132318497 s\n",
      "Batch:  2220 , l1 Loss:  0.10275916755199432 , Time: 12176.580353021622 s\n",
      "Batch:  2230 , l1 Loss:  0.10341486036777496 , Time: 12189.618484258652 s\n",
      "Batch:  2240 , l1 Loss:  0.10382423400878907 , Time: 12202.637456655502 s\n",
      "Batch:  2250 , l1 Loss:  0.10328656286001206 , Time: 12215.673740386963 s\n",
      "Batch:  2260 , l1 Loss:  0.10554587543010711 , Time: 12228.692234277725 s\n",
      "Batch:  2270 , l1 Loss:  0.10476774275302887 , Time: 12241.711860179901 s\n",
      "Batch:  2280 , l1 Loss:  0.10382325425744057 , Time: 12254.733070135117 s\n",
      "Batch:  2290 , l1 Loss:  0.10469429418444634 , Time: 12267.790620326996 s\n",
      "Batch:  2300 , l1 Loss:  0.10375205054879189 , Time: 12280.8698720932 s\n",
      "Batch:  2310 , l1 Loss:  0.10489247143268585 , Time: 12293.887746572495 s\n",
      "Batch:  2320 , l1 Loss:  0.1024462640285492 , Time: 12306.910707235336 s\n",
      "Batch:  2330 , l1 Loss:  0.10280074328184127 , Time: 12319.983845710754 s\n",
      "Batch:  2340 , l1 Loss:  0.10246286392211915 , Time: 12333.044281959534 s\n",
      "Batch:  2350 , l1 Loss:  0.1012167863547802 , Time: 12346.09435415268 s\n",
      "Batch:  2360 , l1 Loss:  0.10198766440153122 , Time: 12359.117954015732 s\n",
      "Batch:  2370 , l1 Loss:  0.1034916304051876 , Time: 12372.131071090698 s\n",
      "Batch:  2380 , l1 Loss:  0.10391266718506813 , Time: 12385.136740207672 s\n",
      "Batch:  2390 , l1 Loss:  0.10206313133239746 , Time: 12398.231246948242 s\n",
      "Batch:  2400 , l1 Loss:  0.10153209418058395 , Time: 12411.269383907318 s\n",
      "Batch:  2410 , l1 Loss:  0.10433914139866829 , Time: 12424.263366222382 s\n",
      "Batch:  2420 , l1 Loss:  0.10370624214410781 , Time: 12437.282438516617 s\n",
      "Batch:  2430 , l1 Loss:  0.10150177255272866 , Time: 12450.314395189285 s\n",
      "Batch:  2440 , l1 Loss:  0.10101192072033882 , Time: 12463.298357248306 s\n",
      "Batch:  2450 , l1 Loss:  0.10305599495768547 , Time: 12476.277535438538 s\n",
      "Batch:  2460 , l1 Loss:  0.10453380942344666 , Time: 12489.270840644836 s\n",
      "Batch:  2470 , l1 Loss:  0.10372884869575501 , Time: 12502.247892141342 s\n",
      "Batch:  2480 , l1 Loss:  0.10338481217622757 , Time: 12515.584955453873 s\n",
      "Batch:  2490 , l1 Loss:  0.10253721624612808 , Time: 12528.639314174652 s\n",
      "Batch:  2500 , l1 Loss:  0.1014790914952755 , Time: 12541.632917404175 s\n",
      "Batch:  2510 , l1 Loss:  0.10364520028233529 , Time: 12554.651166677475 s\n",
      "Batch:  2520 , l1 Loss:  0.10056835785508156 , Time: 12567.626478672028 s\n",
      "Batch:  2530 , l1 Loss:  0.10739734470844269 , Time: 12580.72094321251 s\n",
      "Batch:  2540 , l1 Loss:  0.10480030849575997 , Time: 12593.783940315247 s\n",
      "Batch:  2550 , l1 Loss:  0.10419128462672234 , Time: 12606.798192024231 s\n",
      "Batch:  2560 , l1 Loss:  0.10747501850128174 , Time: 12619.832514286041 s\n",
      "Batch:  2570 , l1 Loss:  0.1041374072432518 , Time: 12632.870139598846 s\n",
      "Batch:  2580 , l1 Loss:  0.10372371897101403 , Time: 12645.888183832169 s\n",
      "Batch:  2590 , l1 Loss:  0.10397621765732765 , Time: 12658.863951444626 s\n",
      "Batch:  2600 , l1 Loss:  0.10417103096842766 , Time: 12671.863011360168 s\n",
      "Batch:  2610 , l1 Loss:  0.10262963995337486 , Time: 12684.885845661163 s\n",
      "Batch:  2620 , l1 Loss:  0.10411715060472489 , Time: 12697.886389255524 s\n",
      "Batch:  2630 , l1 Loss:  0.1033052772283554 , Time: 12710.879962444305 s\n",
      "Batch:  2640 , l1 Loss:  0.1022143580019474 , Time: 12723.926151514053 s\n",
      "Batch:  2650 , l1 Loss:  0.10160421580076218 , Time: 12736.891661405563 s\n",
      "Batch:  2660 , l1 Loss:  0.10498726069927215 , Time: 12749.920466423035 s\n",
      "Batch:  2670 , l1 Loss:  0.10077806189656258 , Time: 12762.92341017723 s\n",
      "Batch:  2680 , l1 Loss:  0.10060297623276711 , Time: 12775.906733989716 s\n",
      "Batch:  2690 , l1 Loss:  0.10445526391267776 , Time: 12788.888623952866 s\n",
      "Batch:  2700 , l1 Loss:  0.10316915288567544 , Time: 12801.901627540588 s\n",
      "Batch:  2710 , l1 Loss:  0.10533242598176003 , Time: 12814.876478672028 s\n",
      "Batch:  2720 , l1 Loss:  0.10150663256645202 , Time: 12827.89068698883 s\n",
      "Batch:  2730 , l1 Loss:  0.10177295282483101 , Time: 12840.869573354721 s\n",
      "Batch:  2740 , l1 Loss:  0.10127801895141601 , Time: 12853.889988899231 s\n",
      "Batch:  2750 , l1 Loss:  0.10231662690639495 , Time: 12866.883470535278 s\n",
      "Batch:  2760 , l1 Loss:  0.10314079374074936 , Time: 12879.88259601593 s\n",
      "Batch:  2770 , l1 Loss:  0.10214620158076286 , Time: 12892.796738624573 s\n",
      "Batch:  2780 , l1 Loss:  0.10222914516925811 , Time: 12905.774335861206 s\n",
      "Batch:  2790 , l1 Loss:  0.10416017398238182 , Time: 12918.753934144974 s\n",
      "Batch:  2800 , l1 Loss:  0.10451706424355507 , Time: 12931.725571632385 s\n",
      "Batch:  2810 , l1 Loss:  0.10407027378678321 , Time: 12944.682200670242 s\n",
      "Batch:  2820 , l1 Loss:  0.1037610650062561 , Time: 12957.635761976242 s\n",
      "Batch:  2830 , l1 Loss:  0.10353458523750306 , Time: 12970.591489553452 s\n",
      "Batch:  2840 , l1 Loss:  0.10311776623129845 , Time: 12983.524186611176 s\n",
      "Batch:  2850 , l1 Loss:  0.10080456361174583 , Time: 12996.54496216774 s\n",
      "Batch:  2860 , l1 Loss:  0.10141071602702141 , Time: 13009.499103307724 s\n",
      "Batch:  2870 , l1 Loss:  0.10526772886514664 , Time: 13022.477008342743 s\n",
      "Batch:  2880 , l1 Loss:  0.10580537095665932 , Time: 13035.434584617615 s\n",
      "Batch:  2890 , l1 Loss:  0.10369610786437988 , Time: 13048.428467035294 s\n",
      "Batch:  2900 , l1 Loss:  0.10288717001676559 , Time: 13061.367449760437 s\n",
      "Batch:  2910 , l1 Loss:  0.10267469882965088 , Time: 13074.394269943237 s\n",
      "Batch:  2920 , l1 Loss:  0.10523568168282509 , Time: 13087.488692522049 s\n",
      "Batch:  2930 , l1 Loss:  0.10314248576760292 , Time: 13100.508196115494 s\n",
      "Batch:  2940 , l1 Loss:  0.10496718361973763 , Time: 13113.562247753143 s\n",
      "Batch:  2950 , l1 Loss:  0.10519694462418556 , Time: 13126.567831754684 s\n",
      "Batch:  2960 , l1 Loss:  0.10435726195573806 , Time: 13139.622650384903 s\n",
      "Batch:  2970 , l1 Loss:  0.10357884839177131 , Time: 13152.602304458618 s\n",
      "Batch:  2980 , l1 Loss:  0.103550935536623 , Time: 13165.613166570663 s\n",
      "Batch:  2990 , l1 Loss:  0.10334340259432792 , Time: 13178.484295368195 s\n",
      "Batch:  3000 , l1 Loss:  0.10308395177125931 , Time: 13191.365756988525 s\n",
      "Batch:  3010 , l1 Loss:  0.10364109724760055 , Time: 13204.303900957108 s\n",
      "Batch:  3020 , l1 Loss:  0.10295454934239387 , Time: 13217.200257062912 s\n",
      "Batch:  3030 , l1 Loss:  0.10237141400575638 , Time: 13230.15624666214 s\n",
      "Batch:  3040 , l1 Loss:  0.10557224974036217 , Time: 13243.090284824371 s\n",
      "Batch:  3050 , l1 Loss:  0.10458584427833557 , Time: 13255.985826969147 s\n",
      "Batch:  3060 , l1 Loss:  0.10400898307561875 , Time: 13268.9045317173 s\n",
      "Batch:  3070 , l1 Loss:  0.10370706841349601 , Time: 13281.78319811821 s\n",
      "Batch:  3080 , l1 Loss:  0.10241960138082504 , Time: 13294.7202937603 s\n",
      "Batch:  3090 , l1 Loss:  0.10488738715648652 , Time: 13307.657597780228 s\n",
      "Batch:  3100 , l1 Loss:  0.10133072212338448 , Time: 13320.593556642532 s\n",
      "Batch:  3110 , l1 Loss:  0.10145886987447739 , Time: 13333.55107307434 s\n",
      "Batch:  3120 , l1 Loss:  0.10335780531167985 , Time: 13346.483984708786 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  3130 , l1 Loss:  0.10373829379677772 , Time: 13359.46435880661 s\n",
      "Batch:  3140 , l1 Loss:  0.10226365625858307 , Time: 13372.386568069458 s\n",
      "Batch:  3150 , l1 Loss:  0.1089572250843048 , Time: 13385.198198795319 s\n",
      "Batch:  3160 , l1 Loss:  0.10833229944109916 , Time: 13398.080803632736 s\n",
      "Batch:  3170 , l1 Loss:  0.10600491687655449 , Time: 13410.959999322891 s\n",
      "Batch:  3180 , l1 Loss:  0.10674877092242241 , Time: 13423.895334005356 s\n",
      "Batch:  3190 , l1 Loss:  0.10544400066137313 , Time: 13436.812149763107 s\n",
      "Batch:  3200 , l1 Loss:  0.10369816496968269 , Time: 13449.772837400436 s\n",
      "Batch:  3210 , l1 Loss:  0.104886594414711 , Time: 13462.751316785812 s\n",
      "Batch:  3220 , l1 Loss:  0.10470624640583992 , Time: 13475.68816947937 s\n",
      "Batch:  3230 , l1 Loss:  0.10679475665092468 , Time: 13488.624327421188 s\n",
      "Batch:  3240 , l1 Loss:  0.10548666268587112 , Time: 13501.578483819962 s\n",
      "Batch:  3250 , l1 Loss:  0.10634243190288543 , Time: 13514.533401727676 s\n",
      "Batch:  3260 , l1 Loss:  0.10282905623316765 , Time: 13527.488217115402 s\n",
      "Batch:  3270 , l1 Loss:  0.10382506549358368 , Time: 13540.447460651398 s\n",
      "Batch:  3280 , l1 Loss:  0.1048217311501503 , Time: 13553.408024549484 s\n",
      "Batch:  3290 , l1 Loss:  0.10224086120724678 , Time: 13566.379672527313 s\n",
      "Batch:  3300 , l1 Loss:  0.10328162536025047 , Time: 13579.315297365189 s\n",
      "Batch:  3310 , l1 Loss:  0.1059922382235527 , Time: 13592.253216266632 s\n",
      "Batch:  3320 , l1 Loss:  0.10156839042901993 , Time: 13605.186781167984 s\n",
      "Batch:  3330 , l1 Loss:  0.10616048276424409 , Time: 13618.123408555984 s\n",
      "Batch:  3340 , l1 Loss:  0.10518718659877777 , Time: 13631.039339780807 s\n",
      "Batch:  3350 , l1 Loss:  0.101300348341465 , Time: 13643.991423606873 s\n",
      "Batch:  3360 , l1 Loss:  0.10575106665492058 , Time: 13656.924943447113 s\n",
      "Batch:  3370 , l1 Loss:  0.1009729765355587 , Time: 13669.866585731506 s\n",
      "Batch:  3380 , l1 Loss:  0.10376781448721886 , Time: 13682.791874170303 s\n",
      "Batch:  3390 , l1 Loss:  0.10280450582504272 , Time: 13695.71540760994 s\n",
      "Batch:  3400 , l1 Loss:  0.10092954039573669 , Time: 13708.709813833237 s\n",
      "Batch:  3410 , l1 Loss:  0.104778853058815 , Time: 13721.644260644913 s\n",
      "Batch:  3420 , l1 Loss:  0.10326486751437187 , Time: 13734.58836555481 s\n",
      "Batch:  3430 , l1 Loss:  0.10324139222502708 , Time: 13747.49518084526 s\n",
      "Batch:  3440 , l1 Loss:  0.10484678745269775 , Time: 13760.358849525452 s\n",
      "Batch:  3450 , l1 Loss:  0.1037332721054554 , Time: 13773.290112018585 s\n",
      "Batch:  3460 , l1 Loss:  0.1025462843477726 , Time: 13786.227419137955 s\n",
      "Batch:  3470 , l1 Loss:  0.10198587030172349 , Time: 13799.186078310013 s\n",
      "Batch:  3480 , l1 Loss:  0.10328837782144547 , Time: 13812.18219614029 s\n",
      "Batch:  3490 , l1 Loss:  0.10021199211478234 , Time: 13825.179862737656 s\n",
      "Batch:  3500 , l1 Loss:  0.10504773706197738 , Time: 13838.171401500702 s\n",
      "Batch:  3510 , l1 Loss:  0.10315917283296586 , Time: 13851.20740389824 s\n",
      "Batch:  3520 , l1 Loss:  0.10632147714495659 , Time: 13864.164087057114 s\n",
      "Batch:  3530 , l1 Loss:  0.10435371473431587 , Time: 13877.19994544983 s\n",
      "Batch:  3540 , l1 Loss:  0.10408993288874627 , Time: 13890.326404571533 s\n",
      "Batch:  3550 , l1 Loss:  0.10373095721006394 , Time: 13903.415881872177 s\n",
      "Batch:  3560 , l1 Loss:  0.10289718881249428 , Time: 13916.55507850647 s\n",
      "Batch:  3570 , l1 Loss:  0.10283139795064926 , Time: 13929.635512828827 s\n",
      "Batch:  3580 , l1 Loss:  0.10426026806235314 , Time: 13942.714194774628 s\n",
      "Batch:  3590 , l1 Loss:  0.10225552022457123 , Time: 13955.826963424683 s\n",
      "Batch:  3600 , l1 Loss:  0.10290680006146431 , Time: 13968.873844385147 s\n",
      "Batch:  3610 , l1 Loss:  0.10212584882974625 , Time: 13981.935868740082 s\n",
      "Batch:  3620 , l1 Loss:  0.10041047483682633 , Time: 13994.95352101326 s\n",
      "Batch:  3630 , l1 Loss:  0.10401883199810982 , Time: 14008.051240444183 s\n",
      "Batch:  3640 , l1 Loss:  0.10343383103609086 , Time: 14021.088973999023 s\n",
      "Batch:  3650 , l1 Loss:  0.10440622344613075 , Time: 14034.144212007523 s\n",
      "Batch:  3660 , l1 Loss:  0.10316397547721863 , Time: 14047.221783399582 s\n",
      "Batch:  3670 , l1 Loss:  0.10264535993337631 , Time: 14060.256210565567 s\n",
      "Batch:  3680 , l1 Loss:  0.10378160178661347 , Time: 14073.32315659523 s\n",
      "Batch:  3690 , l1 Loss:  0.10408436357975007 , Time: 14086.304175138474 s\n",
      "Batch:  3700 , l1 Loss:  0.10475808680057526 , Time: 14099.237124443054 s\n",
      "Batch:  3710 , l1 Loss:  0.10445287674665452 , Time: 14112.188409805298 s\n",
      "Batch:  3720 , l1 Loss:  0.10403444617986679 , Time: 14125.165138959885 s\n",
      "Batch:  3730 , l1 Loss:  0.10191950500011444 , Time: 14138.16050863266 s\n",
      "Batch:  3740 , l1 Loss:  0.10186454504728318 , Time: 14151.196836471558 s\n",
      "Batch:  3750 , l1 Loss:  0.10188548266887665 , Time: 14164.233362197876 s\n",
      "Batch:  3760 , l1 Loss:  0.10265602618455887 , Time: 14177.28637766838 s\n",
      "Batch:  3770 , l1 Loss:  0.10193258747458459 , Time: 14190.340775251389 s\n",
      "Batch:  3780 , l1 Loss:  0.10265778675675392 , Time: 14203.382989406586 s\n",
      "Batch:  3790 , l1 Loss:  0.10474728643894196 , Time: 14216.41575551033 s\n",
      "Batch:  3800 , l1 Loss:  0.1035052090883255 , Time: 14229.47283411026 s\n",
      "Batch:  3810 , l1 Loss:  0.1029115967452526 , Time: 14242.482998371124 s\n",
      "Batch:  3820 , l1 Loss:  0.10252785161137581 , Time: 14255.523082733154 s\n",
      "Batch:  3830 , l1 Loss:  0.10556333810091019 , Time: 14268.541118383408 s\n",
      "Batch:  3840 , l1 Loss:  0.10479055717587471 , Time: 14281.595526456833 s\n",
      "Batch:  3850 , l1 Loss:  0.10325177162885665 , Time: 14294.580670595169 s\n",
      "Batch:  3860 , l1 Loss:  0.10381154045462608 , Time: 14307.621905326843 s\n",
      "Batch:  3870 , l1 Loss:  0.10376540422439576 , Time: 14320.640402317047 s\n",
      "Batch:  3880 , l1 Loss:  0.10296736210584641 , Time: 14333.83418750763 s\n",
      "Batch:  3890 , l1 Loss:  0.10220511928200722 , Time: 14346.692583799362 s\n",
      "Batch:  3900 , l1 Loss:  0.10278377532958985 , Time: 14359.548429727554 s\n",
      "Batch:  3910 , l1 Loss:  0.10122551769018173 , Time: 14372.48576259613 s\n",
      "Batch:  3920 , l1 Loss:  0.10378766134381294 , Time: 14385.417381763458 s\n",
      "Batch:  3930 , l1 Loss:  0.103892482817173 , Time: 14398.35602927208 s\n",
      "Batch:  3940 , l1 Loss:  0.10423775911331176 , Time: 14411.296183347702 s\n",
      "Batch:  3950 , l1 Loss:  0.10588503256440163 , Time: 14424.228889226913 s\n",
      "Batch:  3960 , l1 Loss:  0.10185019075870513 , Time: 14437.24764084816 s\n",
      "Batch:  3970 , l1 Loss:  0.1028837077319622 , Time: 14450.222220897675 s\n",
      "Batch:  3980 , l1 Loss:  0.10286797508597374 , Time: 14463.1539144516 s\n",
      "Batch:  3990 , l1 Loss:  0.10201864391565323 , Time: 14476.092005968094 s\n",
      "Batch:  4000 , l1 Loss:  0.1049938179552555 , Time: 14489.028365135193 s\n",
      "Batch:  4010 , l1 Loss:  0.10221080332994462 , Time: 14502.02671957016 s\n",
      "Batch:  4020 , l1 Loss:  0.10502864792943001 , Time: 14514.982084989548 s\n",
      "Batch:  4030 , l1 Loss:  0.10209939181804657 , Time: 14527.936846971512 s\n",
      "Batch:  4040 , l1 Loss:  0.10168535783886909 , Time: 14540.91462278366 s\n",
      "Batch:  4050 , l1 Loss:  0.09941438436508179 , Time: 14553.910185337067 s\n",
      "Batch:  4060 , l1 Loss:  0.1041841097176075 , Time: 14566.863672494888 s\n",
      "Batch:  4070 , l1 Loss:  0.10151425525546073 , Time: 14579.822474241257 s\n",
      "Batch:  4080 , l1 Loss:  0.1026019275188446 , Time: 14592.796894788742 s\n",
      "Batch:  4090 , l1 Loss:  0.10219746679067612 , Time: 14605.75531053543 s\n",
      "Batch:  4100 , l1 Loss:  0.10257060155272484 , Time: 14618.773248910904 s\n",
      "Batch:  4110 , l1 Loss:  0.10320146083831787 , Time: 14631.905587434769 s\n",
      "Batch:  4120 , l1 Loss:  0.10420227274298668 , Time: 14645.040060043335 s\n",
      "Batch:  4130 , l1 Loss:  0.10362652838230133 , Time: 14658.16973733902 s\n",
      "Batch:  4140 , l1 Loss:  0.10267424136400223 , Time: 14671.315192699432 s\n",
      "Batch:  4150 , l1 Loss:  0.09947584122419358 , Time: 14684.44954943657 s\n",
      "Batch:  4160 , l1 Loss:  0.10227119699120521 , Time: 14697.563927412033 s\n",
      "Batch:  4170 , l1 Loss:  0.10332494154572487 , Time: 14710.639130353928 s\n",
      "Batch:  4180 , l1 Loss:  0.10131980776786804 , Time: 14723.739444494247 s\n",
      "Batch:  4190 , l1 Loss:  0.10232964605093002 , Time: 14736.77387046814 s\n",
      "Batch:  4200 , l1 Loss:  0.10573685839772225 , Time: 14749.878615617752 s\n",
      "Batch:  4210 , l1 Loss:  0.10260308831930161 , Time: 14762.91666173935 s\n",
      "Batch:  4220 , l1 Loss:  0.10238355174660682 , Time: 14775.971322536469 s\n",
      "Batch:  4230 , l1 Loss:  0.10137641951441764 , Time: 14789.089017391205 s\n",
      "Batch:  4240 , l1 Loss:  0.10043549239635467 , Time: 14802.151745796204 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  4250 , l1 Loss:  0.10302729681134223 , Time: 14815.190380573273 s\n",
      "Batch:  4260 , l1 Loss:  0.102212905138731 , Time: 14828.306272983551 s\n",
      "Batch:  4270 , l1 Loss:  0.10838131532073021 , Time: 14841.377132892609 s\n",
      "Batch:  4280 , l1 Loss:  0.1194544978439808 , Time: 14854.430921316147 s\n",
      "Batch:  4290 , l1 Loss:  0.12070790752768516 , Time: 14867.488626718521 s\n",
      "Batch:  4300 , l1 Loss:  0.11568413451313972 , Time: 14880.602949857712 s\n",
      "Batch:  4310 , l1 Loss:  0.11367223411798477 , Time: 14893.640291929245 s\n",
      "Batch:  4320 , l1 Loss:  0.1099728912115097 , Time: 14906.67838048935 s\n",
      "Batch:  4330 , l1 Loss:  0.10706565305590629 , Time: 14919.807616710663 s\n",
      "Batch:  4340 , l1 Loss:  0.10613504648208619 , Time: 14932.871587753296 s\n",
      "Batch:  4350 , l1 Loss:  0.10445750206708908 , Time: 14945.923359394073 s\n",
      "Batch:  4360 , l1 Loss:  0.10483096763491631 , Time: 14958.98577618599 s\n",
      "Batch:  4370 , l1 Loss:  0.1043745070695877 , Time: 14972.025510549545 s\n",
      "Batch:  4380 , l1 Loss:  0.10422563180327415 , Time: 14985.056781291962 s\n",
      "Batch:  4390 , l1 Loss:  0.10549430474638939 , Time: 14998.132648468018 s\n",
      "Batch:  4400 , l1 Loss:  0.1036965273320675 , Time: 15011.208991765976 s\n",
      "Batch:  4410 , l1 Loss:  0.10175516530871391 , Time: 15024.289220809937 s\n",
      "Batch:  4420 , l1 Loss:  0.10694678649306297 , Time: 15037.38689994812 s\n",
      "Batch:  4430 , l1 Loss:  0.10365286692976952 , Time: 15050.441685676575 s\n",
      "Batch:  4440 , l1 Loss:  0.10449594780802726 , Time: 15063.4852912426 s\n",
      "Batch:  4450 , l1 Loss:  0.10346411615610122 , Time: 15076.556087493896 s\n",
      "Batch:  4460 , l1 Loss:  0.10350426957011223 , Time: 15089.63443851471 s\n",
      "Batch:  4470 , l1 Loss:  0.10634194910526276 , Time: 15102.66731262207 s\n",
      "Batch:  4480 , l1 Loss:  0.10391260087490081 , Time: 15115.723462820053 s\n",
      "Batch:  4490 , l1 Loss:  0.10592867136001587 , Time: 15128.759621620178 s\n",
      "Batch:  4500 , l1 Loss:  0.10427231118083 , Time: 15141.815972089767 s\n",
      "Batch:  4510 , l1 Loss:  0.10337699949741364 , Time: 15154.918096780777 s\n",
      "Batch:  4520 , l1 Loss:  0.10212876200675965 , Time: 15167.953896522522 s\n",
      "Batch:  4530 , l1 Loss:  0.10350188836455346 , Time: 15181.004787683487 s\n",
      "Batch:  4540 , l1 Loss:  0.10347522646188737 , Time: 15194.080880641937 s\n",
      "Batch:  4550 , l1 Loss:  0.10246915966272355 , Time: 15207.194747924805 s\n",
      "Batch:  4560 , l1 Loss:  0.10214596688747406 , Time: 15220.394689321518 s\n",
      "Batch:  4570 , l1 Loss:  0.1012268215417862 , Time: 15233.445842027664 s\n",
      "Batch:  4580 , l1 Loss:  0.10247134864330291 , Time: 15246.472987651825 s\n",
      "Batch:  4590 , l1 Loss:  0.10301486030220985 , Time: 15259.541418552399 s\n",
      "Batch:  4600 , l1 Loss:  0.1031441293656826 , Time: 15272.619800567627 s\n",
      "Batch:  4610 , l1 Loss:  0.10431747734546662 , Time: 15285.665334701538 s\n",
      "Batch:  4620 , l1 Loss:  0.10338938757777213 , Time: 15298.738548755646 s\n",
      "Batch:  4630 , l1 Loss:  0.10381854996085167 , Time: 15311.751921892166 s\n",
      "Batch:  4640 , l1 Loss:  0.10544106662273407 , Time: 15324.81163263321 s\n",
      "Batch:  4650 , l1 Loss:  0.10399700403213501 , Time: 15337.84940290451 s\n",
      "Batch:  4660 , l1 Loss:  0.10096933841705322 , Time: 15350.906831502914 s\n",
      "Batch:  4670 , l1 Loss:  0.10098538398742676 , Time: 15363.936470031738 s\n",
      "Batch:  4680 , l1 Loss:  0.1040249839425087 , Time: 15376.961823701859 s\n",
      "Batch:  4690 , l1 Loss:  0.10224617421627044 , Time: 15390.061216831207 s\n",
      "Batch:  4700 , l1 Loss:  0.10348266735672951 , Time: 15403.262030363083 s\n",
      "Batch:  4710 , l1 Loss:  0.10094957798719406 , Time: 15416.326831817627 s\n",
      "Batch:  4720 , l1 Loss:  0.10263588204979897 , Time: 15429.3799431324 s\n",
      "Batch:  4730 , l1 Loss:  0.10293125584721566 , Time: 15442.438727855682 s\n",
      "Batch:  4740 , l1 Loss:  0.10007563903927803 , Time: 15455.47276544571 s\n",
      "Batch:  4750 , l1 Loss:  0.10207312256097793 , Time: 15468.51344537735 s\n",
      "Batch:  4760 , l1 Loss:  0.10691463798284531 , Time: 15481.571516513824 s\n",
      "Batch:  4770 , l1 Loss:  0.1031913198530674 , Time: 15494.606137752533 s\n",
      "Batch:  4780 , l1 Loss:  0.10077412202954292 , Time: 15507.68135881424 s\n",
      "Batch:  4790 , l1 Loss:  0.10199138745665551 , Time: 15520.799287557602 s\n",
      "Batch:  4800 , l1 Loss:  0.10375330224633217 , Time: 15533.835938453674 s\n",
      "Batch:  4810 , l1 Loss:  0.10142435953021049 , Time: 15546.872922897339 s\n",
      "Batch:  4820 , l1 Loss:  0.10328839346766472 , Time: 15559.89252281189 s\n",
      "Batch:  4830 , l1 Loss:  0.10365441143512726 , Time: 15572.94676041603 s\n",
      "Batch:  4840 , l1 Loss:  0.10272518321871757 , Time: 15585.961346149445 s\n",
      "Batch:  4850 , l1 Loss:  0.10217705070972442 , Time: 15599.018533945084 s\n",
      "Batch:  4860 , l1 Loss:  0.10363940894603729 , Time: 15612.065302371979 s\n",
      "Batch:  4870 , l1 Loss:  0.10549168214201927 , Time: 15625.078122377396 s\n",
      "Batch:  4880 , l1 Loss:  0.10289309546351433 , Time: 15638.169824123383 s\n",
      "Batch:  4890 , l1 Loss:  0.10276370719075203 , Time: 15651.18647146225 s\n",
      "Batch:  4900 , l1 Loss:  0.1025410383939743 , Time: 15664.184775590897 s\n",
      "Batch:  4910 , l1 Loss:  0.10227520614862443 , Time: 15677.236680984497 s\n",
      "Batch:  4920 , l1 Loss:  0.10458265841007233 , Time: 15690.295986652374 s\n",
      "Batch:  4930 , l1 Loss:  0.10294846221804618 , Time: 15703.313211679459 s\n",
      "Batch:  4940 , l1 Loss:  0.10502398014068604 , Time: 15716.32961511612 s\n",
      "Batch:  4950 , l1 Loss:  0.10144000425934792 , Time: 15729.342247724533 s\n",
      "Batch:  4960 , l1 Loss:  0.10305026322603225 , Time: 15742.382413625717 s\n",
      "Batch:  4970 , l1 Loss:  0.10284567251801491 , Time: 15755.421571731567 s\n",
      "Batch:  4980 , l1 Loss:  0.10177120566368103 , Time: 15768.475000858307 s\n",
      "Batch:  4990 , l1 Loss:  0.10044512376189232 , Time: 15781.494841337204 s\n",
      "Batch:  5000 , l1 Loss:  0.1052340105175972 , Time: 15794.57198882103 s\n",
      "Batch:  5010 , l1 Loss:  0.10089980363845825 , Time: 15807.650665998459 s\n",
      "Batch:  5020 , l1 Loss:  0.10284933522343635 , Time: 15820.644220113754 s\n",
      "Batch:  5030 , l1 Loss:  0.10334187671542168 , Time: 15833.543082475662 s\n",
      "Batch:  5040 , l1 Loss:  0.10320496261119842 , Time: 15846.444810628891 s\n",
      "Batch:  5050 , l1 Loss:  0.10113479867577553 , Time: 15859.372133016586 s\n",
      "Batch:  5060 , l1 Loss:  0.10299806371331215 , Time: 15872.331284761429 s\n",
      "Batch:  5070 , l1 Loss:  0.10190797373652458 , Time: 15885.325786352158 s\n",
      "Batch:  5080 , l1 Loss:  0.10461125299334526 , Time: 15898.301481485367 s\n",
      "Batch:  5090 , l1 Loss:  0.10172306373715401 , Time: 15911.277351140976 s\n",
      "Batch:  5100 , l1 Loss:  0.10328419208526611 , Time: 15924.256522655487 s\n",
      "Batch:  5110 , l1 Loss:  0.10434712916612625 , Time: 15937.211802721024 s\n",
      "Batch:  5120 , l1 Loss:  0.10428087413311005 , Time: 15950.205840349197 s\n",
      "Batch:  5130 , l1 Loss:  0.10043215528130531 , Time: 15963.207520246506 s\n",
      "Batch:  5140 , l1 Loss:  0.10154133960604668 , Time: 15976.183143138885 s\n",
      "Batch:  5150 , l1 Loss:  0.10273405835032463 , Time: 15989.18107008934 s\n",
      "Batch:  5160 , l1 Loss:  0.10144333094358444 , Time: 16002.155202150345 s\n",
      "Batch:  5170 , l1 Loss:  0.1007831335067749 , Time: 16015.155308008194 s\n",
      "Batch:  5180 , l1 Loss:  0.10219578146934509 , Time: 16028.12097787857 s\n",
      "Batch:  5190 , l1 Loss:  0.10165411382913589 , Time: 16041.149342298508 s\n",
      "Batch:  5200 , l1 Loss:  0.1025284044444561 , Time: 16054.184717655182 s\n",
      "Batch:  5210 , l1 Loss:  0.10222925916314125 , Time: 16067.163628339767 s\n",
      "Batch:  5220 , l1 Loss:  0.10238853394985199 , Time: 16080.183163881302 s\n",
      "Batch:  5230 , l1 Loss:  0.1011621631681919 , Time: 16093.183081388474 s\n",
      "Batch:  5240 , l1 Loss:  0.10218559429049492 , Time: 16106.161727428436 s\n",
      "Batch:  5250 , l1 Loss:  0.10189670324325562 , Time: 16119.23883485794 s\n",
      "Batch:  5260 , l1 Loss:  0.10333927124738693 , Time: 16132.202332735062 s\n",
      "Batch:  5270 , l1 Loss:  0.1034757561981678 , Time: 16145.294913053513 s\n",
      "Batch:  5280 , l1 Loss:  0.10272261649370193 , Time: 16158.415349006653 s\n",
      "Batch:  5290 , l1 Loss:  0.10263732820749283 , Time: 16171.513067483902 s\n",
      "Batch:  5300 , l1 Loss:  0.10323491990566254 , Time: 16184.585482358932 s\n",
      "Batch:  5310 , l1 Loss:  0.10430539250373841 , Time: 16197.64761042595 s\n",
      "Batch:  5320 , l1 Loss:  0.10434852838516236 , Time: 16210.682080745697 s\n",
      "Batch:  5330 , l1 Loss:  0.10303639993071556 , Time: 16223.716568470001 s\n",
      "Batch:  5340 , l1 Loss:  0.10327455103397369 , Time: 16236.738109827042 s\n",
      "Batch:  5350 , l1 Loss:  0.10305847525596619 , Time: 16249.79419374466 s\n",
      "Batch:  5360 , l1 Loss:  0.10574959143996239 , Time: 16262.80674815178 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  5370 , l1 Loss:  0.10279466584324837 , Time: 16275.797885894775 s\n",
      "Batch:  5380 , l1 Loss:  0.10115106105804443 , Time: 16288.773777723312 s\n",
      "Batch:  5390 , l1 Loss:  0.10264011919498443 , Time: 16301.814002513885 s\n",
      "Batch:  5400 , l1 Loss:  0.10465280264616013 , Time: 16314.81283211708 s\n",
      "Batch:  5410 , l1 Loss:  0.10226431488990784 , Time: 16327.78382396698 s\n",
      "Batch:  5420 , l1 Loss:  0.10344723090529442 , Time: 16340.76855301857 s\n",
      "Batch:  5430 , l1 Loss:  0.10581233501434326 , Time: 16353.808062076569 s\n",
      "Batch:  5440 , l1 Loss:  0.10328185707330703 , Time: 16366.805819749832 s\n",
      "Batch:  5450 , l1 Loss:  0.10282253473997116 , Time: 16379.803084611893 s\n",
      "Batch:  5460 , l1 Loss:  0.10351699590682983 , Time: 16392.819905757904 s\n",
      "Batch:  5470 , l1 Loss:  0.10315023586153985 , Time: 16405.82869553566 s\n",
      "Batch:  5480 , l1 Loss:  0.10163533315062523 , Time: 16418.81312060356 s\n",
      "Batch:  5490 , l1 Loss:  0.10243872702121734 , Time: 16431.70971274376 s\n",
      "Batch:  5500 , l1 Loss:  0.10138046443462372 , Time: 16444.542633533478 s\n",
      "Batch:  5510 , l1 Loss:  0.10337958261370658 , Time: 16457.480383634567 s\n",
      "Batch:  5520 , l1 Loss:  0.10260474681854248 , Time: 16470.375492095947 s\n",
      "Batch:  5530 , l1 Loss:  0.1031958967447281 , Time: 16483.310741186142 s\n",
      "Batch:  5540 , l1 Loss:  0.11533209159970284 , Time: 16496.227986335754 s\n",
      "Batch:  5550 , l1 Loss:  0.11685575023293496 , Time: 16509.164840459824 s\n",
      "Batch:  5560 , l1 Loss:  0.11560172289609909 , Time: 16522.082278251648 s\n",
      "Batch:  5570 , l1 Loss:  0.11639468297362328 , Time: 16535.01659011841 s\n",
      "Batch:  5580 , l1 Loss:  0.11042449623346329 , Time: 16548.034011125565 s\n",
      "Batch:  5590 , l1 Loss:  0.10908981263637543 , Time: 16561.03020787239 s\n",
      "Batch:  5600 , l1 Loss:  0.11039674431085586 , Time: 16574.00297164917 s\n",
      "Batch:  5610 , l1 Loss:  0.10854720771312713 , Time: 16586.99979043007 s\n",
      "Batch:  5620 , l1 Loss:  0.1099017933011055 , Time: 16600.096512317657 s\n",
      "Batch:  5630 , l1 Loss:  0.10483235120773315 , Time: 16613.112862348557 s\n",
      "Batch:  5640 , l1 Loss:  0.1058422490954399 , Time: 16626.08981704712 s\n",
      "Batch:  5650 , l1 Loss:  0.10383782833814621 , Time: 16639.091232299805 s\n",
      "Batch:  5660 , l1 Loss:  0.10646612122654915 , Time: 16652.005853891373 s\n",
      "Batch:  5670 , l1 Loss:  0.10406595319509507 , Time: 16664.93831372261 s\n",
      "Batch:  5680 , l1 Loss:  0.10414471849799156 , Time: 16677.874621868134 s\n",
      "Batch:  5690 , l1 Loss:  0.10202269479632378 , Time: 16690.798458576202 s\n",
      "Batch:  5700 , l1 Loss:  0.10534833148121833 , Time: 16703.73220729828 s\n",
      "Batch:  5710 , l1 Loss:  0.10213256254792213 , Time: 16716.64709329605 s\n",
      "Batch:  5720 , l1 Loss:  0.10250893384218215 , Time: 16729.566217184067 s\n",
      "Batch:  5730 , l1 Loss:  0.10337072014808654 , Time: 16742.506054639816 s\n",
      "Batch:  5740 , l1 Loss:  0.10406268537044525 , Time: 16755.39835214615 s\n",
      "Batch:  5750 , l1 Loss:  0.10414576083421707 , Time: 16768.357358932495 s\n",
      "Batch:  5760 , l1 Loss:  0.10443901792168617 , Time: 16781.31444144249 s\n",
      "Batch:  5770 , l1 Loss:  0.10634435340762138 , Time: 16794.24910593033 s\n",
      "Batch:  5780 , l1 Loss:  0.10389885827898979 , Time: 16807.1844496727 s\n",
      "Batch:  5790 , l1 Loss:  0.10146824643015862 , Time: 16820.122688531876 s\n",
      "Batch:  5800 , l1 Loss:  0.10389276146888733 , Time: 16833.10285758972 s\n",
      "Batch:  5810 , l1 Loss:  0.1023807518184185 , Time: 16846.05191040039 s\n",
      "Batch:  5820 , l1 Loss:  0.10539717227220535 , Time: 16859.012515068054 s\n",
      "Batch:  5830 , l1 Loss:  0.10205517411231994 , Time: 16871.988280773163 s\n",
      "Batch:  5840 , l1 Loss:  0.10361309722065926 , Time: 16884.963458299637 s\n",
      "Batch:  5850 , l1 Loss:  0.10261342599987984 , Time: 16897.88427591324 s\n",
      "Batch:  5860 , l1 Loss:  0.10234876424074173 , Time: 16910.8612241745 s\n",
      "Batch:  5870 , l1 Loss:  0.1012555107474327 , Time: 16923.83833527565 s\n",
      "Batch:  5880 , l1 Loss:  0.10312972441315651 , Time: 16936.811334609985 s\n",
      "Batch:  5890 , l1 Loss:  0.10253678560256958 , Time: 16949.81064105034 s\n",
      "Batch:  5900 , l1 Loss:  0.10371803790330887 , Time: 16962.7707798481 s\n",
      "Batch:  5910 , l1 Loss:  0.10480401292443275 , Time: 16975.75276327133 s\n",
      "Batch:  5920 , l1 Loss:  0.10555746406316757 , Time: 16988.746339797974 s\n",
      "Batch:  5930 , l1 Loss:  0.1033499263226986 , Time: 17001.74110174179 s\n",
      "Batch:  5940 , l1 Loss:  0.1047906070947647 , Time: 17014.697282791138 s\n",
      "Batch:  5950 , l1 Loss:  0.10172952711582184 , Time: 17027.672163248062 s\n",
      "Batch:  5960 , l1 Loss:  0.1039208821952343 , Time: 17040.653421878815 s\n",
      "Batch:  5970 , l1 Loss:  0.10377871543169022 , Time: 17053.630818367004 s\n",
      "Batch:  5980 , l1 Loss:  0.10484677255153656 , Time: 17066.596125125885 s\n",
      "Batch:  5990 , l1 Loss:  0.10189358443021775 , Time: 17079.56230044365 s\n",
      "Batch:  6000 , l1 Loss:  0.10260107889771461 , Time: 17092.541023254395 s\n",
      "Batch:  6010 , l1 Loss:  0.10197444185614586 , Time: 17105.58113002777 s\n",
      "Batch:  6020 , l1 Loss:  0.10113129168748855 , Time: 17118.53791332245 s\n",
      "Batch:  6030 , l1 Loss:  0.10423894003033637 , Time: 17131.52100586891 s\n",
      "Batch:  6040 , l1 Loss:  0.10529341623187065 , Time: 17144.531737089157 s\n",
      "Batch:  6050 , l1 Loss:  0.1010050468146801 , Time: 17157.54639673233 s\n",
      "Batch:  6060 , l1 Loss:  0.10349750444293022 , Time: 17170.486110925674 s\n",
      "Batch:  6070 , l1 Loss:  0.10132006481289864 , Time: 17183.463704109192 s\n",
      "Batch:  6080 , l1 Loss:  0.10142751336097718 , Time: 17196.502883911133 s\n",
      "Batch:  6090 , l1 Loss:  0.10041580274701119 , Time: 17209.438475370407 s\n",
      "Batch:  6100 , l1 Loss:  0.10488140657544136 , Time: 17222.436515808105 s\n",
      "Batch:  6110 , l1 Loss:  0.10168179720640183 , Time: 17235.411583662033 s\n",
      "Batch:  6120 , l1 Loss:  0.10164131447672844 , Time: 17248.408982276917 s\n",
      "Batch:  6130 , l1 Loss:  0.10368799343705178 , Time: 17261.38881421089 s\n",
      "Batch:  6140 , l1 Loss:  0.10193414092063904 , Time: 17274.36486840248 s\n",
      "Batch:  6150 , l1 Loss:  0.10295498147606849 , Time: 17287.32140302658 s\n",
      "Batch:  6160 , l1 Loss:  0.10398288965225219 , Time: 17300.319929122925 s\n",
      "Batch:  6170 , l1 Loss:  0.1029951624572277 , Time: 17313.423523664474 s\n",
      "Batch:  6180 , l1 Loss:  0.10277148261666298 , Time: 17326.61917448044 s\n",
      "Batch:  6190 , l1 Loss:  0.1031039983034134 , Time: 17339.75490641594 s\n",
      "Batch:  6200 , l1 Loss:  0.10213221907615662 , Time: 17352.889875650406 s\n",
      "Batch:  6210 , l1 Loss:  0.10315456613898277 , Time: 17366.027014255524 s\n",
      "Batch:  6220 , l1 Loss:  0.10386384204030037 , Time: 17379.070431947708 s\n",
      "Batch:  6230 , l1 Loss:  0.10422946736216546 , Time: 17392.147432804108 s\n",
      "Batch:  6240 , l1 Loss:  0.10460341349244118 , Time: 17405.243772506714 s\n",
      "Batch:  6250 , l1 Loss:  0.10199041068553924 , Time: 17418.28258562088 s\n",
      "Batch:  6260 , l1 Loss:  0.10468848496675491 , Time: 17431.41844177246 s\n",
      "Batch:  6270 , l1 Loss:  0.10366073921322823 , Time: 17444.4572827816 s\n",
      "Batch:  6280 , l1 Loss:  0.1029369868338108 , Time: 17457.49768424034 s\n",
      "Batch:  6290 , l1 Loss:  0.10240329653024674 , Time: 17470.63038444519 s\n",
      "Batch:  6300 , l1 Loss:  0.10469799712300301 , Time: 17483.64439177513 s\n",
      "Batch:  6310 , l1 Loss:  0.1019683986902237 , Time: 17496.684770345688 s\n",
      "Batch:  6320 , l1 Loss:  0.10364575311541557 , Time: 17509.717735528946 s\n",
      "Batch:  6330 , l1 Loss:  0.10187987610697746 , Time: 17522.75564789772 s\n",
      "Batch:  6340 , l1 Loss:  0.10154389515519142 , Time: 17535.75590324402 s\n",
      "Batch:  6350 , l1 Loss:  0.10228044688701629 , Time: 17548.812237024307 s\n",
      "Batch:  6360 , l1 Loss:  0.1038117989897728 , Time: 17561.84760451317 s\n",
      "Batch:  6370 , l1 Loss:  0.10467770621180535 , Time: 17574.896886587143 s\n",
      "Batch:  6380 , l1 Loss:  0.10202491134405137 , Time: 17587.913567066193 s\n",
      "Batch:  6390 , l1 Loss:  0.10046424865722656 , Time: 17600.93283843994 s\n",
      "Batch:  6400 , l1 Loss:  0.10241564586758614 , Time: 17613.92497229576 s\n",
      "Batch:  6410 , l1 Loss:  0.10171870663762092 , Time: 17626.99695968628 s\n",
      "Batch:  6420 , l1 Loss:  0.10340413525700569 , Time: 17639.936461687088 s\n",
      "Batch:  6430 , l1 Loss:  0.10121630579233169 , Time: 17652.749762058258 s\n",
      "Batch:  6440 , l1 Loss:  0.10206212028861046 , Time: 17665.620831012726 s\n",
      "Batch:  6450 , l1 Loss:  0.10173542723059655 , Time: 17678.538992643356 s\n",
      "Batch:  6460 , l1 Loss:  0.10096077993512154 , Time: 17691.43511247635 s\n",
      "Batch:  6470 , l1 Loss:  0.10048034712672234 , Time: 17704.329053640366 s\n",
      "Batch:  6480 , l1 Loss:  0.10402529463171958 , Time: 17717.38979792595 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  6490 , l1 Loss:  0.1020821489393711 , Time: 17730.48830962181 s\n",
      "Batch:  6500 , l1 Loss:  0.10347632691264153 , Time: 17743.56121492386 s\n",
      "Batch:  6510 , l1 Loss:  0.1028152734041214 , Time: 17756.65947151184 s\n",
      "Batch:  6520 , l1 Loss:  0.10131194591522216 , Time: 17769.717993974686 s\n",
      "Batch:  6530 , l1 Loss:  0.09908441007137299 , Time: 17782.735707998276 s\n",
      "Batch:  6540 , l1 Loss:  0.10160050168633461 , Time: 17795.811142206192 s\n",
      "Batch:  6550 , l1 Loss:  0.1035899505019188 , Time: 17808.843181610107 s\n",
      "Batch:  6560 , l1 Loss:  0.10203099548816681 , Time: 17821.855226516724 s\n",
      "Batch:  6570 , l1 Loss:  0.10337842926383019 , Time: 17834.89602279663 s\n",
      "Batch:  6580 , l1 Loss:  0.10317335650324821 , Time: 17847.93301510811 s\n",
      "Batch:  6590 , l1 Loss:  0.10337360203266144 , Time: 17860.96911597252 s\n",
      "Batch:  6600 , l1 Loss:  0.10119169279932975 , Time: 17873.965989112854 s\n",
      "Batch:  6610 , l1 Loss:  0.1014327235519886 , Time: 17886.915684223175 s\n",
      "Batch:  6620 , l1 Loss:  0.10296652168035507 , Time: 17899.761907815933 s\n",
      "Batch:  6630 , l1 Loss:  0.10591823011636733 , Time: 17912.69020962715 s\n",
      "Batch:  6640 , l1 Loss:  0.10222012475132942 , Time: 17925.565960645676 s\n",
      "Batch:  6650 , l1 Loss:  0.10162017047405243 , Time: 17938.463222503662 s\n",
      "Batch:  6660 , l1 Loss:  0.10088339298963547 , Time: 17951.359248638153 s\n",
      "Batch:  6670 , l1 Loss:  0.10071405246853829 , Time: 17964.290524721146 s\n",
      "Batch:  6680 , l1 Loss:  0.10102668851613998 , Time: 17977.147062778473 s\n",
      "Batch:  6690 , l1 Loss:  0.10059424862265587 , Time: 17990.049865484238 s\n",
      "Batch:  6700 , l1 Loss:  0.10448186546564102 , Time: 18002.967447519302 s\n",
      "Batch:  6710 , l1 Loss:  0.10002340003848076 , Time: 18015.86461210251 s\n",
      "Batch:  6720 , l1 Loss:  0.10232856646180152 , Time: 18028.818296194077 s\n",
      "Batch:  6730 , l1 Loss:  0.1035981871187687 , Time: 18041.70027399063 s\n",
      "Batch:  6740 , l1 Loss:  0.10182520002126694 , Time: 18054.592103004456 s\n",
      "Batch:  6750 , l1 Loss:  0.10248071402311325 , Time: 18067.469810009003 s\n",
      "Batch:  6760 , l1 Loss:  0.1023765429854393 , Time: 18080.40797638893 s\n",
      "Batch:  6770 , l1 Loss:  0.10171220302581788 , Time: 18093.343435764313 s\n",
      "Batch:  6780 , l1 Loss:  0.10625201240181922 , Time: 18106.260860204697 s\n",
      "Batch:  6790 , l1 Loss:  0.10145350322127342 , Time: 18119.215843200684 s\n",
      "Batch:  6800 , l1 Loss:  0.10213142335414886 , Time: 18132.110702991486 s\n",
      "Batch:  6810 , l1 Loss:  0.10311213210225105 , Time: 18145.03728747368 s\n",
      "Batch:  6820 , l1 Loss:  0.10346217602491378 , Time: 18157.941593647003 s\n",
      "Batch:  6830 , l1 Loss:  0.10131042376160622 , Time: 18170.860019207 s\n",
      "Batch:  6840 , l1 Loss:  0.10002002194523811 , Time: 18183.731325387955 s\n",
      "Batch:  6850 , l1 Loss:  0.10133763700723648 , Time: 18196.595460891724 s\n",
      "Batch:  6860 , l1 Loss:  0.10297520831227303 , Time: 18209.470991373062 s\n",
      "Batch:  6870 , l1 Loss:  0.10398914515972138 , Time: 18222.34850716591 s\n",
      "Batch:  6880 , l1 Loss:  0.10309207364916802 , Time: 18235.294544935226 s\n",
      "Batch:  6890 , l1 Loss:  0.10326001346111298 , Time: 18248.179716825485 s\n",
      "Batch:  6900 , l1 Loss:  0.10116133540868759 , Time: 18261.0974047184 s\n",
      "Batch:  6910 , l1 Loss:  0.1029851533472538 , Time: 18274.034184217453 s\n",
      "Batch:  6920 , l1 Loss:  0.10265972316265107 , Time: 18286.968338012695 s\n",
      "Batch:  6930 , l1 Loss:  0.105182696133852 , Time: 18299.92240333557 s\n",
      "Batch:  6940 , l1 Loss:  0.10237491279840469 , Time: 18312.86386990547 s\n",
      "Batch:  6950 , l1 Loss:  0.10239507406949996 , Time: 18325.897138118744 s\n",
      "Batch:  6960 , l1 Loss:  0.10285738483071327 , Time: 18338.85454273224 s\n",
      "Batch:  6970 , l1 Loss:  0.1007173590362072 , Time: 18351.788158416748 s\n",
      "Batch:  6980 , l1 Loss:  0.10276887491345406 , Time: 18364.76331591606 s\n",
      "Batch:  6990 , l1 Loss:  0.10116664320230484 , Time: 18377.715735197067 s\n",
      "Batch:  7000 , l1 Loss:  0.1031377486884594 , Time: 18390.697271347046 s\n",
      "Batch:  7010 , l1 Loss:  0.10448664426803589 , Time: 18403.673302173615 s\n",
      "Batch:  7020 , l1 Loss:  0.10167406350374222 , Time: 18416.608354091644 s\n",
      "Epoch:  1 , l1 loss:  0.10371192870025177\n",
      "Epoch:  2\n",
      "Batch:  10 , l1 Loss:  0.10262040590698068 , Time: 18435.398100852966 s\n",
      "Batch:  20 , l1 Loss:  0.10483684167265891 , Time: 18448.392589330673 s\n",
      "Batch:  30 , l1 Loss:  0.10392503216862678 , Time: 18461.369118452072 s\n",
      "Batch:  40 , l1 Loss:  0.10103676989674568 , Time: 18474.346445322037 s\n",
      "Batch:  50 , l1 Loss:  0.10226964950561523 , Time: 18487.30418729782 s\n",
      "Batch:  60 , l1 Loss:  0.10225811302661895 , Time: 18500.27931857109 s\n",
      "Batch:  70 , l1 Loss:  0.10201159492135048 , Time: 18513.29383969307 s\n",
      "Batch:  80 , l1 Loss:  0.10373673886060715 , Time: 18526.273854255676 s\n",
      "Batch:  90 , l1 Loss:  0.10195773169398308 , Time: 18539.21234178543 s\n",
      "Batch:  100 , l1 Loss:  0.10267205983400345 , Time: 18552.068640470505 s\n",
      "Batch:  110 , l1 Loss:  0.10269493460655213 , Time: 18564.922507047653 s\n",
      "Batch:  120 , l1 Loss:  0.09952672123908997 , Time: 18577.801015853882 s\n",
      "Batch:  130 , l1 Loss:  0.10139789804816246 , Time: 18590.601778268814 s\n",
      "Batch:  140 , l1 Loss:  0.10459642037749291 , Time: 18603.47350883484 s\n",
      "Batch:  150 , l1 Loss:  0.10169885531067849 , Time: 18616.352060317993 s\n",
      "Batch:  160 , l1 Loss:  0.10223716422915459 , Time: 18629.227957963943 s\n",
      "Batch:  170 , l1 Loss:  0.10301303714513779 , Time: 18642.08633375168 s\n",
      "Batch:  180 , l1 Loss:  0.10223717018961906 , Time: 18655.00530576706 s\n",
      "Batch:  190 , l1 Loss:  0.10146626755595207 , Time: 18667.882055044174 s\n",
      "Batch:  200 , l1 Loss:  0.10215358212590217 , Time: 18680.73943734169 s\n",
      "Batch:  210 , l1 Loss:  0.09907028079032898 , Time: 18693.5913002491 s\n",
      "Batch:  220 , l1 Loss:  0.10217872485518456 , Time: 18706.46684360504 s\n",
      "Batch:  230 , l1 Loss:  0.10007011219859123 , Time: 18719.34652209282 s\n",
      "Batch:  240 , l1 Loss:  0.1009159505367279 , Time: 18732.224892377853 s\n",
      "Batch:  250 , l1 Loss:  0.10068472251296043 , Time: 18745.100283384323 s\n",
      "Batch:  260 , l1 Loss:  0.10163991451263428 , Time: 18757.999732255936 s\n",
      "Batch:  270 , l1 Loss:  0.10144278928637504 , Time: 18770.87529015541 s\n",
      "Batch:  280 , l1 Loss:  0.10146740823984146 , Time: 18783.771236896515 s\n",
      "Batch:  290 , l1 Loss:  0.10324573963880539 , Time: 18796.652094602585 s\n",
      "Batch:  300 , l1 Loss:  0.10246799364686013 , Time: 18809.569896936417 s\n",
      "Batch:  310 , l1 Loss:  0.10014076307415962 , Time: 18822.505002260208 s\n",
      "Batch:  320 , l1 Loss:  0.10107191950082779 , Time: 18835.421941518784 s\n",
      "Batch:  330 , l1 Loss:  0.10296309217810631 , Time: 18848.392520189285 s\n",
      "Batch:  340 , l1 Loss:  0.10101945847272872 , Time: 18861.334804296494 s\n",
      "Batch:  350 , l1 Loss:  0.10256782099604607 , Time: 18874.291501522064 s\n",
      "Batch:  360 , l1 Loss:  0.10149012431502343 , Time: 18887.2074508667 s\n",
      "Batch:  370 , l1 Loss:  0.10498478189110756 , Time: 18900.10458254814 s\n",
      "Batch:  380 , l1 Loss:  0.10090963914990425 , Time: 18913.02420091629 s\n",
      "Batch:  390 , l1 Loss:  0.09944707825779915 , Time: 18925.94063425064 s\n",
      "Batch:  400 , l1 Loss:  0.10256116539239883 , Time: 18938.858050107956 s\n",
      "Batch:  410 , l1 Loss:  0.10160572305321694 , Time: 18951.77628970146 s\n",
      "Batch:  420 , l1 Loss:  0.10155185237526894 , Time: 18964.709453105927 s\n",
      "Batch:  430 , l1 Loss:  0.10214903280138969 , Time: 18977.647653102875 s\n",
      "Batch:  440 , l1 Loss:  0.10403145700693131 , Time: 18990.608419895172 s\n",
      "Batch:  450 , l1 Loss:  0.10268447026610375 , Time: 19003.560787439346 s\n",
      "Batch:  460 , l1 Loss:  0.10196192786097527 , Time: 19016.538643360138 s\n",
      "Batch:  470 , l1 Loss:  0.10153555944561958 , Time: 19029.534648895264 s\n",
      "Batch:  480 , l1 Loss:  0.10097107589244843 , Time: 19042.48892569542 s\n",
      "Batch:  490 , l1 Loss:  0.10243749320507049 , Time: 19055.449778795242 s\n",
      "Batch:  500 , l1 Loss:  0.10235876366496086 , Time: 19068.387518167496 s\n",
      "Batch:  510 , l1 Loss:  0.10072418227791786 , Time: 19081.36580300331 s\n",
      "Batch:  520 , l1 Loss:  0.104341259598732 , Time: 19094.278036355972 s\n",
      "Batch:  530 , l1 Loss:  0.10170686691999435 , Time: 19107.25440597534 s\n",
      "Batch:  540 , l1 Loss:  0.10332914814352989 , Time: 19120.232474327087 s\n",
      "Batch:  550 , l1 Loss:  0.10106785744428634 , Time: 19133.166199684143 s\n",
      "Batch:  560 , l1 Loss:  0.10442704856395721 , Time: 19146.269726514816 s\n",
      "Batch:  570 , l1 Loss:  0.10261616036295891 , Time: 19159.225519657135 s\n",
      "Batch:  580 , l1 Loss:  0.10367190614342689 , Time: 19172.16302728653 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  590 , l1 Loss:  0.10133177787065506 , Time: 19185.093391656876 s\n",
      "Batch:  600 , l1 Loss:  0.10514897033572197 , Time: 19198.035388231277 s\n",
      "Batch:  610 , l1 Loss:  0.10144117027521134 , Time: 19210.936295986176 s\n",
      "Batch:  620 , l1 Loss:  0.10183952227234841 , Time: 19223.84939956665 s\n",
      "Batch:  630 , l1 Loss:  0.10350258946418762 , Time: 19236.800542593002 s\n",
      "Batch:  640 , l1 Loss:  0.10191370695829391 , Time: 19249.681005954742 s\n",
      "Batch:  650 , l1 Loss:  0.09916811808943748 , Time: 19262.599314689636 s\n",
      "Batch:  660 , l1 Loss:  0.10215995535254478 , Time: 19275.52956223488 s\n",
      "Batch:  670 , l1 Loss:  0.10458474680781364 , Time: 19288.463523626328 s\n",
      "Batch:  680 , l1 Loss:  0.10220379382371902 , Time: 19301.384677648544 s\n",
      "Batch:  690 , l1 Loss:  0.10037873163819314 , Time: 19314.277300834656 s\n",
      "Batch:  700 , l1 Loss:  0.10164713189005851 , Time: 19327.194789409637 s\n",
      "Batch:  710 , l1 Loss:  0.10123834758996964 , Time: 19340.112315654755 s\n",
      "Batch:  720 , l1 Loss:  0.10122834667563438 , Time: 19353.05025625229 s\n",
      "Batch:  730 , l1 Loss:  0.10284189358353615 , Time: 19365.943177461624 s\n",
      "Batch:  740 , l1 Loss:  0.10100861117243767 , Time: 19378.819390535355 s\n",
      "Batch:  750 , l1 Loss:  0.10219090729951859 , Time: 19391.71871161461 s\n",
      "Batch:  760 , l1 Loss:  0.10146482586860657 , Time: 19404.6179459095 s\n",
      "Batch:  770 , l1 Loss:  0.10129792541265488 , Time: 19417.555325746536 s\n",
      "Batch:  780 , l1 Loss:  0.10282495617866516 , Time: 19430.530776023865 s\n",
      "Batch:  790 , l1 Loss:  0.10153213962912559 , Time: 19443.467261075974 s\n",
      "Batch:  800 , l1 Loss:  0.10089769661426544 , Time: 19456.42144870758 s\n",
      "Batch:  810 , l1 Loss:  0.10407759323716163 , Time: 19469.409245967865 s\n",
      "Batch:  820 , l1 Loss:  0.10130059272050858 , Time: 19482.386407852173 s\n",
      "Batch:  830 , l1 Loss:  0.10074282586574554 , Time: 19495.32686161995 s\n",
      "Batch:  840 , l1 Loss:  0.10252678990364075 , Time: 19508.26021051407 s\n",
      "Batch:  850 , l1 Loss:  0.10380767956376076 , Time: 19521.2142932415 s\n",
      "Batch:  860 , l1 Loss:  0.10533158332109452 , Time: 19534.132392406464 s\n",
      "Batch:  870 , l1 Loss:  0.10266314819455147 , Time: 19547.08682370186 s\n",
      "Batch:  880 , l1 Loss:  0.10246955379843711 , Time: 19560.149185180664 s\n",
      "Batch:  890 , l1 Loss:  0.10181191563606262 , Time: 19573.103173971176 s\n",
      "Batch:  900 , l1 Loss:  0.105033540725708 , Time: 19586.058065891266 s\n",
      "Batch:  910 , l1 Loss:  0.10242933332920075 , Time: 19599.01822257042 s\n",
      "Batch:  920 , l1 Loss:  0.10355961918830872 , Time: 19611.998557806015 s\n",
      "Batch:  930 , l1 Loss:  0.10116678327322007 , Time: 19624.9739484787 s\n",
      "Batch:  940 , l1 Loss:  0.10345452651381493 , Time: 19637.949025154114 s\n",
      "Batch:  950 , l1 Loss:  0.10066505223512649 , Time: 19650.927095651627 s\n",
      "Batch:  960 , l1 Loss:  0.1036105714738369 , Time: 19663.88510608673 s\n",
      "Batch:  970 , l1 Loss:  0.10234664529561996 , Time: 19676.861910820007 s\n",
      "Batch:  980 , l1 Loss:  0.102211581915617 , Time: 19689.83867263794 s\n",
      "Batch:  990 , l1 Loss:  0.09983478933572769 , Time: 19702.815036535263 s\n",
      "Batch:  1000 , l1 Loss:  0.10128375887870789 , Time: 19715.895471572876 s\n",
      "Batch:  1010 , l1 Loss:  0.1018526554107666 , Time: 19729.010937213898 s\n",
      "Batch:  1020 , l1 Loss:  0.10300935655832291 , Time: 19742.01901459694 s\n",
      "Batch:  1030 , l1 Loss:  0.10240156129002571 , Time: 19754.984722852707 s\n",
      "Batch:  1040 , l1 Loss:  0.1030214861035347 , Time: 19767.96187853813 s\n",
      "Batch:  1050 , l1 Loss:  0.10174722597002983 , Time: 19780.981476306915 s\n",
      "Batch:  1060 , l1 Loss:  0.1024562545120716 , Time: 19793.979736089706 s\n",
      "Batch:  1070 , l1 Loss:  0.09992735683918 , Time: 19806.928375005722 s\n",
      "Batch:  1080 , l1 Loss:  0.10355301275849342 , Time: 19819.91151380539 s\n",
      "Batch:  1090 , l1 Loss:  0.10250159129500389 , Time: 19832.78861808777 s\n",
      "Batch:  1100 , l1 Loss:  0.10274403244256973 , Time: 19845.62296319008 s\n",
      "Batch:  1110 , l1 Loss:  0.10345688089728355 , Time: 19858.458421468735 s\n",
      "Batch:  1120 , l1 Loss:  0.10331166833639145 , Time: 19871.34063386917 s\n",
      "Batch:  1130 , l1 Loss:  0.10290350019931793 , Time: 19884.19705939293 s\n",
      "Batch:  1140 , l1 Loss:  0.1033980093896389 , Time: 19897.07200026512 s\n",
      "Batch:  1150 , l1 Loss:  0.10292707458138466 , Time: 19909.986858844757 s\n",
      "Batch:  1160 , l1 Loss:  0.1018153689801693 , Time: 19922.90331888199 s\n",
      "Batch:  1170 , l1 Loss:  0.10144323408603668 , Time: 19935.821167469025 s\n",
      "Batch:  1180 , l1 Loss:  0.10326672047376632 , Time: 19948.83529996872 s\n",
      "Batch:  1190 , l1 Loss:  0.10002063065767289 , Time: 19961.81076312065 s\n",
      "Batch:  1200 , l1 Loss:  0.10077660828828812 , Time: 19974.76610159874 s\n",
      "Batch:  1210 , l1 Loss:  0.10071810334920883 , Time: 19987.700598478317 s\n",
      "Batch:  1220 , l1 Loss:  0.10265631824731827 , Time: 20000.63836455345 s\n",
      "Batch:  1230 , l1 Loss:  0.10144209936261177 , Time: 20013.577526807785 s\n",
      "Batch:  1240 , l1 Loss:  0.10363570749759674 , Time: 20026.514298439026 s\n",
      "Batch:  1250 , l1 Loss:  0.10248611271381378 , Time: 20039.426530361176 s\n",
      "Batch:  1260 , l1 Loss:  0.10190318897366524 , Time: 20052.321152210236 s\n",
      "Batch:  1270 , l1 Loss:  0.10090132057666779 , Time: 20065.206290006638 s\n",
      "Batch:  1280 , l1 Loss:  0.10028547942638397 , Time: 20078.165974617004 s\n",
      "Batch:  1290 , l1 Loss:  0.10212531164288521 , Time: 20091.07790493965 s\n",
      "Batch:  1300 , l1 Loss:  0.10451728701591492 , Time: 20103.995798110962 s\n",
      "Batch:  1310 , l1 Loss:  0.10252726674079896 , Time: 20116.91004061699 s\n",
      "Batch:  1320 , l1 Loss:  0.10148682668805123 , Time: 20129.827452659607 s\n",
      "Batch:  1330 , l1 Loss:  0.10436968654394149 , Time: 20142.745804071426 s\n",
      "Batch:  1340 , l1 Loss:  0.10375887602567672 , Time: 20155.65898656845 s\n",
      "Batch:  1350 , l1 Loss:  0.1032223142683506 , Time: 20168.58373260498 s\n",
      "Batch:  1360 , l1 Loss:  0.10225932598114014 , Time: 20181.473495960236 s\n",
      "Batch:  1370 , l1 Loss:  0.10331939458847046 , Time: 20194.414846420288 s\n",
      "Batch:  1380 , l1 Loss:  0.10232942029833794 , Time: 20207.333420038223 s\n",
      "Batch:  1390 , l1 Loss:  0.10154318287968636 , Time: 20220.267570734024 s\n",
      "Batch:  1400 , l1 Loss:  0.10177876427769661 , Time: 20233.2014939785 s\n",
      "Batch:  1410 , l1 Loss:  0.10062315985560417 , Time: 20246.138658046722 s\n",
      "Batch:  1420 , l1 Loss:  0.10272787660360336 , Time: 20259.05429315567 s\n",
      "Batch:  1430 , l1 Loss:  0.1022152692079544 , Time: 20271.966371059418 s\n",
      "Batch:  1440 , l1 Loss:  0.10099133998155593 , Time: 20284.890899658203 s\n",
      "Batch:  1450 , l1 Loss:  0.10029899626970291 , Time: 20297.843945741653 s\n",
      "Batch:  1460 , l1 Loss:  0.10153344571590424 , Time: 20310.817202806473 s\n",
      "Batch:  1470 , l1 Loss:  0.102808977663517 , Time: 20323.736020565033 s\n",
      "Batch:  1480 , l1 Loss:  0.1023601233959198 , Time: 20336.68062901497 s\n",
      "Batch:  1490 , l1 Loss:  0.102248065918684 , Time: 20349.572405338287 s\n",
      "Batch:  1500 , l1 Loss:  0.1039712205529213 , Time: 20362.50706076622 s\n",
      "Batch:  1510 , l1 Loss:  0.10196407809853554 , Time: 20375.500935316086 s\n",
      "Batch:  1520 , l1 Loss:  0.10488538816571236 , Time: 20388.45707678795 s\n",
      "Batch:  1530 , l1 Loss:  0.10355907902121544 , Time: 20401.39995455742 s\n",
      "Batch:  1540 , l1 Loss:  0.10384605303406716 , Time: 20414.358872890472 s\n",
      "Batch:  1550 , l1 Loss:  0.10185752511024475 , Time: 20427.33301591873 s\n",
      "Batch:  1560 , l1 Loss:  0.10114522725343704 , Time: 20440.287560224533 s\n",
      "Batch:  1570 , l1 Loss:  0.10241502597928047 , Time: 20453.2457716465 s\n",
      "Batch:  1580 , l1 Loss:  0.1031393438577652 , Time: 20466.225932359695 s\n",
      "Batch:  1590 , l1 Loss:  0.10100519210100174 , Time: 20479.24634552002 s\n",
      "Batch:  1600 , l1 Loss:  0.1030278779566288 , Time: 20492.221165657043 s\n",
      "Batch:  1610 , l1 Loss:  0.10342718660831451 , Time: 20505.157520532608 s\n",
      "Batch:  1620 , l1 Loss:  0.10094446167349816 , Time: 20518.13289475441 s\n",
      "Batch:  1630 , l1 Loss:  0.10268551409244538 , Time: 20531.108894586563 s\n",
      "Batch:  1640 , l1 Loss:  0.10182376578450203 , Time: 20544.210544347763 s\n",
      "Batch:  1650 , l1 Loss:  0.09943907856941223 , Time: 20557.288872003555 s\n",
      "Batch:  1660 , l1 Loss:  0.10194898024201393 , Time: 20570.306285858154 s\n",
      "Batch:  1670 , l1 Loss:  0.10475228801369667 , Time: 20583.317331790924 s\n",
      "Batch:  1680 , l1 Loss:  0.10210509449243546 , Time: 20596.297287464142 s\n",
      "Batch:  1690 , l1 Loss:  0.1030444972217083 , Time: 20609.27996277809 s\n",
      "Batch:  1700 , l1 Loss:  0.10166668444871903 , Time: 20622.30744957924 s\n",
      "Batch:  1710 , l1 Loss:  0.10080120787024498 , Time: 20635.207297325134 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  1720 , l1 Loss:  0.10303688123822212 , Time: 20648.18138217926 s\n",
      "Batch:  1730 , l1 Loss:  0.10309863537549972 , Time: 20661.147671461105 s\n",
      "Batch:  1740 , l1 Loss:  0.10065256282687188 , Time: 20674.15418434143 s\n",
      "Batch:  1750 , l1 Loss:  0.099588543176651 , Time: 20687.133922100067 s\n",
      "Batch:  1760 , l1 Loss:  0.10301246419548989 , Time: 20700.129646539688 s\n",
      "Batch:  1770 , l1 Loss:  0.1032145656645298 , Time: 20713.065435647964 s\n",
      "Batch:  1780 , l1 Loss:  0.10258913636207581 , Time: 20726.057560920715 s\n",
      "Batch:  1790 , l1 Loss:  0.1006972149014473 , Time: 20739.12262248993 s\n",
      "Batch:  1800 , l1 Loss:  0.10199219584465027 , Time: 20752.204557657242 s\n",
      "Batch:  1810 , l1 Loss:  0.1047582633793354 , Time: 20765.257970571518 s\n",
      "Batch:  1820 , l1 Loss:  0.1026942141354084 , Time: 20778.155484199524 s\n",
      "Batch:  1830 , l1 Loss:  0.10379894003272057 , Time: 20791.05418777466 s\n",
      "Batch:  1840 , l1 Loss:  0.10468000024557114 , Time: 20803.987063884735 s\n",
      "Batch:  1850 , l1 Loss:  0.10677537396550178 , Time: 20816.906175613403 s\n",
      "Batch:  1860 , l1 Loss:  0.10396259427070617 , Time: 20829.86323928833 s\n",
      "Batch:  1870 , l1 Loss:  0.10408039540052413 , Time: 20842.780658721924 s\n",
      "Batch:  1880 , l1 Loss:  0.10504240095615387 , Time: 20855.73739218712 s\n",
      "Batch:  1890 , l1 Loss:  0.10552010536193848 , Time: 20868.69776558876 s\n",
      "Batch:  1900 , l1 Loss:  0.10294563248753548 , Time: 20881.67143702507 s\n",
      "Batch:  1910 , l1 Loss:  0.10159630924463273 , Time: 20894.628443956375 s\n",
      "Batch:  1920 , l1 Loss:  0.10124899223446845 , Time: 20907.58700609207 s\n",
      "Batch:  1930 , l1 Loss:  0.10384023040533066 , Time: 20920.579292535782 s\n",
      "Batch:  1940 , l1 Loss:  0.10262256637215614 , Time: 20933.515743017197 s\n",
      "Batch:  1950 , l1 Loss:  0.10262522697448731 , Time: 20946.59807229042 s\n",
      "Batch:  1960 , l1 Loss:  0.10202891975641251 , Time: 20959.626586198807 s\n",
      "Batch:  1970 , l1 Loss:  0.10277883186936379 , Time: 20972.54132628441 s\n",
      "Batch:  1980 , l1 Loss:  0.10172130614519119 , Time: 20985.45107150078 s\n",
      "Batch:  1990 , l1 Loss:  0.10275209695100784 , Time: 20998.426754951477 s\n",
      "Batch:  2000 , l1 Loss:  0.10091581717133521 , Time: 21011.388040065765 s\n",
      "Batch:  2010 , l1 Loss:  0.10172763019800186 , Time: 21024.384935855865 s\n",
      "Batch:  2020 , l1 Loss:  0.10228374153375626 , Time: 21037.327171087265 s\n",
      "Batch:  2030 , l1 Loss:  0.1042511023581028 , Time: 21050.279893636703 s\n",
      "Batch:  2040 , l1 Loss:  0.09999095872044564 , Time: 21063.186116933823 s\n",
      "Batch:  2050 , l1 Loss:  0.1016506314277649 , Time: 21076.109431266785 s\n",
      "Batch:  2060 , l1 Loss:  0.10233002230525017 , Time: 21089.04941701889 s\n",
      "Batch:  2070 , l1 Loss:  0.10135563537478447 , Time: 21101.96493434906 s\n",
      "Batch:  2080 , l1 Loss:  0.10164318457245827 , Time: 21114.91689968109 s\n",
      "Batch:  2090 , l1 Loss:  0.10340159684419632 , Time: 21127.834210157394 s\n",
      "Batch:  2100 , l1 Loss:  0.10199448466300964 , Time: 21140.754833221436 s\n",
      "Batch:  2110 , l1 Loss:  0.10093980506062508 , Time: 21153.71320962906 s\n",
      "Batch:  2120 , l1 Loss:  0.10319148674607277 , Time: 21166.648609399796 s\n",
      "Batch:  2130 , l1 Loss:  0.10158522874116897 , Time: 21179.580023288727 s\n",
      "Batch:  2140 , l1 Loss:  0.10434701219201088 , Time: 21192.479570388794 s\n",
      "Batch:  2150 , l1 Loss:  0.1023040995001793 , Time: 21205.35864520073 s\n",
      "Batch:  2160 , l1 Loss:  0.10174630358815193 , Time: 21218.2775683403 s\n",
      "Batch:  2170 , l1 Loss:  0.10118402093648911 , Time: 21231.17639040947 s\n",
      "Batch:  2180 , l1 Loss:  0.10001143887639045 , Time: 21244.08890271187 s\n",
      "Batch:  2190 , l1 Loss:  0.10257566720247269 , Time: 21257.004046201706 s\n",
      "Batch:  2200 , l1 Loss:  0.10160099938511849 , Time: 21269.926068544388 s\n",
      "Batch:  2210 , l1 Loss:  0.1044518657028675 , Time: 21282.800968170166 s\n",
      "Batch:  2220 , l1 Loss:  0.10191481411457062 , Time: 21295.693600416183 s\n",
      "Batch:  2230 , l1 Loss:  0.101753930747509 , Time: 21308.555636882782 s\n",
      "Batch:  2240 , l1 Loss:  0.09924490228295327 , Time: 21321.451035499573 s\n",
      "Batch:  2250 , l1 Loss:  0.09991445094347 , Time: 21334.325483322144 s\n",
      "Batch:  2260 , l1 Loss:  0.1001735933125019 , Time: 21347.24417901039 s\n",
      "Batch:  2270 , l1 Loss:  0.10246190875768661 , Time: 21360.141607284546 s\n",
      "Batch:  2280 , l1 Loss:  0.10382195636630058 , Time: 21373.09493279457 s\n",
      "Batch:  2290 , l1 Loss:  0.10336860567331314 , Time: 21386.005996227264 s\n",
      "Batch:  2300 , l1 Loss:  0.10399682521820068 , Time: 21398.969715833664 s\n",
      "Batch:  2310 , l1 Loss:  0.10238375067710877 , Time: 21411.843939065933 s\n",
      "Batch:  2320 , l1 Loss:  0.10337789133191108 , Time: 21424.741018772125 s\n",
      "Batch:  2330 , l1 Loss:  0.10202023833990097 , Time: 21437.63748407364 s\n",
      "Batch:  2340 , l1 Loss:  0.10393597558140755 , Time: 21450.518198251724 s\n",
      "Batch:  2350 , l1 Loss:  0.10047848001122475 , Time: 21463.433380126953 s\n",
      "Batch:  2360 , l1 Loss:  0.1007611721754074 , Time: 21476.33124232292 s\n",
      "Batch:  2370 , l1 Loss:  0.10232071802020073 , Time: 21489.23194050789 s\n",
      "Batch:  2380 , l1 Loss:  0.1007025919854641 , Time: 21502.129628896713 s\n",
      "Batch:  2390 , l1 Loss:  0.10173303857445717 , Time: 21515.102116584778 s\n",
      "Batch:  2400 , l1 Loss:  0.1006886176764965 , Time: 21527.99855208397 s\n",
      "Batch:  2410 , l1 Loss:  0.1013108491897583 , Time: 21540.938143491745 s\n",
      "Batch:  2420 , l1 Loss:  0.10083216205239295 , Time: 21553.933587789536 s\n",
      "Batch:  2430 , l1 Loss:  0.10036000311374664 , Time: 21566.90933895111 s\n",
      "Batch:  2440 , l1 Loss:  0.10294175148010254 , Time: 21579.865624904633 s\n",
      "Batch:  2450 , l1 Loss:  0.09917111620306969 , Time: 21592.833664655685 s\n",
      "Batch:  2460 , l1 Loss:  0.10098891854286193 , Time: 21605.78137397766 s\n",
      "Batch:  2470 , l1 Loss:  0.10313220173120499 , Time: 21618.77991628647 s\n",
      "Batch:  2480 , l1 Loss:  0.10030089989304543 , Time: 21631.778245687485 s\n",
      "Batch:  2490 , l1 Loss:  0.1017902635037899 , Time: 21644.75434279442 s\n",
      "Batch:  2500 , l1 Loss:  0.10287104249000549 , Time: 21657.706496715546 s\n",
      "Batch:  2510 , l1 Loss:  0.10316474735736847 , Time: 21670.7630546093 s\n",
      "Batch:  2520 , l1 Loss:  0.10209986865520478 , Time: 21683.702520132065 s\n",
      "Batch:  2530 , l1 Loss:  0.10234377533197403 , Time: 21696.678779125214 s\n",
      "Batch:  2540 , l1 Loss:  0.1034635253250599 , Time: 21709.64908504486 s\n",
      "Batch:  2550 , l1 Loss:  0.1027295358479023 , Time: 21722.648414850235 s\n",
      "Batch:  2560 , l1 Loss:  0.10245697423815728 , Time: 21735.592569589615 s\n",
      "Batch:  2570 , l1 Loss:  0.10187684372067451 , Time: 21748.605850458145 s\n",
      "Batch:  2580 , l1 Loss:  0.10234490409493446 , Time: 21761.586585998535 s\n",
      "Batch:  2590 , l1 Loss:  0.10083363875746727 , Time: 21774.537012815475 s\n",
      "Batch:  2600 , l1 Loss:  0.09950497150421142 , Time: 21787.626884937286 s\n",
      "Batch:  2610 , l1 Loss:  0.10077464655041694 , Time: 21800.60403776169 s\n",
      "Batch:  2620 , l1 Loss:  0.10320980995893478 , Time: 21813.56450510025 s\n",
      "Batch:  2630 , l1 Loss:  0.10071433335542679 , Time: 21826.50356388092 s\n",
      "Batch:  2640 , l1 Loss:  0.10066041201353074 , Time: 21839.441060066223 s\n",
      "Batch:  2650 , l1 Loss:  0.1014606386423111 , Time: 21852.38000535965 s\n",
      "Batch:  2660 , l1 Loss:  0.10265539288520813 , Time: 21865.35255050659 s\n",
      "Batch:  2670 , l1 Loss:  0.10207957029342651 , Time: 21878.324010849 s\n",
      "Batch:  2680 , l1 Loss:  0.10226658135652542 , Time: 21891.26834344864 s\n",
      "Batch:  2690 , l1 Loss:  0.10020009726285935 , Time: 21904.223198890686 s\n",
      "Batch:  2700 , l1 Loss:  0.10235977321863174 , Time: 21917.178545475006 s\n",
      "Batch:  2710 , l1 Loss:  0.10177920982241631 , Time: 21930.129031181335 s\n",
      "Batch:  2720 , l1 Loss:  0.10071875378489495 , Time: 21943.06974172592 s\n",
      "Batch:  2730 , l1 Loss:  0.10039326474070549 , Time: 21956.01053071022 s\n",
      "Batch:  2740 , l1 Loss:  0.10159290805459023 , Time: 21968.960803747177 s\n",
      "Batch:  2750 , l1 Loss:  0.10328585430979728 , Time: 21981.89922952652 s\n",
      "Batch:  2760 , l1 Loss:  0.10106693208217621 , Time: 21994.83697271347 s\n",
      "Batch:  2770 , l1 Loss:  0.10101911649107934 , Time: 22007.799787282944 s\n",
      "Batch:  2780 , l1 Loss:  0.10022852569818497 , Time: 22020.65851211548 s\n",
      "Batch:  2790 , l1 Loss:  0.10090544745326042 , Time: 22033.53761768341 s\n",
      "Batch:  2800 , l1 Loss:  0.10044382363557816 , Time: 22046.45121860504 s\n",
      "Batch:  2810 , l1 Loss:  0.10221188068389893 , Time: 22059.345346927643 s\n",
      "Batch:  2820 , l1 Loss:  0.10183349177241326 , Time: 22072.29528570175 s\n",
      "Batch:  2830 , l1 Loss:  0.1007104367017746 , Time: 22085.196466445923 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  2840 , l1 Loss:  0.10545584261417389 , Time: 22098.131308555603 s\n",
      "Batch:  2850 , l1 Loss:  0.10223342850804329 , Time: 22111.13097167015 s\n",
      "Batch:  2860 , l1 Loss:  0.1011072002351284 , Time: 22124.089428901672 s\n",
      "Batch:  2870 , l1 Loss:  0.10200414434075356 , Time: 22137.065145254135 s\n",
      "Batch:  2880 , l1 Loss:  0.10208194404840469 , Time: 22150.10292863846 s\n",
      "Batch:  2890 , l1 Loss:  0.09981720298528671 , Time: 22163.083998918533 s\n",
      "Batch:  2900 , l1 Loss:  0.10235111489892006 , Time: 22176.12290453911 s\n",
      "Batch:  2910 , l1 Loss:  0.10320847034454346 , Time: 22189.09217453003 s\n",
      "Batch:  2920 , l1 Loss:  0.10144681558012962 , Time: 22202.132350206375 s\n",
      "Batch:  2930 , l1 Loss:  0.10025516971945762 , Time: 22215.25816822052 s\n",
      "Batch:  2940 , l1 Loss:  0.10062126740813256 , Time: 22228.369537591934 s\n",
      "Batch:  2950 , l1 Loss:  0.10009031444787979 , Time: 22241.500529527664 s\n",
      "Batch:  2960 , l1 Loss:  0.10247887894511223 , Time: 22254.580592870712 s\n",
      "Batch:  2970 , l1 Loss:  0.10254285708069802 , Time: 22267.63497018814 s\n",
      "Batch:  2980 , l1 Loss:  0.10350011065602302 , Time: 22280.738439321518 s\n",
      "Batch:  2990 , l1 Loss:  0.1029220812022686 , Time: 22293.768790006638 s\n",
      "Batch:  3000 , l1 Loss:  0.09961102828383446 , Time: 22306.78593301773 s\n",
      "Batch:  3010 , l1 Loss:  0.10427533909678459 , Time: 22319.917449712753 s\n",
      "Batch:  3020 , l1 Loss:  0.10040422901511192 , Time: 22332.907880544662 s\n",
      "Batch:  3030 , l1 Loss:  0.10012200698256493 , Time: 22345.987436294556 s\n",
      "Batch:  3040 , l1 Loss:  0.10267954990267754 , Time: 22359.0458009243 s\n",
      "Batch:  3050 , l1 Loss:  0.10132309570908546 , Time: 22372.065109968185 s\n",
      "Batch:  3060 , l1 Loss:  0.1021308995783329 , Time: 22385.118203639984 s\n",
      "Batch:  3070 , l1 Loss:  0.10178649425506592 , Time: 22398.13183093071 s\n",
      "Batch:  3080 , l1 Loss:  0.10188519358634948 , Time: 22411.166493415833 s\n",
      "Batch:  3090 , l1 Loss:  0.10004967376589775 , Time: 22424.16428041458 s\n",
      "Batch:  3100 , l1 Loss:  0.10041616410017014 , Time: 22437.186822891235 s\n",
      "Batch:  3110 , l1 Loss:  0.10196713581681252 , Time: 22450.22010421753 s\n",
      "Batch:  3120 , l1 Loss:  0.10210622251033782 , Time: 22463.237239599228 s\n",
      "Batch:  3130 , l1 Loss:  0.10067276060581207 , Time: 22476.175589084625 s\n",
      "Batch:  3140 , l1 Loss:  0.10108542889356613 , Time: 22488.97492313385 s\n",
      "Batch:  3150 , l1 Loss:  0.10068292543292046 , Time: 22501.77263689041 s\n",
      "Batch:  3160 , l1 Loss:  0.10316714644432068 , Time: 22514.687308073044 s\n",
      "Batch:  3170 , l1 Loss:  0.09948646426200866 , Time: 22527.645866155624 s\n",
      "Batch:  3180 , l1 Loss:  0.10086560845375062 , Time: 22540.559471845627 s\n",
      "Batch:  3190 , l1 Loss:  0.10217182487249374 , Time: 22553.49580168724 s\n",
      "Batch:  3200 , l1 Loss:  0.10271001011133193 , Time: 22566.415623903275 s\n",
      "Batch:  3210 , l1 Loss:  0.10092128813266754 , Time: 22579.313901901245 s\n",
      "Batch:  3220 , l1 Loss:  0.10152111053466797 , Time: 22592.264922380447 s\n",
      "Batch:  3230 , l1 Loss:  0.10223152935504913 , Time: 22605.18115925789 s\n",
      "Batch:  3240 , l1 Loss:  0.10246755629777908 , Time: 22618.091110229492 s\n",
      "Batch:  3250 , l1 Loss:  0.1013210617005825 , Time: 22631.013480901718 s\n",
      "Batch:  3260 , l1 Loss:  0.1019678071141243 , Time: 22643.931896924973 s\n",
      "Batch:  3270 , l1 Loss:  0.10053804889321327 , Time: 22656.811766386032 s\n",
      "Batch:  3280 , l1 Loss:  0.10061866119503975 , Time: 22669.70564866066 s\n",
      "Batch:  3290 , l1 Loss:  0.10151906013488769 , Time: 22682.602032661438 s\n",
      "Batch:  3300 , l1 Loss:  0.09978760182857513 , Time: 22695.478816986084 s\n",
      "Batch:  3310 , l1 Loss:  0.10231295377016067 , Time: 22708.395521879196 s\n",
      "Batch:  3320 , l1 Loss:  0.10154908448457718 , Time: 22721.29148387909 s\n",
      "Batch:  3330 , l1 Loss:  0.09994259402155876 , Time: 22734.164300203323 s\n",
      "Batch:  3340 , l1 Loss:  0.10043450817465782 , Time: 22747.095710515976 s\n",
      "Batch:  3350 , l1 Loss:  0.10152856707572937 , Time: 22760.040808200836 s\n",
      "Batch:  3360 , l1 Loss:  0.0996427670121193 , Time: 22772.97989344597 s\n",
      "Batch:  3370 , l1 Loss:  0.1007485680282116 , Time: 22785.911206007004 s\n",
      "Batch:  3380 , l1 Loss:  0.10373900756239891 , Time: 22798.890278816223 s\n",
      "Batch:  3390 , l1 Loss:  0.1002288080751896 , Time: 22811.868092298508 s\n",
      "Batch:  3400 , l1 Loss:  0.10208628177642823 , Time: 22824.80745458603 s\n",
      "Batch:  3410 , l1 Loss:  0.10367861837148666 , Time: 22837.787382364273 s\n",
      "Batch:  3420 , l1 Loss:  0.10082272738218308 , Time: 22850.75798201561 s\n",
      "Batch:  3430 , l1 Loss:  0.100229262560606 , Time: 22863.686213731766 s\n",
      "Batch:  3440 , l1 Loss:  0.10099903643131256 , Time: 22876.616376161575 s\n",
      "Batch:  3450 , l1 Loss:  0.10104886963963508 , Time: 22889.612107753754 s\n",
      "Batch:  3460 , l1 Loss:  0.1037374846637249 , Time: 22902.536412477493 s\n",
      "Batch:  3470 , l1 Loss:  0.10128570571541787 , Time: 22915.508783578873 s\n",
      "Batch:  3480 , l1 Loss:  0.1019982747733593 , Time: 22928.442801475525 s\n",
      "Batch:  3490 , l1 Loss:  0.10216387510299682 , Time: 22941.384141921997 s\n",
      "Batch:  3500 , l1 Loss:  0.10234222635626793 , Time: 22954.351891994476 s\n",
      "Batch:  3510 , l1 Loss:  0.10612390786409379 , Time: 22967.39232110977 s\n",
      "Batch:  3520 , l1 Loss:  0.10533964186906815 , Time: 22980.329683065414 s\n",
      "Batch:  3530 , l1 Loss:  0.10510195940732955 , Time: 22993.263653039932 s\n",
      "Batch:  3540 , l1 Loss:  0.10420691072940827 , Time: 23006.197558641434 s\n",
      "Batch:  3550 , l1 Loss:  0.10582101717591286 , Time: 23019.112102746964 s\n",
      "Batch:  3560 , l1 Loss:  0.11188262179493905 , Time: 23032.049285411835 s\n",
      "Batch:  3570 , l1 Loss:  0.10980947688221931 , Time: 23045.005443811417 s\n",
      "Batch:  3580 , l1 Loss:  0.10925457626581192 , Time: 23057.959129571915 s\n",
      "Batch:  3590 , l1 Loss:  0.10722807571291923 , Time: 23070.93177986145 s\n",
      "Batch:  3600 , l1 Loss:  0.10718057155609131 , Time: 23083.90199780464 s\n",
      "Batch:  3610 , l1 Loss:  0.1051591195166111 , Time: 23096.83035135269 s\n",
      "Batch:  3620 , l1 Loss:  0.10601564571261406 , Time: 23109.80286836624 s\n",
      "Batch:  3630 , l1 Loss:  0.10310652032494545 , Time: 23122.75811958313 s\n",
      "Batch:  3640 , l1 Loss:  0.10479382127523422 , Time: 23135.712547779083 s\n",
      "Batch:  3650 , l1 Loss:  0.10485438778996467 , Time: 23148.643623828888 s\n",
      "Batch:  3660 , l1 Loss:  0.10361218303442002 , Time: 23161.539541244507 s\n",
      "Batch:  3670 , l1 Loss:  0.10178307145833969 , Time: 23174.457469701767 s\n",
      "Batch:  3680 , l1 Loss:  0.10390089675784112 , Time: 23187.38884782791 s\n",
      "Batch:  3690 , l1 Loss:  0.10362158119678497 , Time: 23200.2838640213 s\n",
      "Batch:  3700 , l1 Loss:  0.10284287706017495 , Time: 23213.179268360138 s\n",
      "Batch:  3710 , l1 Loss:  0.10158523172140121 , Time: 23226.073342323303 s\n",
      "Batch:  3720 , l1 Loss:  0.10485204458236694 , Time: 23239.017913341522 s\n",
      "Batch:  3730 , l1 Loss:  0.10298893451690674 , Time: 23251.946182727814 s\n",
      "Batch:  3740 , l1 Loss:  0.10274017155170441 , Time: 23264.85916185379 s\n",
      "Batch:  3750 , l1 Loss:  0.10292731001973152 , Time: 23277.78191781044 s\n",
      "Batch:  3760 , l1 Loss:  0.10260480344295501 , Time: 23290.71239089966 s\n",
      "Batch:  3770 , l1 Loss:  0.10325828567147255 , Time: 23303.629145622253 s\n",
      "Batch:  3780 , l1 Loss:  0.10247542634606362 , Time: 23316.620432138443 s\n",
      "Batch:  3790 , l1 Loss:  0.10155084878206252 , Time: 23329.562207221985 s\n",
      "Batch:  3800 , l1 Loss:  0.10153350681066513 , Time: 23342.48695588112 s\n",
      "Batch:  3810 , l1 Loss:  0.10259320810437203 , Time: 23355.325484514236 s\n",
      "Batch:  3820 , l1 Loss:  0.10370638445019723 , Time: 23368.208991765976 s\n",
      "Batch:  3830 , l1 Loss:  0.10179100409150124 , Time: 23381.071085453033 s\n",
      "Batch:  3840 , l1 Loss:  0.10399310365319252 , Time: 23393.926381349564 s\n",
      "Batch:  3850 , l1 Loss:  0.10164240822196006 , Time: 23406.839109897614 s\n",
      "Batch:  3860 , l1 Loss:  0.1022265188395977 , Time: 23419.755934238434 s\n",
      "Batch:  3870 , l1 Loss:  0.10505076944828033 , Time: 23432.696093797684 s\n",
      "Batch:  3880 , l1 Loss:  0.10348636656999588 , Time: 23445.652292490005 s\n",
      "Batch:  3890 , l1 Loss:  0.10289500951766968 , Time: 23458.590111732483 s\n",
      "Batch:  3900 , l1 Loss:  0.10121063590049743 , Time: 23471.56576037407 s\n",
      "Batch:  3910 , l1 Loss:  0.10120394676923752 , Time: 23484.52446246147 s\n",
      "Batch:  3920 , l1 Loss:  0.10189851671457291 , Time: 23497.500281572342 s\n",
      "Batch:  3930 , l1 Loss:  0.10181237161159515 , Time: 23510.48123073578 s\n",
      "Batch:  3940 , l1 Loss:  0.10200426280498505 , Time: 23523.451417922974 s\n",
      "Batch:  3950 , l1 Loss:  0.10189313516020775 , Time: 23536.393715143204 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  3960 , l1 Loss:  0.10209522917866706 , Time: 23549.411649227142 s\n",
      "Batch:  3970 , l1 Loss:  0.10054313465952873 , Time: 23562.39328813553 s\n",
      "Batch:  3980 , l1 Loss:  0.10439046993851661 , Time: 23575.371765375137 s\n",
      "Batch:  3990 , l1 Loss:  0.10179613381624222 , Time: 23588.290605545044 s\n",
      "Batch:  4000 , l1 Loss:  0.1031246930360794 , Time: 23601.270037651062 s\n",
      "Batch:  4010 , l1 Loss:  0.10229721441864967 , Time: 23614.263493537903 s\n",
      "Batch:  4020 , l1 Loss:  0.10407048910856247 , Time: 23627.238141059875 s\n",
      "Batch:  4030 , l1 Loss:  0.10249204710125923 , Time: 23640.23616361618 s\n",
      "Batch:  4040 , l1 Loss:  0.10046897307038308 , Time: 23653.174507379532 s\n",
      "Batch:  4050 , l1 Loss:  0.10072513520717621 , Time: 23666.16606760025 s\n",
      "Batch:  4060 , l1 Loss:  0.10137928426265716 , Time: 23679.18185400963 s\n",
      "Batch:  4070 , l1 Loss:  0.1010911799967289 , Time: 23692.161667346954 s\n",
      "Batch:  4080 , l1 Loss:  0.10025181695818901 , Time: 23705.10351228714 s\n",
      "Batch:  4090 , l1 Loss:  0.10125950574874878 , Time: 23718.097181797028 s\n",
      "Batch:  4100 , l1 Loss:  0.10151835903525352 , Time: 23731.075535535812 s\n",
      "Batch:  4110 , l1 Loss:  0.10243917480111123 , Time: 23744.074224948883 s\n",
      "Batch:  4120 , l1 Loss:  0.1023162804543972 , Time: 23757.029630422592 s\n",
      "Batch:  4130 , l1 Loss:  0.10257400721311569 , Time: 23770.00931096077 s\n",
      "Batch:  4140 , l1 Loss:  0.10243377164006233 , Time: 23783.02864432335 s\n",
      "Batch:  4150 , l1 Loss:  0.09973132610321045 , Time: 23796.06546521187 s\n",
      "Batch:  4160 , l1 Loss:  0.10298914909362793 , Time: 23809.123267412186 s\n",
      "Batch:  4170 , l1 Loss:  0.10127618908882141 , Time: 23822.098908901215 s\n",
      "Batch:  4180 , l1 Loss:  0.09858505949378013 , Time: 23835.120663166046 s\n",
      "Batch:  4190 , l1 Loss:  0.10257684290409089 , Time: 23848.137219905853 s\n",
      "Batch:  4200 , l1 Loss:  0.10060779228806496 , Time: 23861.102066993713 s\n",
      "Batch:  4210 , l1 Loss:  0.09987372010946274 , Time: 23874.107995271683 s\n",
      "Batch:  4220 , l1 Loss:  0.10058641880750656 , Time: 23887.101685762405 s\n",
      "Batch:  4230 , l1 Loss:  0.09953809231519699 , Time: 23900.09697008133 s\n",
      "Batch:  4240 , l1 Loss:  0.10039985775947571 , Time: 23913.11972761154 s\n",
      "Batch:  4250 , l1 Loss:  0.1004662737250328 , Time: 23926.114623069763 s\n",
      "Batch:  4260 , l1 Loss:  0.10167387276887893 , Time: 23939.09005022049 s\n",
      "Batch:  4270 , l1 Loss:  0.10131453350186348 , Time: 23952.207550525665 s\n",
      "Batch:  4280 , l1 Loss:  0.10109577029943466 , Time: 23965.283529281616 s\n",
      "Batch:  4290 , l1 Loss:  0.1043953225016594 , Time: 23978.296905994415 s\n",
      "Batch:  4300 , l1 Loss:  0.10214735493063927 , Time: 23991.29679965973 s\n",
      "Batch:  4310 , l1 Loss:  0.10309689864516258 , Time: 24004.31245493889 s\n",
      "Batch:  4320 , l1 Loss:  0.10070199444890023 , Time: 24017.286954402924 s\n",
      "Batch:  4330 , l1 Loss:  0.10225341469049454 , Time: 24030.242006778717 s\n",
      "Batch:  4340 , l1 Loss:  0.1026192508637905 , Time: 24043.176817178726 s\n",
      "Batch:  4350 , l1 Loss:  0.10389929637312889 , Time: 24056.177040815353 s\n",
      "Batch:  4360 , l1 Loss:  0.10187314078211784 , Time: 24069.15673661232 s\n",
      "Batch:  4370 , l1 Loss:  0.10032196193933487 , Time: 24082.08956336975 s\n",
      "Batch:  4380 , l1 Loss:  0.10082478299736977 , Time: 24095.026407003403 s\n",
      "Batch:  4390 , l1 Loss:  0.10115978717803956 , Time: 24107.981814146042 s\n",
      "Batch:  4400 , l1 Loss:  0.10020611435174942 , Time: 24120.878269433975 s\n",
      "Batch:  4410 , l1 Loss:  0.09951354041695595 , Time: 24133.794814825058 s\n",
      "Batch:  4420 , l1 Loss:  0.09971551150083542 , Time: 24146.737330913544 s\n",
      "Batch:  4430 , l1 Loss:  0.10212868601083755 , Time: 24159.69432091713 s\n",
      "Batch:  4440 , l1 Loss:  0.1038665883243084 , Time: 24172.592526435852 s\n",
      "Batch:  4450 , l1 Loss:  0.10382749959826469 , Time: 24185.511927127838 s\n",
      "Batch:  4460 , l1 Loss:  0.10016758441925049 , Time: 24198.404490709305 s\n",
      "Batch:  4470 , l1 Loss:  0.10150352492928505 , Time: 24211.34686255455 s\n",
      "Batch:  4480 , l1 Loss:  0.10165006071329116 , Time: 24224.283848285675 s\n",
      "Batch:  4490 , l1 Loss:  0.10136754363775254 , Time: 24237.183578968048 s\n",
      "Batch:  4500 , l1 Loss:  0.10069274380803109 , Time: 24250.096797466278 s\n",
      "Batch:  4510 , l1 Loss:  0.10102538838982582 , Time: 24263.12105345726 s\n",
      "Batch:  4520 , l1 Loss:  0.09979984983801841 , Time: 24276.08055996895 s\n",
      "Batch:  4530 , l1 Loss:  0.09925822615623474 , Time: 24288.99716925621 s\n",
      "Batch:  4540 , l1 Loss:  0.10082266107201576 , Time: 24301.93368911743 s\n",
      "Batch:  4550 , l1 Loss:  0.10035061985254287 , Time: 24314.86300611496 s\n",
      "Batch:  4560 , l1 Loss:  0.09895214661955834 , Time: 24327.770396232605 s\n",
      "Batch:  4570 , l1 Loss:  0.10122356042265893 , Time: 24340.725705623627 s\n",
      "Batch:  4580 , l1 Loss:  0.10297439470887185 , Time: 24353.658878326416 s\n",
      "Batch:  4590 , l1 Loss:  0.10032456144690513 , Time: 24366.55885076523 s\n",
      "Batch:  4600 , l1 Loss:  0.10196757093071937 , Time: 24379.479204654694 s\n",
      "Batch:  4610 , l1 Loss:  0.10238064527511596 , Time: 24392.45509815216 s\n",
      "Batch:  4620 , l1 Loss:  0.10101732686161995 , Time: 24405.37262392044 s\n",
      "Batch:  4630 , l1 Loss:  0.10282954350113868 , Time: 24418.269948244095 s\n",
      "Batch:  4640 , l1 Loss:  0.10248124748468398 , Time: 24431.1999001503 s\n",
      "Batch:  4650 , l1 Loss:  0.10083581432700157 , Time: 24444.076902151108 s\n",
      "Batch:  4660 , l1 Loss:  0.10292406007647514 , Time: 24456.935814380646 s\n",
      "Batch:  4670 , l1 Loss:  0.10436341613531112 , Time: 24469.833423376083 s\n",
      "Batch:  4680 , l1 Loss:  0.10124603882431985 , Time: 24482.750725984573 s\n",
      "Batch:  4690 , l1 Loss:  0.10219609290361405 , Time: 24495.664258003235 s\n",
      "Batch:  4700 , l1 Loss:  0.09952265992760659 , Time: 24508.610563755035 s\n",
      "Batch:  4710 , l1 Loss:  0.09944453164935112 , Time: 24521.520323991776 s\n",
      "Batch:  4720 , l1 Loss:  0.1026421532034874 , Time: 24534.398056030273 s\n",
      "Batch:  4730 , l1 Loss:  0.10101653337478637 , Time: 24547.35206747055 s\n",
      "Batch:  4740 , l1 Loss:  0.1009119614958763 , Time: 24560.289816856384 s\n",
      "Batch:  4750 , l1 Loss:  0.10109009370207786 , Time: 24573.227880954742 s\n",
      "Batch:  4760 , l1 Loss:  0.10129057168960572 , Time: 24586.167277812958 s\n",
      "Batch:  4770 , l1 Loss:  0.09957929626107216 , Time: 24599.125220298767 s\n",
      "Batch:  4780 , l1 Loss:  0.10452884510159492 , Time: 24612.07926940918 s\n",
      "Batch:  4790 , l1 Loss:  0.09929127842187882 , Time: 24625.015486717224 s\n",
      "Batch:  4800 , l1 Loss:  0.09858789816498756 , Time: 24637.986419916153 s\n",
      "Batch:  4810 , l1 Loss:  0.10089510902762414 , Time: 24650.946190595627 s\n",
      "Batch:  4820 , l1 Loss:  0.10038429200649261 , Time: 24663.901089191437 s\n",
      "Batch:  4830 , l1 Loss:  0.10166890993714332 , Time: 24676.854452371597 s\n",
      "Batch:  4840 , l1 Loss:  0.10259495526552201 , Time: 24689.791229724884 s\n",
      "Batch:  4850 , l1 Loss:  0.10095861330628395 , Time: 24702.726856708527 s\n",
      "Batch:  4860 , l1 Loss:  0.09950219243764877 , Time: 24715.667345046997 s\n",
      "Batch:  4870 , l1 Loss:  0.10146146193146706 , Time: 24728.625250816345 s\n",
      "Batch:  4880 , l1 Loss:  0.10335847437381744 , Time: 24741.582210302353 s\n",
      "Batch:  4890 , l1 Loss:  0.10029520913958549 , Time: 24754.537036657333 s\n",
      "Batch:  4900 , l1 Loss:  0.09979585707187652 , Time: 24767.471921920776 s\n",
      "Batch:  4910 , l1 Loss:  0.10092592835426331 , Time: 24780.44397711754 s\n",
      "Batch:  4920 , l1 Loss:  0.1033934123814106 , Time: 24793.379212856293 s\n",
      "Batch:  4930 , l1 Loss:  0.098777873814106 , Time: 24806.301889419556 s\n",
      "Batch:  4940 , l1 Loss:  0.10091233253479004 , Time: 24819.24287891388 s\n",
      "Batch:  4950 , l1 Loss:  0.10104041248559952 , Time: 24832.191910982132 s\n",
      "Batch:  4960 , l1 Loss:  0.10200144052505493 , Time: 24845.12455511093 s\n",
      "Batch:  4970 , l1 Loss:  0.10095358714461326 , Time: 24858.06579685211 s\n",
      "Batch:  4980 , l1 Loss:  0.10099192187190056 , Time: 24871.10236930847 s\n",
      "Batch:  4990 , l1 Loss:  0.10253566354513169 , Time: 24884.057051181793 s\n",
      "Batch:  5000 , l1 Loss:  0.10044768899679184 , Time: 24896.99325156212 s\n",
      "Batch:  5010 , l1 Loss:  0.10001569017767906 , Time: 24910.03338074684 s\n",
      "Batch:  5020 , l1 Loss:  0.10160515382885933 , Time: 24922.994954824448 s\n",
      "Batch:  5030 , l1 Loss:  0.10224104449152946 , Time: 24935.94789505005 s\n",
      "Batch:  5040 , l1 Loss:  0.10295540988445281 , Time: 24948.8917222023 s\n",
      "Batch:  5050 , l1 Loss:  0.10064759626984596 , Time: 24961.825417518616 s\n",
      "Batch:  5060 , l1 Loss:  0.10064492523670196 , Time: 24974.81539440155 s\n",
      "Batch:  5070 , l1 Loss:  0.09991993531584739 , Time: 24987.818994045258 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  5080 , l1 Loss:  0.10449554696679116 , Time: 25000.799622297287 s\n",
      "Batch:  5090 , l1 Loss:  0.09967636093497276 , Time: 25013.737236738205 s\n",
      "Batch:  5100 , l1 Loss:  0.10055437311530113 , Time: 25026.647030115128 s\n",
      "Batch:  5110 , l1 Loss:  0.10231124013662338 , Time: 25039.58411049843 s\n",
      "Batch:  5120 , l1 Loss:  0.10345015525817872 , Time: 25052.517202854156 s\n",
      "Batch:  5130 , l1 Loss:  0.10485049858689308 , Time: 25065.459993839264 s\n",
      "Batch:  5140 , l1 Loss:  0.10052623003721237 , Time: 25078.393759965897 s\n",
      "Batch:  5150 , l1 Loss:  0.1032386414706707 , Time: 25091.28619670868 s\n",
      "Batch:  5160 , l1 Loss:  0.10135585591197013 , Time: 25104.159628391266 s\n",
      "Batch:  5170 , l1 Loss:  0.09907504692673683 , Time: 25117.117537498474 s\n",
      "Batch:  5180 , l1 Loss:  0.10064190849661828 , Time: 25130.015751838684 s\n",
      "Batch:  5190 , l1 Loss:  0.10101099535822869 , Time: 25143.009566307068 s\n",
      "Batch:  5200 , l1 Loss:  0.09978479295969009 , Time: 25155.942548513412 s\n",
      "Batch:  5210 , l1 Loss:  0.10016264691948891 , Time: 25168.88153243065 s\n",
      "Batch:  5220 , l1 Loss:  0.10076702237129212 , Time: 25181.795485258102 s\n",
      "Batch:  5230 , l1 Loss:  0.10085192248225212 , Time: 25194.745872735977 s\n",
      "Batch:  5240 , l1 Loss:  0.09887794628739358 , Time: 25207.670415878296 s\n",
      "Batch:  5250 , l1 Loss:  0.09942108318209648 , Time: 25220.58643221855 s\n",
      "Batch:  5260 , l1 Loss:  0.10113961845636368 , Time: 25233.520917654037 s\n",
      "Batch:  5270 , l1 Loss:  0.10079922154545784 , Time: 25246.4177672863 s\n",
      "Batch:  5280 , l1 Loss:  0.09979223683476449 , Time: 25259.342097759247 s\n",
      "Batch:  5290 , l1 Loss:  0.1030794471502304 , Time: 25272.25506234169 s\n",
      "Batch:  5300 , l1 Loss:  0.10123401805758477 , Time: 25285.187278032303 s\n",
      "Batch:  5310 , l1 Loss:  0.10317302942276001 , Time: 25298.022099256516 s\n",
      "Batch:  5320 , l1 Loss:  0.10117678940296174 , Time: 25310.93708872795 s\n",
      "Batch:  5330 , l1 Loss:  0.10221510827541351 , Time: 25323.857077121735 s\n",
      "Batch:  5340 , l1 Loss:  0.10188499391078949 , Time: 25336.77241897583 s\n",
      "Batch:  5350 , l1 Loss:  0.10207416340708733 , Time: 25349.708800554276 s\n",
      "Batch:  5360 , l1 Loss:  0.10014430284500123 , Time: 25362.602781534195 s\n",
      "Batch:  5370 , l1 Loss:  0.10178535059094429 , Time: 25375.500220775604 s\n",
      "Batch:  5380 , l1 Loss:  0.10130546689033508 , Time: 25388.39973306656 s\n",
      "Batch:  5390 , l1 Loss:  0.10192608758807183 , Time: 25401.33787918091 s\n",
      "Batch:  5400 , l1 Loss:  0.10161669254302978 , Time: 25414.25191283226 s\n",
      "Batch:  5410 , l1 Loss:  0.10062017664313316 , Time: 25427.165730714798 s\n",
      "Batch:  5420 , l1 Loss:  0.10171569511294365 , Time: 25440.10327553749 s\n",
      "Batch:  5430 , l1 Loss:  0.09916435778141022 , Time: 25453.02278995514 s\n",
      "Batch:  5440 , l1 Loss:  0.10092454329133034 , Time: 25465.99995303154 s\n",
      "Batch:  5450 , l1 Loss:  0.10122147500514984 , Time: 25479.069692134857 s\n",
      "Batch:  5460 , l1 Loss:  0.10342968329787254 , Time: 25492.130603075027 s\n",
      "Batch:  5470 , l1 Loss:  0.10010669603943825 , Time: 25505.08554291725 s\n",
      "Batch:  5480 , l1 Loss:  0.09892808347940445 , Time: 25517.906468868256 s\n",
      "Batch:  5490 , l1 Loss:  0.10025811940431595 , Time: 25530.780415058136 s\n",
      "Batch:  5500 , l1 Loss:  0.10032305642962455 , Time: 25543.6847114563 s\n",
      "Batch:  5510 , l1 Loss:  0.10175028219819068 , Time: 25556.639290094376 s\n",
      "Batch:  5520 , l1 Loss:  0.10195379853248596 , Time: 25569.59317946434 s\n",
      "Batch:  5530 , l1 Loss:  0.10295827984809876 , Time: 25582.555795669556 s\n",
      "Batch:  5540 , l1 Loss:  0.10211882889270782 , Time: 25595.513957977295 s\n",
      "Batch:  5550 , l1 Loss:  0.09995187669992447 , Time: 25608.48800945282 s\n",
      "Batch:  5560 , l1 Loss:  0.10256782174110413 , Time: 25621.50328040123 s\n",
      "Batch:  5570 , l1 Loss:  0.0993760235607624 , Time: 25634.43985271454 s\n",
      "Batch:  5580 , l1 Loss:  0.10038520395755768 , Time: 25647.41432785988 s\n",
      "Batch:  5590 , l1 Loss:  0.10139596164226532 , Time: 25660.37087392807 s\n",
      "Batch:  5600 , l1 Loss:  0.10115917474031448 , Time: 25673.355608701706 s\n",
      "Batch:  5610 , l1 Loss:  0.10293279811739922 , Time: 25686.330794095993 s\n",
      "Batch:  5620 , l1 Loss:  0.104366634786129 , Time: 25699.26450896263 s\n",
      "Batch:  5630 , l1 Loss:  0.10007814466953277 , Time: 25712.303196430206 s\n",
      "Batch:  5640 , l1 Loss:  0.10072018131613732 , Time: 25725.281579732895 s\n",
      "Batch:  5650 , l1 Loss:  0.10033834278583527 , Time: 25738.25732278824 s\n",
      "Batch:  5660 , l1 Loss:  0.10135277435183525 , Time: 25751.212667942047 s\n",
      "Batch:  5670 , l1 Loss:  0.10059042274951935 , Time: 25764.37181377411 s\n",
      "Batch:  5680 , l1 Loss:  0.10050882175564765 , Time: 25777.50900220871 s\n",
      "Batch:  5690 , l1 Loss:  0.10088207274675369 , Time: 25790.60854244232 s\n",
      "Batch:  5700 , l1 Loss:  0.10066761299967766 , Time: 25803.707062005997 s\n",
      "Batch:  5710 , l1 Loss:  0.10115379467606544 , Time: 25816.74612760544 s\n",
      "Batch:  5720 , l1 Loss:  0.10152435079216957 , Time: 25829.70028114319 s\n",
      "Batch:  5730 , l1 Loss:  0.09931857660412788 , Time: 25842.656441688538 s\n",
      "Batch:  5740 , l1 Loss:  0.09972967728972434 , Time: 25855.614840984344 s\n",
      "Batch:  5750 , l1 Loss:  0.10075778663158416 , Time: 25868.571711540222 s\n",
      "Batch:  5760 , l1 Loss:  0.09890052527189255 , Time: 25881.52553343773 s\n",
      "Batch:  5770 , l1 Loss:  0.10184236988425255 , Time: 25894.5218000412 s\n",
      "Batch:  5780 , l1 Loss:  0.10093057975172996 , Time: 25907.577004909515 s\n",
      "Batch:  5790 , l1 Loss:  0.1006888821721077 , Time: 25920.59036874771 s\n",
      "Batch:  5800 , l1 Loss:  0.10056029632687569 , Time: 25933.61495089531 s\n",
      "Batch:  5810 , l1 Loss:  0.10062110051512718 , Time: 25946.613088607788 s\n",
      "Batch:  5820 , l1 Loss:  0.10056135579943656 , Time: 25959.62485384941 s\n",
      "Batch:  5830 , l1 Loss:  0.10189847648143768 , Time: 25972.599257469177 s\n",
      "Batch:  5840 , l1 Loss:  0.10302807316184044 , Time: 25985.557379722595 s\n",
      "Batch:  5850 , l1 Loss:  0.10357172191143035 , Time: 25998.553992033005 s\n",
      "Batch:  5860 , l1 Loss:  0.1013309046626091 , Time: 26011.531818151474 s\n",
      "Batch:  5870 , l1 Loss:  0.10027165189385415 , Time: 26024.528027534485 s\n",
      "Batch:  5880 , l1 Loss:  0.10108320340514183 , Time: 26037.494074583054 s\n",
      "Batch:  5890 , l1 Loss:  0.10183969661593437 , Time: 26050.460676193237 s\n",
      "Batch:  5900 , l1 Loss:  0.1043014571070671 , Time: 26063.419575452805 s\n",
      "Batch:  5910 , l1 Loss:  0.10095988661050796 , Time: 26076.439628839493 s\n",
      "Batch:  5920 , l1 Loss:  0.1015042819082737 , Time: 26089.412809848785 s\n",
      "Batch:  5930 , l1 Loss:  0.1014571100473404 , Time: 26102.36287689209 s\n",
      "Batch:  5940 , l1 Loss:  0.1016133725643158 , Time: 26115.303520679474 s\n",
      "Batch:  5950 , l1 Loss:  0.10301708802580833 , Time: 26128.283007621765 s\n",
      "Batch:  5960 , l1 Loss:  0.1006736308336258 , Time: 26141.246153831482 s\n",
      "Batch:  5970 , l1 Loss:  0.10032460615038871 , Time: 26154.20223212242 s\n",
      "Batch:  5980 , l1 Loss:  0.10590143352746964 , Time: 26167.176746845245 s\n",
      "Batch:  5990 , l1 Loss:  0.10453373342752456 , Time: 26180.133126974106 s\n",
      "Batch:  6000 , l1 Loss:  0.10101535990834236 , Time: 26193.150726795197 s\n",
      "Batch:  6010 , l1 Loss:  0.10203539803624154 , Time: 26206.19266486168 s\n",
      "Batch:  6020 , l1 Loss:  0.10509124770760536 , Time: 26219.13618850708 s\n",
      "Batch:  6030 , l1 Loss:  0.1028940238058567 , Time: 26232.207842350006 s\n",
      "Batch:  6040 , l1 Loss:  0.10405414626002311 , Time: 26245.25991177559 s\n",
      "Batch:  6050 , l1 Loss:  0.10211340561509133 , Time: 26258.326137304306 s\n",
      "Batch:  6060 , l1 Loss:  0.1021413929760456 , Time: 26271.36446261406 s\n",
      "Batch:  6070 , l1 Loss:  0.10119475275278092 , Time: 26284.436384916306 s\n",
      "Batch:  6080 , l1 Loss:  0.10000180974602699 , Time: 26297.499071598053 s\n",
      "Batch:  6090 , l1 Loss:  0.10397575870156288 , Time: 26310.552911758423 s\n",
      "Batch:  6100 , l1 Loss:  0.10343257263302803 , Time: 26323.5916826725 s\n",
      "Batch:  6110 , l1 Loss:  0.10038547813892365 , Time: 26336.589637756348 s\n",
      "Batch:  6120 , l1 Loss:  0.10253491401672363 , Time: 26349.546456336975 s\n",
      "Batch:  6130 , l1 Loss:  0.10054371356964112 , Time: 26362.365722179413 s\n",
      "Batch:  6140 , l1 Loss:  0.10162103995680809 , Time: 26375.282820940018 s\n",
      "Batch:  6150 , l1 Loss:  0.10265287905931472 , Time: 26388.15145921707 s\n",
      "Batch:  6160 , l1 Loss:  0.1017136350274086 , Time: 26401.053221464157 s\n",
      "Batch:  6170 , l1 Loss:  0.10258377343416214 , Time: 26413.947003364563 s\n",
      "Batch:  6180 , l1 Loss:  0.10191048383712768 , Time: 26426.884348154068 s\n",
      "Batch:  6190 , l1 Loss:  0.10008116438984871 , Time: 26439.79995584488 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  6200 , l1 Loss:  0.09987829625606537 , Time: 26452.75675010681 s\n",
      "Batch:  6210 , l1 Loss:  0.10325600430369378 , Time: 26465.694767475128 s\n",
      "Batch:  6220 , l1 Loss:  0.10297117680311203 , Time: 26478.614973306656 s\n",
      "Batch:  6230 , l1 Loss:  0.10075679868459701 , Time: 26491.5708861351 s\n",
      "Batch:  6240 , l1 Loss:  0.10201162546873092 , Time: 26504.524520397186 s\n",
      "Batch:  6250 , l1 Loss:  0.10098938941955567 , Time: 26517.500088214874 s\n",
      "Batch:  6260 , l1 Loss:  0.10180521085858345 , Time: 26530.458481788635 s\n",
      "Batch:  6270 , l1 Loss:  0.10145903006196022 , Time: 26543.40000796318 s\n",
      "Batch:  6280 , l1 Loss:  0.10224303454160691 , Time: 26556.39503955841 s\n",
      "Batch:  6290 , l1 Loss:  0.10111218914389611 , Time: 26569.371505975723 s\n",
      "Batch:  6300 , l1 Loss:  0.10072181671857834 , Time: 26582.331192731857 s\n",
      "Batch:  6310 , l1 Loss:  0.10042344480752945 , Time: 26595.337315797806 s\n",
      "Batch:  6320 , l1 Loss:  0.10003795176744461 , Time: 26608.302629470825 s\n",
      "Batch:  6330 , l1 Loss:  0.10133296102285386 , Time: 26621.274903059006 s\n",
      "Batch:  6340 , l1 Loss:  0.10223967134952545 , Time: 26634.25427532196 s\n",
      "Batch:  6350 , l1 Loss:  0.09954000860452653 , Time: 26647.20896244049 s\n",
      "Batch:  6360 , l1 Loss:  0.1015379123389721 , Time: 26660.144911050797 s\n",
      "Batch:  6370 , l1 Loss:  0.1001044511795044 , Time: 26673.127220869064 s\n",
      "Batch:  6380 , l1 Loss:  0.10094413831830025 , Time: 26686.061366081238 s\n",
      "Batch:  6390 , l1 Loss:  0.09989776164293289 , Time: 26699.033415555954 s\n",
      "Batch:  6400 , l1 Loss:  0.10093168392777443 , Time: 26711.97039580345 s\n",
      "Batch:  6410 , l1 Loss:  0.0997276023030281 , Time: 26724.92501425743 s\n",
      "Batch:  6420 , l1 Loss:  0.09991928488016129 , Time: 26737.842418670654 s\n",
      "Batch:  6430 , l1 Loss:  0.10325976610183715 , Time: 26750.764815092087 s\n",
      "Batch:  6440 , l1 Loss:  0.10239850953221322 , Time: 26763.73893737793 s\n",
      "Batch:  6450 , l1 Loss:  0.0991552084684372 , Time: 26776.691673994064 s\n",
      "Batch:  6460 , l1 Loss:  0.09995234087109565 , Time: 26789.671150684357 s\n",
      "Batch:  6470 , l1 Loss:  0.09970316961407662 , Time: 26802.612063407898 s\n",
      "Batch:  6480 , l1 Loss:  0.10249817371368408 , Time: 26815.5514023304 s\n",
      "Batch:  6490 , l1 Loss:  0.1010261632502079 , Time: 26828.46776866913 s\n",
      "Batch:  6500 , l1 Loss:  0.10088212415575981 , Time: 26841.46526670456 s\n",
      "Batch:  6510 , l1 Loss:  0.10112889930605888 , Time: 26854.564302921295 s\n",
      "Batch:  6520 , l1 Loss:  0.10087165758013725 , Time: 26867.554940223694 s\n",
      "Batch:  6530 , l1 Loss:  0.10075677484273911 , Time: 26880.541030406952 s\n",
      "Batch:  6540 , l1 Loss:  0.10012409538030624 , Time: 26893.51937031746 s\n",
      "Batch:  6550 , l1 Loss:  0.1016362801194191 , Time: 26906.486931562424 s\n",
      "Batch:  6560 , l1 Loss:  0.1011615626513958 , Time: 26919.494292020798 s\n",
      "Batch:  6570 , l1 Loss:  0.09937781915068626 , Time: 26932.472944021225 s\n",
      "Batch:  6580 , l1 Loss:  0.10104513987898826 , Time: 26945.405432462692 s\n",
      "Batch:  6590 , l1 Loss:  0.10140046328306199 , Time: 26958.285138130188 s\n",
      "Batch:  6600 , l1 Loss:  0.10288346484303475 , Time: 26971.188441753387 s\n",
      "Batch:  6610 , l1 Loss:  0.10314625948667526 , Time: 26984.079125404358 s\n",
      "Batch:  6620 , l1 Loss:  0.09908691868185997 , Time: 26996.992880105972 s\n",
      "Batch:  6630 , l1 Loss:  0.10058657974004745 , Time: 27009.89259004593 s\n",
      "Batch:  6640 , l1 Loss:  0.10080575495958329 , Time: 27022.811757802963 s\n",
      "Batch:  6650 , l1 Loss:  0.09935983568429947 , Time: 27035.74610733986 s\n",
      "Batch:  6660 , l1 Loss:  0.09937962144613266 , Time: 27048.639935731888 s\n",
      "Batch:  6670 , l1 Loss:  0.10013745352625847 , Time: 27061.537392139435 s\n",
      "Batch:  6680 , l1 Loss:  0.1017437718808651 , Time: 27074.494191884995 s\n",
      "Batch:  6690 , l1 Loss:  0.09998262748122215 , Time: 27087.417934656143 s\n",
      "Batch:  6700 , l1 Loss:  0.10097151100635529 , Time: 27100.33113217354 s\n",
      "Batch:  6710 , l1 Loss:  0.10108996480703354 , Time: 27113.242950201035 s\n",
      "Batch:  6720 , l1 Loss:  0.10251709967851638 , Time: 27126.17888355255 s\n",
      "Batch:  6730 , l1 Loss:  0.10272770673036576 , Time: 27139.116539239883 s\n",
      "Batch:  6740 , l1 Loss:  0.10091644152998924 , Time: 27152.059478998184 s\n",
      "Batch:  6750 , l1 Loss:  0.09973900243639947 , Time: 27164.994416236877 s\n",
      "Batch:  6760 , l1 Loss:  0.09845386743545533 , Time: 27177.90594649315 s\n",
      "Batch:  6770 , l1 Loss:  0.10175799652934074 , Time: 27190.801372766495 s\n",
      "Batch:  6780 , l1 Loss:  0.10066229104995728 , Time: 27203.718527317047 s\n",
      "Batch:  6790 , l1 Loss:  0.1004148505628109 , Time: 27216.658396482468 s\n",
      "Batch:  6800 , l1 Loss:  0.10260583162307739 , Time: 27229.559925079346 s\n",
      "Batch:  6810 , l1 Loss:  0.10397164598107338 , Time: 27242.485600709915 s\n",
      "Batch:  6820 , l1 Loss:  0.10263122841715813 , Time: 27255.400331258774 s\n",
      "Batch:  6830 , l1 Loss:  0.10088193416595459 , Time: 27268.355808258057 s\n",
      "Batch:  6840 , l1 Loss:  0.10179313346743583 , Time: 27281.277211666107 s\n",
      "Batch:  6850 , l1 Loss:  0.10251470655202866 , Time: 27294.213215112686 s\n",
      "Batch:  6860 , l1 Loss:  0.10068625062704087 , Time: 27307.068257331848 s\n",
      "Batch:  6870 , l1 Loss:  0.10080794841051102 , Time: 27319.94400024414 s\n",
      "Batch:  6880 , l1 Loss:  0.09933220744132995 , Time: 27332.97678589821 s\n",
      "Batch:  6890 , l1 Loss:  0.10009252279996872 , Time: 27345.8973236084 s\n",
      "Batch:  6900 , l1 Loss:  0.09985492751002312 , Time: 27358.82960128784 s\n",
      "Batch:  6910 , l1 Loss:  0.10265449807047844 , Time: 27371.78454875946 s\n",
      "Batch:  6920 , l1 Loss:  0.10134424194693566 , Time: 27384.837869167328 s\n",
      "Batch:  6930 , l1 Loss:  0.10223347395658493 , Time: 27397.81964635849 s\n",
      "Batch:  6940 , l1 Loss:  0.1016851931810379 , Time: 27410.76113963127 s\n",
      "Batch:  6950 , l1 Loss:  0.101108867675066 , Time: 27423.76106238365 s\n",
      "Batch:  6960 , l1 Loss:  0.10143816769123078 , Time: 27436.91865181923 s\n",
      "Batch:  6970 , l1 Loss:  0.10031840577721596 , Time: 27450.024518966675 s\n",
      "Batch:  6980 , l1 Loss:  0.10007350593805313 , Time: 27462.90689754486 s\n",
      "Batch:  6990 , l1 Loss:  0.1020144522190094 , Time: 27475.848083019257 s\n",
      "Batch:  7000 , l1 Loss:  0.1022880420088768 , Time: 27488.780916690826 s\n",
      "Batch:  7010 , l1 Loss:  0.10173561647534371 , Time: 27501.77889275551 s\n",
      "Batch:  7020 , l1 Loss:  0.09860049933195114 , Time: 27514.738580942154 s\n",
      "Epoch:  2 , l1 loss:  0.10183689852323646\n",
      "Epoch:  3\n",
      "Batch:  10 , l1 Loss:  0.09857968376441435 , Time: 27533.474504947662 s\n",
      "Batch:  20 , l1 Loss:  0.10141747817397118 , Time: 27546.37681055069 s\n",
      "Batch:  30 , l1 Loss:  0.09930190369486809 , Time: 27559.353328466415 s\n",
      "Batch:  40 , l1 Loss:  0.09986779987812042 , Time: 27572.3098757267 s\n",
      "Batch:  50 , l1 Loss:  0.10420529320836067 , Time: 27585.28565096855 s\n",
      "Batch:  60 , l1 Loss:  0.10064333900809289 , Time: 27598.244291067123 s\n",
      "Batch:  70 , l1 Loss:  0.10067108795046806 , Time: 27611.20343375206 s\n",
      "Batch:  80 , l1 Loss:  0.10089750736951827 , Time: 27624.1389708519 s\n",
      "Batch:  90 , l1 Loss:  0.10461949408054352 , Time: 27637.136957645416 s\n",
      "Batch:  100 , l1 Loss:  0.10103117749094963 , Time: 27650.115268945694 s\n",
      "Batch:  110 , l1 Loss:  0.10032131522893906 , Time: 27663.09324336052 s\n",
      "Batch:  120 , l1 Loss:  0.10091791450977325 , Time: 27676.088725805283 s\n",
      "Batch:  130 , l1 Loss:  0.10252210348844529 , Time: 27689.030475854874 s\n",
      "Batch:  140 , l1 Loss:  0.1022353321313858 , Time: 27702.002908945084 s\n",
      "Batch:  150 , l1 Loss:  0.1013259895145893 , Time: 27714.959990501404 s\n",
      "Batch:  160 , l1 Loss:  0.10059058889746667 , Time: 27727.9354865551 s\n",
      "Batch:  170 , l1 Loss:  0.10045360028743744 , Time: 27741.07421708107 s\n",
      "Batch:  180 , l1 Loss:  0.10016872808337211 , Time: 27754.256195545197 s\n",
      "Batch:  190 , l1 Loss:  0.09976871982216835 , Time: 27767.390523672104 s\n",
      "Batch:  200 , l1 Loss:  0.10244105979800225 , Time: 27780.473164081573 s\n",
      "Batch:  210 , l1 Loss:  0.10005649775266648 , Time: 27793.506742477417 s\n",
      "Batch:  220 , l1 Loss:  0.10213355273008347 , Time: 27806.580658197403 s\n",
      "Batch:  230 , l1 Loss:  0.09971461817622185 , Time: 27819.600652694702 s\n",
      "Batch:  240 , l1 Loss:  0.10226010531187057 , Time: 27832.63480591774 s\n",
      "Batch:  250 , l1 Loss:  0.10154476016759872 , Time: 27845.646926403046 s\n",
      "Batch:  260 , l1 Loss:  0.10005422905087472 , Time: 27858.686275720596 s\n",
      "Batch:  270 , l1 Loss:  0.09957487136125565 , Time: 27871.765023231506 s\n",
      "Batch:  280 , l1 Loss:  0.10143286287784577 , Time: 27884.804329156876 s\n",
      "Batch:  290 , l1 Loss:  0.10193087831139565 , Time: 27897.804152965546 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  300 , l1 Loss:  0.10054391101002694 , Time: 27910.838450193405 s\n",
      "Batch:  310 , l1 Loss:  0.10132896304130554 , Time: 27923.731503248215 s\n",
      "Batch:  320 , l1 Loss:  0.10147906988859176 , Time: 27936.541546583176 s\n",
      "Batch:  330 , l1 Loss:  0.10131789445877075 , Time: 27949.4203042984 s\n",
      "Batch:  340 , l1 Loss:  0.10259396061301232 , Time: 27962.303371429443 s\n",
      "Batch:  350 , l1 Loss:  0.10191823691129684 , Time: 27975.219435214996 s\n",
      "Batch:  360 , l1 Loss:  0.10160309374332428 , Time: 27988.13053393364 s\n",
      "Batch:  370 , l1 Loss:  0.10033189356327057 , Time: 28001.26632642746 s\n",
      "Batch:  380 , l1 Loss:  0.10131421759724617 , Time: 28014.31858921051 s\n",
      "Batch:  390 , l1 Loss:  0.10200956240296363 , Time: 28027.377527713776 s\n",
      "Batch:  400 , l1 Loss:  0.10046070590615272 , Time: 28040.376056432724 s\n",
      "Batch:  410 , l1 Loss:  0.09945999234914779 , Time: 28053.40935897827 s\n",
      "Batch:  420 , l1 Loss:  0.10006348118185997 , Time: 28066.439769744873 s\n",
      "Batch:  430 , l1 Loss:  0.09940270632505417 , Time: 28079.484585762024 s\n",
      "Batch:  440 , l1 Loss:  0.10188046619296073 , Time: 28092.50760102272 s\n",
      "Batch:  450 , l1 Loss:  0.09883632436394692 , Time: 28105.558045387268 s\n",
      "Batch:  460 , l1 Loss:  0.1020846962928772 , Time: 28118.60564827919 s\n",
      "Batch:  470 , l1 Loss:  0.10079905986785889 , Time: 28131.608562469482 s\n",
      "Batch:  480 , l1 Loss:  0.10190802812576294 , Time: 28144.484650850296 s\n",
      "Batch:  490 , l1 Loss:  0.10100450366735458 , Time: 28157.305760622025 s\n",
      "Batch:  500 , l1 Loss:  0.101385348290205 , Time: 28170.199424743652 s\n",
      "Batch:  510 , l1 Loss:  0.09975598752498627 , Time: 28183.100284576416 s\n",
      "Batch:  520 , l1 Loss:  0.09987013041973114 , Time: 28195.979332208633 s\n",
      "Batch:  530 , l1 Loss:  0.10116996392607688 , Time: 28208.895729780197 s\n",
      "Batch:  540 , l1 Loss:  0.10181401148438454 , Time: 28221.815853357315 s\n",
      "Batch:  550 , l1 Loss:  0.09968345910310746 , Time: 28234.75527691841 s\n",
      "Batch:  560 , l1 Loss:  0.10044680908322334 , Time: 28247.66914010048 s\n",
      "Batch:  570 , l1 Loss:  0.10066462084650993 , Time: 28260.62323117256 s\n",
      "Batch:  580 , l1 Loss:  0.10047571435570717 , Time: 28273.762804985046 s\n",
      "Batch:  590 , l1 Loss:  0.09806301295757294 , Time: 28286.882014274597 s\n",
      "Batch:  600 , l1 Loss:  0.10368287935853004 , Time: 28299.939032554626 s\n",
      "Batch:  610 , l1 Loss:  0.10150662809610367 , Time: 28312.945610523224 s\n",
      "Batch:  620 , l1 Loss:  0.10042769461870193 , Time: 28326.008239984512 s\n",
      "Batch:  630 , l1 Loss:  0.10143949091434479 , Time: 28339.022381544113 s\n",
      "Batch:  640 , l1 Loss:  0.09979514330625534 , Time: 28352.076004505157 s\n",
      "Batch:  650 , l1 Loss:  0.10037693828344345 , Time: 28365.07497406006 s\n",
      "Batch:  660 , l1 Loss:  0.10039160251617432 , Time: 28378.07406425476 s\n",
      "Batch:  670 , l1 Loss:  0.1019842803478241 , Time: 28391.084277391434 s\n",
      "Batch:  680 , l1 Loss:  0.09989105314016342 , Time: 28404.102398872375 s\n",
      "Batch:  690 , l1 Loss:  0.09806821048259735 , Time: 28417.11926841736 s\n",
      "Batch:  700 , l1 Loss:  0.09977559968829156 , Time: 28430.117254018784 s\n",
      "Batch:  710 , l1 Loss:  0.1000695876777172 , Time: 28443.13202214241 s\n",
      "Batch:  720 , l1 Loss:  0.10039756968617439 , Time: 28456.1464509964 s\n",
      "Batch:  730 , l1 Loss:  0.10027638748288155 , Time: 28469.170043230057 s\n",
      "Batch:  740 , l1 Loss:  0.10167119950056076 , Time: 28482.174477100372 s\n",
      "Batch:  750 , l1 Loss:  0.0997664287686348 , Time: 28495.140055656433 s\n",
      "Batch:  760 , l1 Loss:  0.10216190069913864 , Time: 28508.121070861816 s\n",
      "Batch:  770 , l1 Loss:  0.10023192167282105 , Time: 28521.209936618805 s\n",
      "Batch:  780 , l1 Loss:  0.09960371181368828 , Time: 28534.205735206604 s\n",
      "Batch:  790 , l1 Loss:  0.10197146460413933 , Time: 28547.203764677048 s\n",
      "Batch:  800 , l1 Loss:  0.10111017599701881 , Time: 28560.160423755646 s\n",
      "Batch:  810 , l1 Loss:  0.10025860667228699 , Time: 28573.11074900627 s\n",
      "Batch:  820 , l1 Loss:  0.09902360066771507 , Time: 28586.048023462296 s\n",
      "Batch:  830 , l1 Loss:  0.09935860559344292 , Time: 28599.02750468254 s\n",
      "Batch:  840 , l1 Loss:  0.09955454617738724 , Time: 28612.016224384308 s\n",
      "Batch:  850 , l1 Loss:  0.10020283237099648 , Time: 28624.995675086975 s\n",
      "Batch:  860 , l1 Loss:  0.10017628595232964 , Time: 28637.95137643814 s\n",
      "Batch:  870 , l1 Loss:  0.10277936458587647 , Time: 28650.921469688416 s\n",
      "Batch:  880 , l1 Loss:  0.09952648878097534 , Time: 28663.91128063202 s\n",
      "Batch:  890 , l1 Loss:  0.102156350761652 , Time: 28676.86387705803 s\n",
      "Batch:  900 , l1 Loss:  0.10170479416847229 , Time: 28689.82411956787 s\n",
      "Batch:  910 , l1 Loss:  0.10139084979891777 , Time: 28702.81491279602 s\n",
      "Batch:  920 , l1 Loss:  0.10166813731193543 , Time: 28715.87542462349 s\n",
      "Batch:  930 , l1 Loss:  0.09985285848379136 , Time: 28728.851697206497 s\n",
      "Batch:  940 , l1 Loss:  0.10127654001116752 , Time: 28741.781221866608 s\n",
      "Batch:  950 , l1 Loss:  0.10157584398984909 , Time: 28754.739245653152 s\n",
      "Batch:  960 , l1 Loss:  0.1011784851551056 , Time: 28767.741516828537 s\n",
      "Batch:  970 , l1 Loss:  0.10124633610248565 , Time: 28780.736279964447 s\n",
      "Batch:  980 , l1 Loss:  0.10011832714080811 , Time: 28793.72696518898 s\n",
      "Batch:  990 , l1 Loss:  0.10165093839168549 , Time: 28806.684423685074 s\n",
      "Batch:  1000 , l1 Loss:  0.1006695196032524 , Time: 28819.659018993378 s\n",
      "Batch:  1010 , l1 Loss:  0.1034494549036026 , Time: 28832.74165201187 s\n",
      "Batch:  1020 , l1 Loss:  0.10055742263793946 , Time: 28845.728975057602 s\n",
      "Batch:  1030 , l1 Loss:  0.10088104233145714 , Time: 28858.74637389183 s\n",
      "Batch:  1040 , l1 Loss:  0.1005151093006134 , Time: 28871.7231528759 s\n",
      "Batch:  1050 , l1 Loss:  0.1012095607817173 , Time: 28884.721835374832 s\n",
      "Batch:  1060 , l1 Loss:  0.10161022543907165 , Time: 28897.725239515305 s\n",
      "Batch:  1070 , l1 Loss:  0.10193450376391411 , Time: 28910.692900657654 s\n",
      "Batch:  1080 , l1 Loss:  0.09933004900813103 , Time: 28923.674751996994 s\n",
      "Batch:  1090 , l1 Loss:  0.10000560879707336 , Time: 28936.648666620255 s\n",
      "Batch:  1100 , l1 Loss:  0.10142753124237061 , Time: 28949.64843416214 s\n",
      "Batch:  1110 , l1 Loss:  0.10085735395550728 , Time: 28962.628954410553 s\n",
      "Batch:  1120 , l1 Loss:  0.10026161447167396 , Time: 28975.579073905945 s\n",
      "Batch:  1130 , l1 Loss:  0.10051236227154732 , Time: 28988.535210371017 s\n",
      "Batch:  1140 , l1 Loss:  0.10288727059960365 , Time: 29001.424774885178 s\n",
      "Batch:  1150 , l1 Loss:  0.10211370661854743 , Time: 29014.155131816864 s\n",
      "Batch:  1160 , l1 Loss:  0.10256442055106163 , Time: 29026.90984940529 s\n",
      "Batch:  1170 , l1 Loss:  0.10041246116161347 , Time: 29039.6734457016 s\n",
      "Batch:  1180 , l1 Loss:  0.1001367561519146 , Time: 29052.568273305893 s\n",
      "Batch:  1190 , l1 Loss:  0.10000878125429154 , Time: 29065.444197654724 s\n",
      "Batch:  1200 , l1 Loss:  0.09837736859917641 , Time: 29078.366796970367 s\n",
      "Batch:  1210 , l1 Loss:  0.10144590809941292 , Time: 29091.263230085373 s\n",
      "Batch:  1220 , l1 Loss:  0.10051166564226151 , Time: 29104.19678544998 s\n",
      "Batch:  1230 , l1 Loss:  0.10038951635360718 , Time: 29117.11274909973 s\n",
      "Batch:  1240 , l1 Loss:  0.10044308081269264 , Time: 29130.02969145775 s\n",
      "Batch:  1250 , l1 Loss:  0.09913322776556015 , Time: 29143.041428089142 s\n",
      "Batch:  1260 , l1 Loss:  0.10180097594857215 , Time: 29156.046675920486 s\n",
      "Batch:  1270 , l1 Loss:  0.09998577535152435 , Time: 29169.016446828842 s\n",
      "Batch:  1280 , l1 Loss:  0.09990600347518921 , Time: 29181.98942565918 s\n",
      "Batch:  1290 , l1 Loss:  0.10064377337694168 , Time: 29194.966128349304 s\n",
      "Batch:  1300 , l1 Loss:  0.10046040788292884 , Time: 29207.900597572327 s\n",
      "Batch:  1310 , l1 Loss:  0.10126124769449234 , Time: 29220.83638215065 s\n",
      "Batch:  1320 , l1 Loss:  0.1001543328166008 , Time: 29233.777334690094 s\n",
      "Batch:  1330 , l1 Loss:  0.10344783812761307 , Time: 29246.693444013596 s\n",
      "Batch:  1340 , l1 Loss:  0.09801838621497154 , Time: 29259.62184071541 s\n",
      "Batch:  1350 , l1 Loss:  0.09960473626852036 , Time: 29272.509027957916 s\n",
      "Batch:  1360 , l1 Loss:  0.09986166656017303 , Time: 29285.460052251816 s\n",
      "Batch:  1370 , l1 Loss:  0.10006419718265533 , Time: 29298.397990465164 s\n",
      "Batch:  1380 , l1 Loss:  0.10167819932103157 , Time: 29311.357137441635 s\n",
      "Batch:  1390 , l1 Loss:  0.09954945221543313 , Time: 29324.274054527283 s\n",
      "Batch:  1400 , l1 Loss:  0.10017750263214112 , Time: 29337.227653503418 s\n",
      "Batch:  1410 , l1 Loss:  0.09969147965312004 , Time: 29350.067741155624 s\n",
      "Batch:  1420 , l1 Loss:  0.09982641637325287 , Time: 29362.9206700325 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  1430 , l1 Loss:  0.10132381692528725 , Time: 29375.817677259445 s\n",
      "Batch:  1440 , l1 Loss:  0.10107669606804848 , Time: 29388.731818199158 s\n",
      "Batch:  1450 , l1 Loss:  0.10133690908551216 , Time: 29401.654061317444 s\n",
      "Batch:  1460 , l1 Loss:  0.10746443271636963 , Time: 29414.608151435852 s\n",
      "Batch:  1470 , l1 Loss:  0.10680588260293007 , Time: 29427.523127555847 s\n",
      "Batch:  1480 , l1 Loss:  0.10688736736774444 , Time: 29440.464397192 s\n",
      "Batch:  1490 , l1 Loss:  0.10672667324542999 , Time: 29453.374522686005 s\n",
      "Batch:  1500 , l1 Loss:  0.10146920457482338 , Time: 29466.29358267784 s\n",
      "Batch:  1510 , l1 Loss:  0.10123461261391639 , Time: 29479.267792224884 s\n",
      "Batch:  1520 , l1 Loss:  0.1023484081029892 , Time: 29492.18756699562 s\n",
      "Batch:  1530 , l1 Loss:  0.09910318329930305 , Time: 29505.128677129745 s\n",
      "Batch:  1540 , l1 Loss:  0.10035663694143296 , Time: 29518.065029144287 s\n",
      "Batch:  1550 , l1 Loss:  0.10117477551102638 , Time: 29531.000784873962 s\n",
      "Batch:  1560 , l1 Loss:  0.10092361494898797 , Time: 29543.902452230453 s\n",
      "Batch:  1570 , l1 Loss:  0.09982938542962075 , Time: 29556.94087290764 s\n",
      "Batch:  1580 , l1 Loss:  0.10026141852140427 , Time: 29569.94305038452 s\n",
      "Batch:  1590 , l1 Loss:  0.09933568686246871 , Time: 29582.89199781418 s\n",
      "Batch:  1600 , l1 Loss:  0.10055336207151414 , Time: 29595.85670733452 s\n",
      "Batch:  1610 , l1 Loss:  0.09973819479346276 , Time: 29608.792495012283 s\n",
      "Batch:  1620 , l1 Loss:  0.10113871395587921 , Time: 29621.7541949749 s\n",
      "Batch:  1630 , l1 Loss:  0.10231811851263047 , Time: 29634.70897078514 s\n",
      "Batch:  1640 , l1 Loss:  0.09996760711073875 , Time: 29647.647789001465 s\n",
      "Batch:  1650 , l1 Loss:  0.10095734521746635 , Time: 29660.573397874832 s\n",
      "Batch:  1660 , l1 Loss:  0.10226125121116639 , Time: 29673.544746875763 s\n",
      "Batch:  1670 , l1 Loss:  0.09884878322482109 , Time: 29686.459769964218 s\n",
      "Batch:  1680 , l1 Loss:  0.0994554579257965 , Time: 29699.3768556118 s\n",
      "Batch:  1690 , l1 Loss:  0.10200977474451065 , Time: 29712.296298980713 s\n",
      "Batch:  1700 , l1 Loss:  0.1020992211997509 , Time: 29725.19350004196 s\n",
      "Batch:  1710 , l1 Loss:  0.10185106918215751 , Time: 29738.10258746147 s\n",
      "Batch:  1720 , l1 Loss:  0.09920792877674103 , Time: 29751.00274157524 s\n",
      "Batch:  1730 , l1 Loss:  0.0999770000576973 , Time: 29763.860776662827 s\n",
      "Batch:  1740 , l1 Loss:  0.10036739408969879 , Time: 29776.71640610695 s\n",
      "Batch:  1750 , l1 Loss:  0.10007035359740257 , Time: 29789.638130903244 s\n",
      "Batch:  1760 , l1 Loss:  0.09942423403263093 , Time: 29802.549701690674 s\n",
      "Batch:  1770 , l1 Loss:  0.10106067582964898 , Time: 29815.464581251144 s\n",
      "Batch:  1780 , l1 Loss:  0.10127407759428024 , Time: 29828.37913608551 s\n",
      "Batch:  1790 , l1 Loss:  0.09927602186799049 , Time: 29841.300208091736 s\n",
      "Batch:  1800 , l1 Loss:  0.10066130980849267 , Time: 29854.23795890808 s\n",
      "Batch:  1810 , l1 Loss:  0.09929627850651741 , Time: 29867.172437906265 s\n",
      "Batch:  1820 , l1 Loss:  0.10201247036457062 , Time: 29880.10786819458 s\n",
      "Batch:  1830 , l1 Loss:  0.10019350871443748 , Time: 29893.02657008171 s\n",
      "Batch:  1840 , l1 Loss:  0.10219563990831375 , Time: 29906.005472660065 s\n",
      "Batch:  1850 , l1 Loss:  0.10287360996007919 , Time: 29918.962406396866 s\n",
      "Batch:  1860 , l1 Loss:  0.09934206604957581 , Time: 29931.91993546486 s\n",
      "Batch:  1870 , l1 Loss:  0.10056794732809067 , Time: 29945.016787290573 s\n",
      "Batch:  1880 , l1 Loss:  0.10088252127170563 , Time: 29958.06984782219 s\n",
      "Batch:  1890 , l1 Loss:  0.09931513592600823 , Time: 29971.131888628006 s\n",
      "Batch:  1900 , l1 Loss:  0.10048413798213005 , Time: 29984.18789792061 s\n",
      "Batch:  1910 , l1 Loss:  0.10120220482349396 , Time: 29997.262591362 s\n",
      "Batch:  1920 , l1 Loss:  0.10271920040249824 , Time: 30010.263033628464 s\n",
      "Batch:  1930 , l1 Loss:  0.09925774186849594 , Time: 30023.29738020897 s\n",
      "Batch:  1940 , l1 Loss:  0.10081634894013405 , Time: 30036.319348573685 s\n",
      "Batch:  1950 , l1 Loss:  0.10025826767086983 , Time: 30049.353402137756 s\n",
      "Batch:  1960 , l1 Loss:  0.09933967143297195 , Time: 30062.348680734634 s\n",
      "Batch:  1970 , l1 Loss:  0.09995657801628113 , Time: 30075.325733423233 s\n",
      "Batch:  1980 , l1 Loss:  0.09974839463829994 , Time: 30088.344158887863 s\n",
      "Batch:  1990 , l1 Loss:  0.10054352954030037 , Time: 30101.356890916824 s\n",
      "Batch:  2000 , l1 Loss:  0.10226565301418304 , Time: 30114.322736740112 s\n",
      "Batch:  2010 , l1 Loss:  0.10352328717708588 , Time: 30127.47457075119 s\n",
      "Batch:  2020 , l1 Loss:  0.1003553181886673 , Time: 30140.48735189438 s\n",
      "Batch:  2030 , l1 Loss:  0.10006465539336204 , Time: 30153.50453186035 s\n",
      "Batch:  2040 , l1 Loss:  0.10215556249022484 , Time: 30166.525531053543 s\n",
      "Batch:  2050 , l1 Loss:  0.09900244772434234 , Time: 30179.50358939171 s\n",
      "Batch:  2060 , l1 Loss:  0.10323943868279457 , Time: 30192.48011279106 s\n",
      "Batch:  2070 , l1 Loss:  0.09875653311610222 , Time: 30205.50811624527 s\n",
      "Batch:  2080 , l1 Loss:  0.1015069916844368 , Time: 30218.512464284897 s\n",
      "Batch:  2090 , l1 Loss:  0.10140499025583267 , Time: 30231.494402885437 s\n",
      "Batch:  2100 , l1 Loss:  0.10212438851594925 , Time: 30244.514338731766 s\n",
      "Batch:  2110 , l1 Loss:  0.10051233321428299 , Time: 30257.507591485977 s\n",
      "Batch:  2120 , l1 Loss:  0.10291923359036445 , Time: 30270.523193597794 s\n",
      "Batch:  2130 , l1 Loss:  0.10363307595252991 , Time: 30283.51679110527 s\n",
      "Batch:  2140 , l1 Loss:  0.09828185960650444 , Time: 30296.511286735535 s\n",
      "Batch:  2150 , l1 Loss:  0.1011374056339264 , Time: 30309.496523857117 s\n",
      "Batch:  2160 , l1 Loss:  0.10137413665652276 , Time: 30322.46870803833 s\n",
      "Batch:  2170 , l1 Loss:  0.10023872181773186 , Time: 30335.441334724426 s\n",
      "Batch:  2180 , l1 Loss:  0.10284487456083298 , Time: 30348.397361278534 s\n",
      "Batch:  2190 , l1 Loss:  0.10192765444517135 , Time: 30361.35998415947 s\n",
      "Batch:  2200 , l1 Loss:  0.10028115436434745 , Time: 30374.335594654083 s\n",
      "Batch:  2210 , l1 Loss:  0.10101769715547562 , Time: 30387.272398233414 s\n",
      "Batch:  2220 , l1 Loss:  0.10084936842322349 , Time: 30400.164737701416 s\n",
      "Batch:  2230 , l1 Loss:  0.09938145279884339 , Time: 30413.036264657974 s\n",
      "Batch:  2240 , l1 Loss:  0.09925649389624595 , Time: 30425.931056261063 s\n",
      "Batch:  2250 , l1 Loss:  0.10076164454221725 , Time: 30438.82648539543 s\n",
      "Batch:  2260 , l1 Loss:  0.10245116725564003 , Time: 30451.70646595955 s\n",
      "Batch:  2270 , l1 Loss:  0.09842099994421005 , Time: 30464.585480690002 s\n",
      "Batch:  2280 , l1 Loss:  0.09987710490822792 , Time: 30477.481963396072 s\n",
      "Batch:  2290 , l1 Loss:  0.09993516653776169 , Time: 30490.379462957382 s\n",
      "Batch:  2300 , l1 Loss:  0.10134918838739396 , Time: 30503.27030324936 s\n",
      "Batch:  2310 , l1 Loss:  0.0996528722345829 , Time: 30516.18218922615 s\n",
      "Batch:  2320 , l1 Loss:  0.09975306764245033 , Time: 30529.03595852852 s\n",
      "Batch:  2330 , l1 Loss:  0.10168120712041855 , Time: 30541.932705640793 s\n",
      "Batch:  2340 , l1 Loss:  0.09973306953907013 , Time: 30554.768723249435 s\n",
      "Batch:  2350 , l1 Loss:  0.10044200867414474 , Time: 30567.64789748192 s\n",
      "Batch:  2360 , l1 Loss:  0.1014621376991272 , Time: 30580.52666926384 s\n",
      "Batch:  2370 , l1 Loss:  0.10319682732224464 , Time: 30593.398957252502 s\n",
      "Batch:  2380 , l1 Loss:  0.09935232698917389 , Time: 30606.311804056168 s\n",
      "Batch:  2390 , l1 Loss:  0.10074577406048775 , Time: 30619.21021938324 s\n",
      "Batch:  2400 , l1 Loss:  0.10197153091430664 , Time: 30632.167134046555 s\n",
      "Batch:  2410 , l1 Loss:  0.10135492831468582 , Time: 30645.11686563492 s\n",
      "Batch:  2420 , l1 Loss:  0.10299283266067505 , Time: 30658.04611349106 s\n",
      "Batch:  2430 , l1 Loss:  0.09952026233077049 , Time: 30670.961194753647 s\n",
      "Batch:  2440 , l1 Loss:  0.10028264671564102 , Time: 30683.87455201149 s\n",
      "Batch:  2450 , l1 Loss:  0.10097716972231865 , Time: 30696.821736097336 s\n",
      "Batch:  2460 , l1 Loss:  0.10090331435203552 , Time: 30709.748351335526 s\n",
      "Batch:  2470 , l1 Loss:  0.10241223275661468 , Time: 30722.645464658737 s\n",
      "Batch:  2480 , l1 Loss:  0.10058932974934578 , Time: 30735.58095407486 s\n",
      "Batch:  2490 , l1 Loss:  0.10137064084410667 , Time: 30748.566849708557 s\n",
      "Batch:  2500 , l1 Loss:  0.1015703596174717 , Time: 30761.5146048069 s\n",
      "Batch:  2510 , l1 Loss:  0.10132425576448441 , Time: 30774.548580408096 s\n",
      "Batch:  2520 , l1 Loss:  0.09957177117466927 , Time: 30787.54033279419 s\n",
      "Batch:  2530 , l1 Loss:  0.0998567096889019 , Time: 30800.52419948578 s\n",
      "Batch:  2540 , l1 Loss:  0.09960951507091523 , Time: 30813.45920753479 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  2550 , l1 Loss:  0.10131178423762321 , Time: 30826.39546251297 s\n",
      "Batch:  2560 , l1 Loss:  0.10187182649970054 , Time: 30839.334251880646 s\n",
      "Batch:  2570 , l1 Loss:  0.10205570757389068 , Time: 30852.265276432037 s\n",
      "Batch:  2580 , l1 Loss:  0.09901227653026581 , Time: 30865.18859219551 s\n",
      "Batch:  2590 , l1 Loss:  0.10131625384092331 , Time: 30878.106032848358 s\n",
      "Batch:  2600 , l1 Loss:  0.10074106007814407 , Time: 30891.063526153564 s\n",
      "Batch:  2610 , l1 Loss:  0.10112023651599884 , Time: 30904.0222697258 s\n",
      "Batch:  2620 , l1 Loss:  0.09982427433133126 , Time: 30916.942880392075 s\n",
      "Batch:  2630 , l1 Loss:  0.0986778162419796 , Time: 30929.774524450302 s\n",
      "Batch:  2640 , l1 Loss:  0.10179335176944733 , Time: 30942.702518701553 s\n",
      "Batch:  2650 , l1 Loss:  0.10148065909743309 , Time: 30955.597086429596 s\n",
      "Batch:  2660 , l1 Loss:  0.10148991867899895 , Time: 30968.49508213997 s\n",
      "Batch:  2670 , l1 Loss:  0.09933649301528931 , Time: 30981.435520887375 s\n",
      "Batch:  2680 , l1 Loss:  0.10082468539476394 , Time: 30994.470110416412 s\n",
      "Batch:  2690 , l1 Loss:  0.10056249648332596 , Time: 31007.445172548294 s\n",
      "Batch:  2700 , l1 Loss:  0.10155557468533516 , Time: 31020.404406785965 s\n",
      "Batch:  2710 , l1 Loss:  0.10032337605953216 , Time: 31033.30423784256 s\n",
      "Batch:  2720 , l1 Loss:  0.10055029094219207 , Time: 31046.205515146255 s\n",
      "Batch:  2730 , l1 Loss:  0.1011347934603691 , Time: 31059.124651908875 s\n",
      "Batch:  2740 , l1 Loss:  0.09942395836114884 , Time: 31072.16119337082 s\n",
      "Batch:  2750 , l1 Loss:  0.10169902890920639 , Time: 31085.093701839447 s\n",
      "Batch:  2760 , l1 Loss:  0.0990960419178009 , Time: 31098.007232904434 s\n",
      "Batch:  2770 , l1 Loss:  0.10029922425746918 , Time: 31110.90843272209 s\n",
      "Batch:  2780 , l1 Loss:  0.10233757942914963 , Time: 31123.80627989769 s\n",
      "Batch:  2790 , l1 Loss:  0.1009642094373703 , Time: 31136.664266347885 s\n",
      "Batch:  2800 , l1 Loss:  0.10054879412055015 , Time: 31149.701375722885 s\n",
      "Batch:  2810 , l1 Loss:  0.10133277475833893 , Time: 31162.69832086563 s\n",
      "Batch:  2820 , l1 Loss:  0.10023357048630714 , Time: 31175.73872089386 s\n",
      "Batch:  2830 , l1 Loss:  0.09825756400823593 , Time: 31188.735491275787 s\n",
      "Batch:  2840 , l1 Loss:  0.0991043321788311 , Time: 31201.74901843071 s\n",
      "Batch:  2850 , l1 Loss:  0.10050140395760536 , Time: 31214.744138479233 s\n",
      "Batch:  2860 , l1 Loss:  0.10206632018089294 , Time: 31227.761172533035 s\n",
      "Batch:  2870 , l1 Loss:  0.09936998933553695 , Time: 31240.754489660263 s\n",
      "Batch:  2880 , l1 Loss:  0.10044027417898178 , Time: 31253.795476675034 s\n",
      "Batch:  2890 , l1 Loss:  0.09936678633093834 , Time: 31266.78740143776 s\n",
      "Batch:  2900 , l1 Loss:  0.10015372037887574 , Time: 31279.760885953903 s\n",
      "Batch:  2910 , l1 Loss:  0.10182890966534615 , Time: 31292.75559735298 s\n",
      "Batch:  2920 , l1 Loss:  0.10369589179754257 , Time: 31305.746938467026 s\n",
      "Batch:  2930 , l1 Loss:  0.10196196362376213 , Time: 31318.722967863083 s\n",
      "Batch:  2940 , l1 Loss:  0.10193484127521515 , Time: 31331.866645097733 s\n",
      "Batch:  2950 , l1 Loss:  0.10169148594141006 , Time: 31344.857789754868 s\n",
      "Batch:  2960 , l1 Loss:  0.10115076526999474 , Time: 31357.872828245163 s\n",
      "Batch:  2970 , l1 Loss:  0.10119618996977806 , Time: 31370.82420873642 s\n",
      "Batch:  2980 , l1 Loss:  0.10049550235271454 , Time: 31383.842771053314 s\n",
      "Batch:  2990 , l1 Loss:  0.1000227764248848 , Time: 31396.838839292526 s\n",
      "Batch:  3000 , l1 Loss:  0.09895664900541305 , Time: 31409.81759929657 s\n",
      "Batch:  3010 , l1 Loss:  0.09965036213397979 , Time: 31422.86798095703 s\n",
      "Batch:  3020 , l1 Loss:  0.10196159631013871 , Time: 31435.805163383484 s\n",
      "Batch:  3030 , l1 Loss:  0.10116270333528518 , Time: 31448.7931368351 s\n",
      "Batch:  3040 , l1 Loss:  0.10056603252887726 , Time: 31461.760836839676 s\n",
      "Batch:  3050 , l1 Loss:  0.10066162049770355 , Time: 31474.61187505722 s\n",
      "Batch:  3060 , l1 Loss:  0.10335494354367256 , Time: 31487.326632976532 s\n",
      "Batch:  3070 , l1 Loss:  0.09983539283275604 , Time: 31500.142528295517 s\n",
      "Batch:  3080 , l1 Loss:  0.10108107179403306 , Time: 31512.99656677246 s\n",
      "Batch:  3090 , l1 Loss:  0.10048123672604561 , Time: 31525.836646556854 s\n",
      "Batch:  3100 , l1 Loss:  0.09968634247779846 , Time: 31538.68973326683 s\n",
      "Batch:  3110 , l1 Loss:  0.10219611749053001 , Time: 31551.540275335312 s\n",
      "Batch:  3120 , l1 Loss:  0.1003503181040287 , Time: 31564.38570213318 s\n",
      "Batch:  3130 , l1 Loss:  0.10248507186770439 , Time: 31577.242961406708 s\n",
      "Batch:  3140 , l1 Loss:  0.1026733547449112 , Time: 31590.34220647812 s\n",
      "Batch:  3150 , l1 Loss:  0.09950785338878632 , Time: 31603.31538081169 s\n",
      "Batch:  3160 , l1 Loss:  0.1018843598663807 , Time: 31616.27837395668 s\n",
      "Batch:  3170 , l1 Loss:  0.10003100708127022 , Time: 31629.242398500443 s\n",
      "Batch:  3180 , l1 Loss:  0.10086356624960899 , Time: 31642.204589366913 s\n",
      "Batch:  3190 , l1 Loss:  0.10045711696147919 , Time: 31655.18428850174 s\n",
      "Batch:  3200 , l1 Loss:  0.1013008937239647 , Time: 31668.15962791443 s\n",
      "Batch:  3210 , l1 Loss:  0.10073278099298477 , Time: 31681.074202775955 s\n",
      "Batch:  3220 , l1 Loss:  0.101316087692976 , Time: 31694.01272726059 s\n",
      "Batch:  3230 , l1 Loss:  0.10068985298275948 , Time: 31706.988678455353 s\n",
      "Batch:  3240 , l1 Loss:  0.10019388943910598 , Time: 31719.94613146782 s\n",
      "Batch:  3250 , l1 Loss:  0.1001888707280159 , Time: 31732.914863348007 s\n",
      "Batch:  3260 , l1 Loss:  0.09962814897298813 , Time: 31745.79919219017 s\n",
      "Batch:  3270 , l1 Loss:  0.10145134180784225 , Time: 31758.67315387726 s\n",
      "Batch:  3280 , l1 Loss:  0.10254112035036086 , Time: 31771.58872818947 s\n",
      "Batch:  3290 , l1 Loss:  0.1014972597360611 , Time: 31784.545518159866 s\n",
      "Batch:  3300 , l1 Loss:  0.09992717504501343 , Time: 31797.46455001831 s\n",
      "Batch:  3310 , l1 Loss:  0.100424525141716 , Time: 31810.39665412903 s\n",
      "Batch:  3320 , l1 Loss:  0.10020094364881516 , Time: 31823.335458278656 s\n",
      "Batch:  3330 , l1 Loss:  0.09900003150105477 , Time: 31836.29433631897 s\n",
      "Batch:  3340 , l1 Loss:  0.10076849237084388 , Time: 31849.249244213104 s\n",
      "Batch:  3350 , l1 Loss:  0.09990057349205017 , Time: 31862.17385482788 s\n",
      "Batch:  3360 , l1 Loss:  0.09961641281843185 , Time: 31875.09064745903 s\n",
      "Batch:  3370 , l1 Loss:  0.09860719665884972 , Time: 31888.040363788605 s\n",
      "Batch:  3380 , l1 Loss:  0.09949937760829926 , Time: 31900.972897529602 s\n",
      "Batch:  3390 , l1 Loss:  0.09982312247157096 , Time: 31913.909603595734 s\n",
      "Batch:  3400 , l1 Loss:  0.10041602849960327 , Time: 31926.887773036957 s\n",
      "Batch:  3410 , l1 Loss:  0.1010764129459858 , Time: 31939.921690940857 s\n",
      "Batch:  3420 , l1 Loss:  0.09950494319200516 , Time: 31953.0666744709 s\n",
      "Batch:  3430 , l1 Loss:  0.10146965757012368 , Time: 31966.187992811203 s\n",
      "Batch:  3440 , l1 Loss:  0.10029842928051949 , Time: 31979.2293343544 s\n",
      "Batch:  3450 , l1 Loss:  0.10064707472920417 , Time: 31992.20953822136 s\n",
      "Batch:  3460 , l1 Loss:  0.10095942243933678 , Time: 32005.223669290543 s\n",
      "Batch:  3470 , l1 Loss:  0.09896808788180352 , Time: 32018.239688396454 s\n",
      "Batch:  3480 , l1 Loss:  0.10028312653303147 , Time: 32031.239112138748 s\n",
      "Batch:  3490 , l1 Loss:  0.09935744479298592 , Time: 32044.249796390533 s\n",
      "Batch:  3500 , l1 Loss:  0.10004743933677673 , Time: 32057.247446775436 s\n",
      "Batch:  3510 , l1 Loss:  0.10068556070327758 , Time: 32070.288786411285 s\n",
      "Batch:  3520 , l1 Loss:  0.09972618669271469 , Time: 32083.279121160507 s\n",
      "Batch:  3530 , l1 Loss:  0.09894705265760421 , Time: 32096.23526287079 s\n",
      "Batch:  3540 , l1 Loss:  0.09949091374874115 , Time: 32109.209050655365 s\n",
      "Batch:  3550 , l1 Loss:  0.1008442223072052 , Time: 32122.1991853714 s\n",
      "Batch:  3560 , l1 Loss:  0.1005592055618763 , Time: 32135.218757629395 s\n",
      "Batch:  3570 , l1 Loss:  0.10245739743113517 , Time: 32148.197794914246 s\n",
      "Batch:  3580 , l1 Loss:  0.10100415647029877 , Time: 32161.17287683487 s\n",
      "Batch:  3590 , l1 Loss:  0.10336027890443802 , Time: 32174.2095413208 s\n",
      "Batch:  3600 , l1 Loss:  0.10144351869821548 , Time: 32187.204034090042 s\n",
      "Batch:  3610 , l1 Loss:  0.10194339454174042 , Time: 32200.181803941727 s\n",
      "Batch:  3620 , l1 Loss:  0.10394354686141014 , Time: 32213.159040927887 s\n",
      "Batch:  3630 , l1 Loss:  0.09926604852080345 , Time: 32226.1531791687 s\n",
      "Batch:  3640 , l1 Loss:  0.10243573188781738 , Time: 32239.135642051697 s\n",
      "Batch:  3650 , l1 Loss:  0.10104470998048783 , Time: 32252.16929745674 s\n",
      "Batch:  3660 , l1 Loss:  0.10325618907809257 , Time: 32265.18820810318 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  3670 , l1 Loss:  0.09983877763152123 , Time: 32278.2036986351 s\n",
      "Batch:  3680 , l1 Loss:  0.10030801892280579 , Time: 32291.236379623413 s\n",
      "Batch:  3690 , l1 Loss:  0.10166999697685242 , Time: 32304.212918758392 s\n",
      "Batch:  3700 , l1 Loss:  0.10088608115911483 , Time: 32317.250661849976 s\n",
      "Batch:  3710 , l1 Loss:  0.10052293315529823 , Time: 32330.25079727173 s\n",
      "Batch:  3720 , l1 Loss:  0.10248799994587898 , Time: 32343.15325665474 s\n",
      "Batch:  3730 , l1 Loss:  0.09996562823653221 , Time: 32355.93921971321 s\n",
      "Batch:  3740 , l1 Loss:  0.09995659813284874 , Time: 32368.75483727455 s\n",
      "Batch:  3750 , l1 Loss:  0.09980555400252342 , Time: 32381.69346833229 s\n",
      "Batch:  3760 , l1 Loss:  0.10138349756598472 , Time: 32394.670224428177 s\n",
      "Batch:  3770 , l1 Loss:  0.10158933848142623 , Time: 32407.586256742477 s\n",
      "Batch:  3780 , l1 Loss:  0.10122073739767075 , Time: 32420.503121614456 s\n",
      "Batch:  3790 , l1 Loss:  0.10033605322241783 , Time: 32433.43492078781 s\n",
      "Batch:  3800 , l1 Loss:  0.10133186429738998 , Time: 32446.371569156647 s\n",
      "Batch:  3810 , l1 Loss:  0.09953555166721344 , Time: 32459.327303409576 s\n",
      "Batch:  3820 , l1 Loss:  0.1002329058945179 , Time: 32472.26600265503 s\n",
      "Batch:  3830 , l1 Loss:  0.10186181142926216 , Time: 32485.19806957245 s\n",
      "Batch:  3840 , l1 Loss:  0.10066028162837029 , Time: 32498.153324842453 s\n",
      "Batch:  3850 , l1 Loss:  0.09932958409190178 , Time: 32511.124397277832 s\n",
      "Batch:  3860 , l1 Loss:  0.09980130419135094 , Time: 32524.1012134552 s\n",
      "Batch:  3870 , l1 Loss:  0.10072298645973206 , Time: 32537.079241514206 s\n",
      "Batch:  3880 , l1 Loss:  0.0991572804749012 , Time: 32550.0213906765 s\n",
      "Batch:  3890 , l1 Loss:  0.10102900266647338 , Time: 32562.934193134308 s\n",
      "Batch:  3900 , l1 Loss:  0.10202044099569321 , Time: 32575.867000341415 s\n",
      "Batch:  3910 , l1 Loss:  0.10048159211874008 , Time: 32588.82761645317 s\n",
      "Batch:  3920 , l1 Loss:  0.10216962695121765 , Time: 32601.807151556015 s\n",
      "Batch:  3930 , l1 Loss:  0.10044394433498383 , Time: 32614.805136203766 s\n",
      "Batch:  3940 , l1 Loss:  0.10055609717965126 , Time: 32627.78163933754 s\n",
      "Batch:  3950 , l1 Loss:  0.10143219158053399 , Time: 32640.739562511444 s\n",
      "Batch:  3960 , l1 Loss:  0.10122845023870468 , Time: 32653.73423576355 s\n",
      "Batch:  3970 , l1 Loss:  0.1009271651506424 , Time: 32666.721932411194 s\n",
      "Batch:  3980 , l1 Loss:  0.09897514283657075 , Time: 32679.738742351532 s\n",
      "Batch:  3990 , l1 Loss:  0.10184196382761002 , Time: 32692.696412324905 s\n",
      "Batch:  4000 , l1 Loss:  0.09957169145345687 , Time: 32705.71304655075 s\n",
      "Batch:  4010 , l1 Loss:  0.10258936360478402 , Time: 32718.732741117477 s\n",
      "Batch:  4020 , l1 Loss:  0.09981578662991523 , Time: 32731.74951648712 s\n",
      "Batch:  4030 , l1 Loss:  0.10068158432841301 , Time: 32744.732666015625 s\n",
      "Batch:  4040 , l1 Loss:  0.10028032138943672 , Time: 32757.708893299103 s\n",
      "Batch:  4050 , l1 Loss:  0.10079405307769776 , Time: 32770.68616318703 s\n",
      "Batch:  4060 , l1 Loss:  0.10173401236534119 , Time: 32783.641055583954 s\n",
      "Batch:  4070 , l1 Loss:  0.10418252348899841 , Time: 32796.7005443573 s\n",
      "Batch:  4080 , l1 Loss:  0.10361667573451996 , Time: 32809.72320151329 s\n",
      "Batch:  4090 , l1 Loss:  0.10410105362534523 , Time: 32822.80000662804 s\n",
      "Batch:  4100 , l1 Loss:  0.10184892490506173 , Time: 32835.83789110184 s\n",
      "Batch:  4110 , l1 Loss:  0.1027110457420349 , Time: 32848.81034088135 s\n",
      "Batch:  4120 , l1 Loss:  0.09939701333642006 , Time: 32861.79077887535 s\n",
      "Batch:  4130 , l1 Loss:  0.10135325267910958 , Time: 32874.763904094696 s\n",
      "Batch:  4140 , l1 Loss:  0.10127119645476342 , Time: 32887.72415781021 s\n",
      "Batch:  4150 , l1 Loss:  0.10014853551983834 , Time: 32900.71832370758 s\n",
      "Batch:  4160 , l1 Loss:  0.09875921607017517 , Time: 32913.720171928406 s\n",
      "Batch:  4170 , l1 Loss:  0.09955778121948242 , Time: 32926.669169425964 s\n",
      "Batch:  4180 , l1 Loss:  0.10041939243674278 , Time: 32939.66978216171 s\n",
      "Batch:  4190 , l1 Loss:  0.10163627564907074 , Time: 32952.669847011566 s\n",
      "Batch:  4200 , l1 Loss:  0.10164752528071404 , Time: 32965.68170666695 s\n",
      "Batch:  4210 , l1 Loss:  0.09946293458342552 , Time: 32978.700984716415 s\n",
      "Batch:  4220 , l1 Loss:  0.10050404816865921 , Time: 32991.72106170654 s\n",
      "Batch:  4230 , l1 Loss:  0.10028458759188652 , Time: 33004.782620191574 s\n",
      "Batch:  4240 , l1 Loss:  0.10081319808959961 , Time: 33017.77975797653 s\n",
      "Batch:  4250 , l1 Loss:  0.10165042877197265 , Time: 33030.856803655624 s\n",
      "Batch:  4260 , l1 Loss:  0.10008087828755378 , Time: 33043.83147883415 s\n",
      "Batch:  4270 , l1 Loss:  0.10068603008985519 , Time: 33056.75034189224 s\n",
      "Batch:  4280 , l1 Loss:  0.10062922015786172 , Time: 33069.62574386597 s\n",
      "Batch:  4290 , l1 Loss:  0.10052287876605988 , Time: 33082.56656384468 s\n",
      "Batch:  4300 , l1 Loss:  0.09935354888439178 , Time: 33095.50110888481 s\n",
      "Batch:  4310 , l1 Loss:  0.10235715582966805 , Time: 33108.41556239128 s\n",
      "Batch:  4320 , l1 Loss:  0.10030768811702728 , Time: 33121.39345574379 s\n",
      "Batch:  4330 , l1 Loss:  0.10131818652153016 , Time: 33134.370451927185 s\n",
      "Batch:  4340 , l1 Loss:  0.09965426772832871 , Time: 33147.34971618652 s\n",
      "Batch:  4350 , l1 Loss:  0.09996898323297501 , Time: 33160.305393218994 s\n",
      "Batch:  4360 , l1 Loss:  0.09984825551509857 , Time: 33173.28323984146 s\n",
      "Batch:  4370 , l1 Loss:  0.10041533857584 , Time: 33186.242382764816 s\n",
      "Batch:  4380 , l1 Loss:  0.09927035272121429 , Time: 33199.19930052757 s\n",
      "Batch:  4390 , l1 Loss:  0.0988236241042614 , Time: 33212.19884967804 s\n",
      "Batch:  4400 , l1 Loss:  0.09896470382809638 , Time: 33225.19778442383 s\n",
      "Batch:  4410 , l1 Loss:  0.09907758012413978 , Time: 33238.18976020813 s\n",
      "Batch:  4420 , l1 Loss:  0.09783991649746895 , Time: 33251.144758701324 s\n",
      "Batch:  4430 , l1 Loss:  0.1004343070089817 , Time: 33264.16421747208 s\n",
      "Batch:  4440 , l1 Loss:  0.10042728185653686 , Time: 33277.20562648773 s\n",
      "Batch:  4450 , l1 Loss:  0.10220576524734497 , Time: 33290.17412400246 s\n",
      "Batch:  4460 , l1 Loss:  0.10083170980215073 , Time: 33303.13988661766 s\n",
      "Batch:  4470 , l1 Loss:  0.10004231482744216 , Time: 33316.15862989426 s\n",
      "Batch:  4480 , l1 Loss:  0.09872237518429756 , Time: 33329.15628528595 s\n",
      "Batch:  4490 , l1 Loss:  0.09970111101865768 , Time: 33342.13552904129 s\n",
      "Batch:  4500 , l1 Loss:  0.10099857896566392 , Time: 33355.11652350426 s\n",
      "Batch:  4510 , l1 Loss:  0.10062824264168739 , Time: 33368.15348982811 s\n",
      "Batch:  4520 , l1 Loss:  0.09842605441808701 , Time: 33381.12920832634 s\n",
      "Batch:  4530 , l1 Loss:  0.09944667294621468 , Time: 33394.16713643074 s\n",
      "Batch:  4540 , l1 Loss:  0.10074460133910179 , Time: 33407.12808179855 s\n",
      "Batch:  4550 , l1 Loss:  0.09994455501437187 , Time: 33420.14756536484 s\n",
      "Batch:  4560 , l1 Loss:  0.09995106756687164 , Time: 33433.16288971901 s\n",
      "Batch:  4570 , l1 Loss:  0.09964616596698761 , Time: 33446.119272470474 s\n",
      "Batch:  4580 , l1 Loss:  0.10169051885604859 , Time: 33459.13515496254 s\n",
      "Batch:  4590 , l1 Loss:  0.09989710673689842 , Time: 33472.15067744255 s\n",
      "Batch:  4600 , l1 Loss:  0.10008940324187279 , Time: 33485.11827015877 s\n",
      "Batch:  4610 , l1 Loss:  0.09819266796112061 , Time: 33498.090715646744 s\n",
      "Batch:  4620 , l1 Loss:  0.10124362409114837 , Time: 33511.12697124481 s\n",
      "Batch:  4630 , l1 Loss:  0.10007860139012337 , Time: 33524.105830192566 s\n",
      "Batch:  4640 , l1 Loss:  0.1001399502158165 , Time: 33537.06490969658 s\n",
      "Batch:  4650 , l1 Loss:  0.1016784965991974 , Time: 33550.04251360893 s\n",
      "Batch:  4660 , l1 Loss:  0.09917952120304108 , Time: 33563.07896399498 s\n",
      "Batch:  4670 , l1 Loss:  0.09963159710168838 , Time: 33576.05690598488 s\n",
      "Batch:  4680 , l1 Loss:  0.09886209890246392 , Time: 33589.034069776535 s\n",
      "Batch:  4690 , l1 Loss:  0.09980185925960541 , Time: 33602.014667749405 s\n",
      "Batch:  4700 , l1 Loss:  0.10192412808537483 , Time: 33615.032109975815 s\n",
      "Batch:  4710 , l1 Loss:  0.10148525834083558 , Time: 33628.03070664406 s\n",
      "Batch:  4720 , l1 Loss:  0.0996553547680378 , Time: 33641.090723752975 s\n",
      "Batch:  4730 , l1 Loss:  0.09862383604049682 , Time: 33654.04861545563 s\n",
      "Batch:  4740 , l1 Loss:  0.09974816143512726 , Time: 33667.069412469864 s\n",
      "Batch:  4750 , l1 Loss:  0.10055659413337707 , Time: 33680.09030652046 s\n",
      "Batch:  4760 , l1 Loss:  0.10099194720387458 , Time: 33693.06640601158 s\n",
      "Batch:  4770 , l1 Loss:  0.10296839475631714 , Time: 33706.06167125702 s\n",
      "Batch:  4780 , l1 Loss:  0.10034314766526223 , Time: 33719.06083011627 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  4790 , l1 Loss:  0.09880012348294258 , Time: 33732.035818099976 s\n",
      "Batch:  4800 , l1 Loss:  0.1016931876540184 , Time: 33745.055603027344 s\n",
      "Batch:  4810 , l1 Loss:  0.10036587417125702 , Time: 33758.09735226631 s\n",
      "Batch:  4820 , l1 Loss:  0.09778079539537429 , Time: 33771.05070948601 s\n",
      "Batch:  4830 , l1 Loss:  0.10132867097854614 , Time: 33784.05187869072 s\n",
      "Batch:  4840 , l1 Loss:  0.10134657323360444 , Time: 33797.10373330116 s\n",
      "Batch:  4850 , l1 Loss:  0.09909924194216728 , Time: 33810.1434738636 s\n",
      "Batch:  4860 , l1 Loss:  0.10084285438060761 , Time: 33823.17971134186 s\n",
      "Batch:  4870 , l1 Loss:  0.10101465433835984 , Time: 33836.235557317734 s\n",
      "Batch:  4880 , l1 Loss:  0.10023643150925636 , Time: 33849.25014424324 s\n",
      "Batch:  4890 , l1 Loss:  0.1002196952700615 , Time: 33862.20684862137 s\n",
      "Batch:  4900 , l1 Loss:  0.10008579641580581 , Time: 33875.242653131485 s\n",
      "Batch:  4910 , l1 Loss:  0.10067836493253708 , Time: 33888.221528053284 s\n",
      "Batch:  4920 , l1 Loss:  0.09923197478055953 , Time: 33901.19810819626 s\n",
      "Batch:  4930 , l1 Loss:  0.09930475205183029 , Time: 33914.173104047775 s\n",
      "Batch:  4940 , l1 Loss:  0.10163703337311744 , Time: 33927.146383047104 s\n",
      "Batch:  4950 , l1 Loss:  0.1013331800699234 , Time: 33940.146384716034 s\n",
      "Batch:  4960 , l1 Loss:  0.10063092932105064 , Time: 33953.121807575226 s\n",
      "Batch:  4970 , l1 Loss:  0.10096103176474572 , Time: 33966.11822080612 s\n",
      "Batch:  4980 , l1 Loss:  0.09939494654536248 , Time: 33979.09707427025 s\n",
      "Batch:  4990 , l1 Loss:  0.10008142441511154 , Time: 33992.07039499283 s\n",
      "Batch:  5000 , l1 Loss:  0.10099150836467743 , Time: 34005.00983738899 s\n",
      "Batch:  5010 , l1 Loss:  0.09974527955055237 , Time: 34018.02834415436 s\n",
      "Batch:  5020 , l1 Loss:  0.10059912502765656 , Time: 34031.007529735565 s\n",
      "Batch:  5030 , l1 Loss:  0.09934941679239273 , Time: 34043.98413562775 s\n",
      "Batch:  5040 , l1 Loss:  0.09947040230035782 , Time: 34056.898178339005 s\n",
      "Batch:  5050 , l1 Loss:  0.10031416267156601 , Time: 34069.87300276756 s\n",
      "Batch:  5060 , l1 Loss:  0.10021713823080063 , Time: 34082.8554854393 s\n",
      "Batch:  5070 , l1 Loss:  0.0997130736708641 , Time: 34095.81006002426 s\n",
      "Batch:  5080 , l1 Loss:  0.10011742413043975 , Time: 34108.8140707016 s\n",
      "Batch:  5090 , l1 Loss:  0.10156699046492576 , Time: 34121.80381798744 s\n",
      "Batch:  5100 , l1 Loss:  0.09978798031806946 , Time: 34134.85800862312 s\n",
      "Batch:  5110 , l1 Loss:  0.09811899289488793 , Time: 34147.79952073097 s\n",
      "Batch:  5120 , l1 Loss:  0.09773756638169288 , Time: 34160.73799204826 s\n",
      "Batch:  5130 , l1 Loss:  0.10011764541268349 , Time: 34173.6812813282 s\n",
      "Batch:  5140 , l1 Loss:  0.10200118646025658 , Time: 34186.67270874977 s\n",
      "Batch:  5150 , l1 Loss:  0.10144353359937668 , Time: 34199.64845299721 s\n",
      "Batch:  5160 , l1 Loss:  0.09979921653866768 , Time: 34212.62697196007 s\n",
      "Batch:  5170 , l1 Loss:  0.10158052816987037 , Time: 34225.605061769485 s\n",
      "Batch:  5180 , l1 Loss:  0.0995446003973484 , Time: 34238.58206129074 s\n",
      "Batch:  5190 , l1 Loss:  0.10000955685973167 , Time: 34251.56148338318 s\n",
      "Batch:  5200 , l1 Loss:  0.09960167855024338 , Time: 34264.54098010063 s\n",
      "Batch:  5210 , l1 Loss:  0.10034497678279877 , Time: 34277.537544965744 s\n",
      "Batch:  5220 , l1 Loss:  0.0995061606168747 , Time: 34290.49695253372 s\n",
      "Batch:  5230 , l1 Loss:  0.09892229288816452 , Time: 34303.454437971115 s\n",
      "Batch:  5240 , l1 Loss:  0.09959747418761253 , Time: 34316.45031905174 s\n",
      "Batch:  5250 , l1 Loss:  0.09946763217449188 , Time: 34329.42894053459 s\n",
      "Batch:  5260 , l1 Loss:  0.10076609998941422 , Time: 34342.42700743675 s\n",
      "Batch:  5270 , l1 Loss:  0.0990940935909748 , Time: 34355.39173436165 s\n",
      "Batch:  5280 , l1 Loss:  0.09866263046860695 , Time: 34368.38359236717 s\n",
      "Batch:  5290 , l1 Loss:  0.10096715092658996 , Time: 34381.371983766556 s\n",
      "Batch:  5300 , l1 Loss:  0.09926498159766198 , Time: 34394.317391872406 s\n",
      "Batch:  5310 , l1 Loss:  0.10070722773671151 , Time: 34407.29281258583 s\n",
      "Batch:  5320 , l1 Loss:  0.10159512162208557 , Time: 34420.27111077309 s\n",
      "Batch:  5330 , l1 Loss:  0.09972279146313667 , Time: 34433.25284123421 s\n",
      "Batch:  5340 , l1 Loss:  0.09918313398957253 , Time: 34446.24551773071 s\n",
      "Batch:  5350 , l1 Loss:  0.09920365735888481 , Time: 34459.20011115074 s\n",
      "Batch:  5360 , l1 Loss:  0.10042770057916642 , Time: 34472.29860830307 s\n",
      "Batch:  5370 , l1 Loss:  0.09988723769783973 , Time: 34485.37768602371 s\n",
      "Batch:  5380 , l1 Loss:  0.10130507871508598 , Time: 34498.432639837265 s\n",
      "Batch:  5390 , l1 Loss:  0.10074551478028297 , Time: 34511.50890183449 s\n",
      "Batch:  5400 , l1 Loss:  0.10118704438209533 , Time: 34524.49326634407 s\n",
      "Batch:  5410 , l1 Loss:  0.10051384642720222 , Time: 34537.49720454216 s\n",
      "Batch:  5420 , l1 Loss:  0.09935952574014664 , Time: 34550.51502084732 s\n",
      "Batch:  5430 , l1 Loss:  0.09981898069381714 , Time: 34563.53548789024 s\n",
      "Batch:  5440 , l1 Loss:  0.10014402121305466 , Time: 34576.57401919365 s\n",
      "Batch:  5450 , l1 Loss:  0.09883111864328384 , Time: 34589.606790304184 s\n",
      "Batch:  5460 , l1 Loss:  0.10091726928949356 , Time: 34602.62080550194 s\n",
      "Batch:  5470 , l1 Loss:  0.10062319859862327 , Time: 34615.63824009895 s\n",
      "Batch:  5480 , l1 Loss:  0.09900335595011711 , Time: 34628.65668845177 s\n",
      "Batch:  5490 , l1 Loss:  0.10221076160669326 , Time: 34641.63685679436 s\n",
      "Batch:  5500 , l1 Loss:  0.10235576555132866 , Time: 34654.65200448036 s\n",
      "Batch:  5510 , l1 Loss:  0.10189511477947236 , Time: 34667.68650269508 s\n",
      "Batch:  5520 , l1 Loss:  0.10092732682824135 , Time: 34680.66126871109 s\n",
      "Batch:  5530 , l1 Loss:  0.1016643337905407 , Time: 34693.661095142365 s\n",
      "Batch:  5540 , l1 Loss:  0.09870960414409638 , Time: 34706.661440849304 s\n",
      "Batch:  5550 , l1 Loss:  0.09934445023536682 , Time: 34719.65067625046 s\n",
      "Batch:  5560 , l1 Loss:  0.09962386339902878 , Time: 34732.649575948715 s\n",
      "Batch:  5570 , l1 Loss:  0.1008064717054367 , Time: 34745.62848639488 s\n",
      "Batch:  5580 , l1 Loss:  0.10060573741793633 , Time: 34758.62741780281 s\n",
      "Batch:  5590 , l1 Loss:  0.10085400417447091 , Time: 34771.58131766319 s\n",
      "Batch:  5600 , l1 Loss:  0.10018128752708436 , Time: 34784.55669617653 s\n",
      "Batch:  5610 , l1 Loss:  0.09774044752120972 , Time: 34797.55441451073 s\n",
      "Batch:  5620 , l1 Loss:  0.0994300290942192 , Time: 34810.52727460861 s\n",
      "Batch:  5630 , l1 Loss:  0.10038424953818322 , Time: 34823.5084233284 s\n",
      "Batch:  5640 , l1 Loss:  0.09889623746275902 , Time: 34836.54533100128 s\n",
      "Batch:  5650 , l1 Loss:  0.09985472708940506 , Time: 34849.50406861305 s\n",
      "Batch:  5660 , l1 Loss:  0.09983139336109162 , Time: 34862.440046072006 s\n",
      "Batch:  5670 , l1 Loss:  0.1004331074655056 , Time: 34875.379076480865 s\n",
      "Batch:  5680 , l1 Loss:  0.09992314577102661 , Time: 34888.388391017914 s\n",
      "Batch:  5690 , l1 Loss:  0.09998817294836045 , Time: 34901.34803342819 s\n",
      "Batch:  5700 , l1 Loss:  0.09987917095422745 , Time: 34914.28676509857 s\n",
      "Batch:  5710 , l1 Loss:  0.10037051737308503 , Time: 34927.22447538376 s\n",
      "Batch:  5720 , l1 Loss:  0.100288125872612 , Time: 34940.194811820984 s\n",
      "Batch:  5730 , l1 Loss:  0.09949318319559097 , Time: 34953.19956469536 s\n",
      "Batch:  5740 , l1 Loss:  0.09948698654770852 , Time: 34966.21810746193 s\n",
      "Batch:  5750 , l1 Loss:  0.10082269459962845 , Time: 34979.23617172241 s\n",
      "Batch:  5760 , l1 Loss:  0.1007359892129898 , Time: 34992.24678635597 s\n",
      "Batch:  5770 , l1 Loss:  0.10034958198666573 , Time: 35005.301418066025 s\n",
      "Batch:  5780 , l1 Loss:  0.1003944918513298 , Time: 35018.32211089134 s\n",
      "Batch:  5790 , l1 Loss:  0.09764885529875755 , Time: 35031.3215944767 s\n",
      "Batch:  5800 , l1 Loss:  0.10103738084435462 , Time: 35044.333416461945 s\n",
      "Batch:  5810 , l1 Loss:  0.10158922374248505 , Time: 35057.37275981903 s\n",
      "Batch:  5820 , l1 Loss:  0.1010387048125267 , Time: 35070.40365934372 s\n",
      "Batch:  5830 , l1 Loss:  0.10003717467188836 , Time: 35083.45910644531 s\n",
      "Batch:  5840 , l1 Loss:  0.09870302006602287 , Time: 35096.27852392197 s\n",
      "Batch:  5850 , l1 Loss:  0.09867208674550057 , Time: 35109.15427279472 s\n",
      "Batch:  5860 , l1 Loss:  0.1006777562201023 , Time: 35122.05055141449 s\n",
      "Batch:  5870 , l1 Loss:  0.10060030072927476 , Time: 35134.92611312866 s\n",
      "Batch:  5880 , l1 Loss:  0.09980101212859153 , Time: 35147.803575754166 s\n",
      "Batch:  5890 , l1 Loss:  0.09976996406912804 , Time: 35160.68312168121 s\n",
      "Batch:  5900 , l1 Loss:  0.10040682703256607 , Time: 35173.59946370125 s\n",
      "Batch:  5910 , l1 Loss:  0.10069101974368096 , Time: 35186.528890132904 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  5920 , l1 Loss:  0.10152223780751228 , Time: 35199.4715590477 s\n",
      "Batch:  5930 , l1 Loss:  0.1007527120411396 , Time: 35212.367154598236 s\n",
      "Batch:  5940 , l1 Loss:  0.10187013521790504 , Time: 35225.28562760353 s\n",
      "Batch:  5950 , l1 Loss:  0.09913881719112397 , Time: 35238.324226379395 s\n",
      "Batch:  5960 , l1 Loss:  0.09940312504768371 , Time: 35251.38167977333 s\n",
      "Batch:  5970 , l1 Loss:  0.09797674715518952 , Time: 35264.38931107521 s\n",
      "Batch:  5980 , l1 Loss:  0.10130699798464775 , Time: 35277.43057227135 s\n",
      "Batch:  5990 , l1 Loss:  0.09882613718509674 , Time: 35290.45270204544 s\n",
      "Batch:  6000 , l1 Loss:  0.10026866495609284 , Time: 35303.491309165955 s\n",
      "Batch:  6010 , l1 Loss:  0.10060828775167466 , Time: 35316.60376572609 s\n",
      "Batch:  6020 , l1 Loss:  0.09808481708168984 , Time: 35329.639719963074 s\n",
      "Batch:  6030 , l1 Loss:  0.10112260282039642 , Time: 35342.67514538765 s\n",
      "Batch:  6040 , l1 Loss:  0.09871230721473694 , Time: 35355.67322182655 s\n",
      "Batch:  6050 , l1 Loss:  0.09989573955535888 , Time: 35368.56791090965 s\n",
      "Batch:  6060 , l1 Loss:  0.10124612823128701 , Time: 35381.442888736725 s\n",
      "Batch:  6070 , l1 Loss:  0.09940363094210625 , Time: 35394.295986652374 s\n",
      "Batch:  6080 , l1 Loss:  0.09956988245248795 , Time: 35407.171243429184 s\n",
      "Batch:  6090 , l1 Loss:  0.10023945719003677 , Time: 35420.06799817085 s\n",
      "Batch:  6100 , l1 Loss:  0.09927662536501884 , Time: 35432.98804950714 s\n",
      "Batch:  6110 , l1 Loss:  0.09961205422878265 , Time: 35445.88082432747 s\n",
      "Batch:  6120 , l1 Loss:  0.09868030995130539 , Time: 35458.75176858902 s\n",
      "Batch:  6130 , l1 Loss:  0.09886989817023277 , Time: 35471.60887026787 s\n",
      "Batch:  6140 , l1 Loss:  0.10045682266354561 , Time: 35484.52164173126 s\n",
      "Batch:  6150 , l1 Loss:  0.09974960163235665 , Time: 35497.379824876785 s\n",
      "Batch:  6160 , l1 Loss:  0.09932011812925338 , Time: 35510.257667303085 s\n",
      "Batch:  6170 , l1 Loss:  0.09951279312372208 , Time: 35523.16947197914 s\n",
      "Batch:  6180 , l1 Loss:  0.09921998232603073 , Time: 35536.0239880085 s\n",
      "Batch:  6190 , l1 Loss:  0.09821355938911439 , Time: 35548.93668317795 s\n",
      "Batch:  6200 , l1 Loss:  0.10285955220460892 , Time: 35561.87986898422 s\n",
      "Batch:  6210 , l1 Loss:  0.09930110871791839 , Time: 35574.713480234146 s\n",
      "Batch:  6220 , l1 Loss:  0.09971523955464363 , Time: 35587.61349105835 s\n",
      "Batch:  6230 , l1 Loss:  0.09955827370285988 , Time: 35600.48206496239 s\n",
      "Batch:  6240 , l1 Loss:  0.09816043749451638 , Time: 35613.36935710907 s\n",
      "Batch:  6250 , l1 Loss:  0.09845752865076066 , Time: 35626.24277305603 s\n",
      "Batch:  6260 , l1 Loss:  0.10052607133984566 , Time: 35639.1050286293 s\n",
      "Batch:  6270 , l1 Loss:  0.10174906626343727 , Time: 35652.0012114048 s\n",
      "Batch:  6280 , l1 Loss:  0.09899736121296883 , Time: 35664.89562034607 s\n",
      "Batch:  6290 , l1 Loss:  0.09770544096827508 , Time: 35677.810455322266 s\n",
      "Batch:  6300 , l1 Loss:  0.10035105422139168 , Time: 35690.70740246773 s\n",
      "Batch:  6310 , l1 Loss:  0.10030164420604706 , Time: 35703.57712030411 s\n",
      "Batch:  6320 , l1 Loss:  0.09984855577349663 , Time: 35716.47956109047 s\n",
      "Batch:  6330 , l1 Loss:  0.09840336069464684 , Time: 35729.37370848656 s\n",
      "Batch:  6340 , l1 Loss:  0.09978414252400399 , Time: 35742.22686314583 s\n",
      "Batch:  6350 , l1 Loss:  0.1017493560910225 , Time: 35755.100800037384 s\n",
      "Batch:  6360 , l1 Loss:  0.10112466812133789 , Time: 35767.97552013397 s\n",
      "Batch:  6370 , l1 Loss:  0.09891514256596565 , Time: 35780.89656043053 s\n",
      "Batch:  6380 , l1 Loss:  0.10068741366267205 , Time: 35793.81439971924 s\n",
      "Batch:  6390 , l1 Loss:  0.09974664822220802 , Time: 35806.709790468216 s\n",
      "Batch:  6400 , l1 Loss:  0.09854300916194916 , Time: 35819.58557653427 s\n",
      "Batch:  6410 , l1 Loss:  0.10093335881829262 , Time: 35832.463359832764 s\n",
      "Batch:  6420 , l1 Loss:  0.10066916197538375 , Time: 35845.33926868439 s\n",
      "Batch:  6430 , l1 Loss:  0.09990084692835807 , Time: 35858.19513320923 s\n",
      "Batch:  6440 , l1 Loss:  0.09970212057232856 , Time: 35871.07262825966 s\n",
      "Batch:  6450 , l1 Loss:  0.10058193653821945 , Time: 35883.96696424484 s\n",
      "Batch:  6460 , l1 Loss:  0.0995167076587677 , Time: 35896.78022837639 s\n",
      "Batch:  6470 , l1 Loss:  0.10108909383416176 , Time: 35909.68824195862 s\n",
      "Batch:  6480 , l1 Loss:  0.09951972737908363 , Time: 35922.623364925385 s\n",
      "Batch:  6490 , l1 Loss:  0.10031885802745819 , Time: 35935.555909872055 s\n",
      "Batch:  6500 , l1 Loss:  0.1010181337594986 , Time: 35948.47143411636 s\n",
      "Batch:  6510 , l1 Loss:  0.09907094091176986 , Time: 35961.4478290081 s\n",
      "Batch:  6520 , l1 Loss:  0.10201524719595909 , Time: 35974.352632284164 s\n",
      "Batch:  6530 , l1 Loss:  0.0988863505423069 , Time: 35987.26294755936 s\n",
      "Batch:  6540 , l1 Loss:  0.10144825056195259 , Time: 36000.16121530533 s\n",
      "Batch:  6550 , l1 Loss:  0.10092134699225426 , Time: 36013.28443169594 s\n",
      "Batch:  6560 , l1 Loss:  0.09848409295082092 , Time: 36026.20503282547 s\n",
      "Batch:  6570 , l1 Loss:  0.09922523647546769 , Time: 36039.109127283096 s\n",
      "Batch:  6580 , l1 Loss:  0.09881067574024201 , Time: 36052.06746339798 s\n",
      "Batch:  6590 , l1 Loss:  0.10147190243005752 , Time: 36065.02380776405 s\n",
      "Batch:  6600 , l1 Loss:  0.09940164610743522 , Time: 36077.98370528221 s\n",
      "Batch:  6610 , l1 Loss:  0.1001210242509842 , Time: 36090.958770513535 s\n",
      "Batch:  6620 , l1 Loss:  0.10104826092720032 , Time: 36103.91833615303 s\n",
      "Batch:  6630 , l1 Loss:  0.09897094070911408 , Time: 36116.954773664474 s\n",
      "Batch:  6640 , l1 Loss:  0.09932786002755165 , Time: 36129.960918188095 s\n",
      "Batch:  6650 , l1 Loss:  0.10198968127369881 , Time: 36142.948008060455 s\n",
      "Batch:  6660 , l1 Loss:  0.09794982969760894 , Time: 36155.968349695206 s\n",
      "Batch:  6670 , l1 Loss:  0.09787323623895645 , Time: 36168.97527217865 s\n",
      "Batch:  6680 , l1 Loss:  0.1000635027885437 , Time: 36181.92398095131 s\n",
      "Batch:  6690 , l1 Loss:  0.10002041906118393 , Time: 36194.879526376724 s\n",
      "Batch:  6700 , l1 Loss:  0.09957705587148666 , Time: 36207.85465049744 s\n",
      "Batch:  6710 , l1 Loss:  0.10175234600901603 , Time: 36220.78903961182 s\n",
      "Batch:  6720 , l1 Loss:  0.10008737444877625 , Time: 36233.74656009674 s\n",
      "Batch:  6730 , l1 Loss:  0.09850466623902321 , Time: 36246.66622686386 s\n",
      "Batch:  6740 , l1 Loss:  0.09996665641665459 , Time: 36259.60256314278 s\n",
      "Batch:  6750 , l1 Loss:  0.0991801716387272 , Time: 36272.594714164734 s\n",
      "Batch:  6760 , l1 Loss:  0.10063445270061493 , Time: 36285.53153920174 s\n",
      "Batch:  6770 , l1 Loss:  0.09931078031659127 , Time: 36298.45758795738 s\n",
      "Batch:  6780 , l1 Loss:  0.09926451593637467 , Time: 36311.390906095505 s\n",
      "Batch:  6790 , l1 Loss:  0.09937516674399376 , Time: 36324.259066820145 s\n",
      "Batch:  6800 , l1 Loss:  0.10231685489416123 , Time: 36337.13221359253 s\n",
      "Batch:  6810 , l1 Loss:  0.10034034997224808 , Time: 36349.98506426811 s\n",
      "Batch:  6820 , l1 Loss:  0.10146113485097885 , Time: 36362.84306311607 s\n",
      "Batch:  6830 , l1 Loss:  0.1000659167766571 , Time: 36375.72221040726 s\n",
      "Batch:  6840 , l1 Loss:  0.10047676786780357 , Time: 36388.54241466522 s\n",
      "Batch:  6850 , l1 Loss:  0.10128419250249862 , Time: 36401.33874082565 s\n",
      "Batch:  6860 , l1 Loss:  0.09960467666387558 , Time: 36414.249160289764 s\n",
      "Batch:  6870 , l1 Loss:  0.10135805159807205 , Time: 36427.14861488342 s\n",
      "Batch:  6880 , l1 Loss:  0.10106440782546997 , Time: 36440.048526763916 s\n",
      "Batch:  6890 , l1 Loss:  0.10055955201387405 , Time: 36452.962399721146 s\n",
      "Batch:  6900 , l1 Loss:  0.09996402412652969 , Time: 36465.859676122665 s\n",
      "Batch:  6910 , l1 Loss:  0.09845919460058213 , Time: 36478.79313492775 s\n",
      "Batch:  6920 , l1 Loss:  0.10002278611063957 , Time: 36491.70799612999 s\n",
      "Batch:  6930 , l1 Loss:  0.09866072311997413 , Time: 36504.6076362133 s\n",
      "Batch:  6940 , l1 Loss:  0.10028163194656373 , Time: 36517.564645290375 s\n",
      "Batch:  6950 , l1 Loss:  0.09962060302495956 , Time: 36530.479091882706 s\n",
      "Batch:  6960 , l1 Loss:  0.10155394375324249 , Time: 36543.39329099655 s\n",
      "Batch:  6970 , l1 Loss:  0.10061811283230782 , Time: 36556.32287287712 s\n",
      "Batch:  6980 , l1 Loss:  0.09960632994771004 , Time: 36569.20217204094 s\n",
      "Batch:  6990 , l1 Loss:  0.10293560177087784 , Time: 36582.10415697098 s\n",
      "Batch:  7000 , l1 Loss:  0.10063686296343803 , Time: 36595.76778149605 s\n",
      "Batch:  7010 , l1 Loss:  0.09995209649205208 , Time: 36610.25667881966 s\n",
      "Batch:  7020 , l1 Loss:  0.09909720718860626 , Time: 36624.36394405365 s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1bf67f6e20d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0msample_pt_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_pt_scale\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msample_pt_query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_pt_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvox_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_pt_distance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-4e399b88e063>\u001b[0m in \u001b[0;36mgetContext\u001b[0;34m(sample_pt_query, vox)\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0mmeshgrid_base\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_pt_query\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0mmeshgrid_base\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_pt_query\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                     \u001b[0;34m(\u001b[0m\u001b[0mmeshgrid_base\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_pt_query\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 ].transpose(0, 1)\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "#test sub module\n",
    "\n",
    "import time\n",
    "\n",
    "vox_size = 32\n",
    "latent_dim = 256\n",
    "con_dim = 32\n",
    "\n",
    "batch_len = len(train_sdf_dataloader)\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(start_epoch, num_epoch):\n",
    "    \n",
    "    loss_list = []\n",
    "    loss_batch = []\n",
    "    \n",
    "    print(\"Epoch: \", epoch)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for i, data in enumerate(train_sdf_dataloader):\n",
    "        \n",
    "        ####################\n",
    "        # Data preparation #\n",
    "        ####################\n",
    "        \n",
    "        # b x 1 x 256 x 256\n",
    "        depth_img = data['depth_img'].to(device)\n",
    "        # b x 128 x 1 x 1\n",
    "        z = discrete_encoder(depth_img)\n",
    "        # b x n x 3\n",
    "        # DO NOT scale by np.sqrt(3)\n",
    "        sample_pt = data['sample_pt']\n",
    "        # b x n x 1\n",
    "        sample_sdf = data['sample_sdf']\n",
    "        \n",
    "        # b x 16 x 64 x 64 x 64\n",
    "        target_vox = data['target_vox'].to(device)\n",
    "        vox_feature = unet(target_vox, z)\n",
    "        #vox_feature = unet(torch.sigmoid(discrete_decoder(mapping(z))))\n",
    "        \n",
    "        ####################\n",
    "        # indexing context #\n",
    "        ####################\n",
    "        \n",
    "        # stay with cpu for v-ram efficiency\n",
    "        sample_pt_normalized = sample_pt + torch.tensor([0.5, 0.5, 0.5])\n",
    "        # (0, vox_size-1)\n",
    "        sample_pt_scale = torch.clamp(sample_pt_normalized* (vox_size-1), 0, (vox_size-1)-1e-5)\n",
    "        # (0, vox_size-2)\n",
    "        sample_pt_query = torch.clamp((sample_pt_scale).int(), 0, (vox_size-2))\n",
    "        sample_pt_distance = sample_pt_scale - sample_pt_query\n",
    "        \n",
    "        context = getContext(sample_pt_query, vox_feature)\n",
    "        \n",
    "        dx = sample_pt_distance[:, :, 0].unsqueeze(1)\n",
    "        dy = sample_pt_distance[:, :, 1].unsqueeze(1)\n",
    "        dz = sample_pt_distance[:, :, 2].unsqueeze(1)\n",
    "        # local feature\n",
    "        con = trilinearInterpolation(context, dx, dy, dz)\n",
    "        \n",
    "        ################################\n",
    "        # Reshape input & forward pass #\n",
    "        ################################\n",
    "        \n",
    "        sample_pt = sample_pt.transpose(-1, -2).to(device)\n",
    "        con = con.to(device)\n",
    "        z = z.squeeze(-1).squeeze(-1).repeat(1, 1, sample_size)\n",
    "        sample_sdf = sample_sdf.transpose(-1, -2).to(device)\n",
    "        \n",
    "        \n",
    "        sample_pt = sample_pt.transpose(-1, -2).reshape(-1, 3)\n",
    "        con = con.transpose(-1, -2).reshape(-1, con_dim)\n",
    "        z = z.transpose(-1, -2).reshape(-1, latent_dim)\n",
    "        sample_sdf = sample_sdf.transpose(-1, -2).reshape(-1, 1)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred_sdf = model(sample_pt, con, z)\n",
    "        \n",
    "        loss_l1 = l1loss(pred_sdf, sample_sdf)\n",
    "        \n",
    "        loss = loss_l1\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        loss_list.append(loss_l1.item())\n",
    "        loss_batch.append(loss_l1.item())\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        #scheduler.step()\n",
    "        \n",
    "        if count != 0 and count % 10 == 0:\n",
    "            loss_batch_avg = np.average(loss_batch)\n",
    "            \n",
    "            print(\"Batch: \", count, \", l1 Loss: \", loss_batch_avg, \", Time: %s s\" % (time.time() - start_time))\n",
    "            \n",
    "            if count % 500 == 0:\n",
    "                torch.save(model.state_dict(), continuous_model_path)\n",
    "                \n",
    "            loss_batch.clear()\n",
    "            \n",
    "        count += 1\n",
    "        \n",
    "    print(\"Epoch: \", epoch, ', l1 loss: ', np.average(loss_list))\n",
    "    \n",
    "    loss_list.clear()\n",
    "    \n",
    "    torch.save(model.state_dict(), continuous_model_path)\n",
    "    \n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'continuous_state_dict': model.state_dict(),\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    })\n",
    "    \n",
    "print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
