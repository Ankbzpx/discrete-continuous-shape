{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "uuid": "f30eb3b7-dbf6-4c48-adee-9610f3cd58d0"
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "uuid": "74cdc08c-592b-4737-bd37-cd75401707b6"
   },
   "outputs": [],
   "source": [
    "# models\n",
    "discrete_encoder_path = 'discrete_encoder.pth'\n",
    "discrete_decoder_path = 'discrete_decoder.pth'\n",
    "mapping_path = 'mapping.pth'\n",
    "unet_path = 'con_unet_full.pth'\n",
    "continuous_model_path = 'continuous_model.pth'\n",
    "\n",
    "hidden_dim_discrete = 128\n",
    "\n",
    "# data preparation\n",
    "data_file = '/home/ankbzpx/datasets/ShapeNet/ShapeNetRenderingh5_v1/03001627/sdf_train_core.h5'\n",
    "sample_size = 2048\n",
    "batch_size = 32\n",
    "split_ratio = 0.9\n",
    "depth_size = 256\n",
    "num_of_workers = 12\n",
    "# training\n",
    "num_epoch = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "uuid": "c10b2893-a503-482e-95bb-2554e96864ba"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "uuid": "6b4c7bac-058e-4eb6-b0cd-a9f21f24ad9e"
   },
   "outputs": [],
   "source": [
    "# reproducible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    " \n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "uuid": "b8cefb09-7a78-4ae7-b9ea-001858c59003"
   },
   "outputs": [],
   "source": [
    "class ChairSDFDataset(Dataset):\n",
    "     \n",
    "    def __init__(self, h5_file):\n",
    "        \n",
    "        self.file_path = h5_file\n",
    "        self.dataset = None\n",
    "        \n",
    "        with h5py.File(self.file_path, 'r') as file:\n",
    "            self.dataset_len = len(file)\n",
    "            self.keys = list(file.keys())\n",
    "            \n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "     \n",
    "    def __len__(self):\n",
    "        return self.dataset_len\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        #start_time = time.time()\n",
    "        \n",
    "        if self.dataset is None:\n",
    "            self.dataset = h5py.File(self.file_path, 'r')\n",
    "         \n",
    "        group = self.dataset[self.keys[idx]]\n",
    "        \n",
    "        depth_img = self.to_tensor(Image.fromarray(np.array(group['depth_img'])))\n",
    "        \n",
    "        #print(\"--- depth preprocessing %s seconds ---\" % (time.time() - start_time))\n",
    "        \n",
    "        sample_pt_np = np.array(group['sample_pt']).reshape(-1, 3)\n",
    "        sample_sdf_np = np.array(group['sample_sdf']).reshape(-1, 1)\n",
    "        \n",
    "        # check size correctness and fix incorrect data\n",
    "        if sample_pt_np.shape[0] != 2048:\n",
    "            sample_pt_np = np.pad(sample_pt_np, ((0, 2048 - sample_pt_np.shape[0]), (0, 0)), 'reflect')\n",
    "        if sample_sdf_np.shape[0] != 2048:\n",
    "            sample_sdf_np = np.pad(sample_sdf_np, ((0, 2048 - sample_sdf_np.shape[0]), (0, 0)), 'reflect')\n",
    "            \n",
    "        \n",
    "        sample_pt = torch.from_numpy(sample_pt_np).float()\n",
    "        sample_sdf = torch.from_numpy(sample_sdf_np).float()\n",
    "        # scale sdf\n",
    "        sample_sdf = torch.sign(sample_sdf)*torch.pow(torch.abs(sample_sdf), 0.25)\n",
    "        \n",
    "        #print(\"--- subsampling %s seconds ---\" % (time.time() - start_time))\n",
    "        \n",
    "        target_vox = torch.from_numpy(np.array(group['target_vox'])).float()\n",
    "        \n",
    "        sample = { 'depth_img': depth_img,\n",
    "                   'sample_pt':sample_pt,\n",
    "                   'sample_sdf':sample_sdf,\n",
    "                   'target_vox':target_vox,\n",
    "                  }\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "uuid": "2f44af65-5139-4d46-ac93-2f620eaceb79"
   },
   "outputs": [],
   "source": [
    "train_sdf_dataset = ChairSDFDataset(data_file)\n",
    "\n",
    "train_sdf_dataloader = DataLoader(train_sdf_dataset, batch_size=batch_size, shuffle=True, num_workers=num_of_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2634"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sdf_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "latent_dim = 256\n",
    "\n",
    "from models import Discrete_encoder, Mapping, Discrete_decoder, Conditional_UNET\n",
    "\n",
    "####################\n",
    "# Discrete Encoder #\n",
    "####################\n",
    "\n",
    "discrete_encoder = Discrete_encoder(256).to(device)\n",
    "discrete_encoder.load_state_dict(torch.load(discrete_encoder_path))\n",
    "discrete_encoder.eval()\n",
    "\n",
    "for child in discrete_encoder.children():\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "####################\n",
    "# Mapping #\n",
    "####################\n",
    "\n",
    "mapping = Mapping().to(device)\n",
    "mapping.load_state_dict(torch.load(mapping_path))\n",
    "mapping.eval()\n",
    "\n",
    "for child in mapping.children():\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "# ####################\n",
    "# # Discrete Decoder #\n",
    "# ####################\n",
    "        \n",
    "discrete_decoder = Discrete_decoder(256).to(device)\n",
    "discrete_decoder.load_state_dict(torch.load(discrete_decoder_path))\n",
    "discrete_decoder.eval()\n",
    "\n",
    "for child in discrete_decoder.children():\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "########\n",
    "# UNET #\n",
    "########\n",
    "\n",
    "# pre-trained model is loaded within the model\n",
    "unet = Conditional_UNET(unet_path).to(device)\n",
    "unet.eval()\n",
    "\n",
    "for child in unet.children():\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleNect1D(nn.Module):\n",
    "    def __init__(self, input_dim, expand = 5):\n",
    "        super(BottleNect1D, self).__init__()\n",
    "        \n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(input_dim, expand*input_dim),\n",
    "            nn.BatchNorm1d(expand*input_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(expand*input_dim, input_dim),\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class Continuous(nn.Module):\n",
    "    def __init__(self, pt_dim = 3, con_dim = 32, latent_dim = 256):\n",
    "        super(Continuous, self).__init__()\n",
    "        \n",
    "        self.de_pt =  nn.Sequential(\n",
    "            nn.Linear(pt_dim + con_dim + latent_dim, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            BottleNect1D(latent_dim),\n",
    "        )\n",
    "        \n",
    "        self.de_1 = nn.Sequential(\n",
    "            nn.Linear(latent_dim, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            BottleNect1D(latent_dim),\n",
    "        )\n",
    "        \n",
    "        self.de_2 = nn.Sequential(\n",
    "            nn.Linear(latent_dim, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            BottleNect1D(latent_dim),\n",
    "            nn.Linear(latent_dim, 1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, pt, con, z):\n",
    "        \n",
    "        fea = self.de_pt(torch.cat((torch.cat((pt, con), 1), z), 1))\n",
    "        out = self.de_1(fea) + fea\n",
    "        out = self.de_2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "continuous = Continuous().to(device)\n",
    "continuous.load_state_dict(torch.load(continuous_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 256]          74,752\n",
      "       BatchNorm1d-2                  [-1, 256]             512\n",
      "            Linear-3                 [-1, 1280]         328,960\n",
      "       BatchNorm1d-4                 [-1, 1280]           2,560\n",
      "              ReLU-5                 [-1, 1280]               0\n",
      "            Linear-6                  [-1, 256]         327,936\n",
      "       BatchNorm1d-7                  [-1, 256]             512\n",
      "      BottleNect1D-8                  [-1, 256]               0\n",
      "            Linear-9                  [-1, 256]          65,792\n",
      "      BatchNorm1d-10                  [-1, 256]             512\n",
      "           Linear-11                 [-1, 1280]         328,960\n",
      "      BatchNorm1d-12                 [-1, 1280]           2,560\n",
      "             ReLU-13                 [-1, 1280]               0\n",
      "           Linear-14                  [-1, 256]         327,936\n",
      "      BatchNorm1d-15                  [-1, 256]             512\n",
      "     BottleNect1D-16                  [-1, 256]               0\n",
      "           Linear-17                  [-1, 256]          65,792\n",
      "      BatchNorm1d-18                  [-1, 256]             512\n",
      "           Linear-19                 [-1, 1280]         328,960\n",
      "      BatchNorm1d-20                 [-1, 1280]           2,560\n",
      "             ReLU-21                 [-1, 1280]               0\n",
      "           Linear-22                  [-1, 256]         327,936\n",
      "      BatchNorm1d-23                  [-1, 256]             512\n",
      "     BottleNect1D-24                  [-1, 256]               0\n",
      "           Linear-25                    [-1, 1]             257\n",
      "             Tanh-26                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 2,188,033\n",
      "Trainable params: 2,188,033\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 0.12\n",
      "Params size (MB): 8.35\n",
      "Estimated Total Size (MB): 8.56\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(continuous, [(3, ), (32, ), (256, )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1loss = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "uuid": "66f2e463-b1d4-4d52-bd69-503dee235960"
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "\n",
    "model = continuous\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state):\n",
    "    torch.save(state, 'continuous_model_checkpoint.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load('continuous_model_checkpoint.pth.tar')\n",
    "start_epoch = checkpoint['epoch']\n",
    "model.load_state_dict(checkpoint['continuous_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# advanced indexing 2x2x2 context from voxel\n",
    "def getContext(sample_pt_query, vox):\n",
    "    \n",
    "    # sample_pt bxmx3\n",
    "    # vox bxcxdimxdimxdim\n",
    "    \n",
    "    channel_size = vox.shape[1]\n",
    "    batch_size, sample_size, _ = sample_pt_query.shape\n",
    "    meshgrid_base = torch.Tensor(np.meshgrid(np.arange(0, batch_size), np.arange(0, channel_size), np.arange(0, 2), np.arange(0, 2), np.arange(0, 2))).int()\n",
    "    context = torch.empty((batch_size, sample_size, channel_size, 2, 2, 2))\n",
    "    \n",
    "    for j in range(context.shape[1]):\n",
    "        context[:, j, :, :, :, :] = vox[\n",
    "                    meshgrid_base[0].long(),\n",
    "                    meshgrid_base[1].long(),\n",
    "                    (meshgrid_base[2] + sample_pt_query[:, j, 0].reshape(1, -1, 1, 1, 1)).long(), \n",
    "                    (meshgrid_base[3] + sample_pt_query[:, j, 1].reshape(1, -1, 1, 1, 1)).long(), \n",
    "                    (meshgrid_base[4] + sample_pt_query[:, j, 2].reshape(1, -1, 1, 1, 1)).long()\n",
    "                ].transpose(0, 1)\n",
    "    \n",
    "    # b x c x m x 2 x 2 x 2\n",
    "    return context.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trilinearInterpolation(context, dx, dy, dz):\n",
    "    \n",
    "    v0 = context[:, :, :, 0, 0, 0]*(1-dx)*(1-dy)*(1-dz)\n",
    "    v1 = context[:, :, :, 1, 0, 0]*dx*(1-dy)*(1-dz)\n",
    "    v2 = context[:, :, :, 0, 1, 0]*(1-dx)*dy*(1-dz)\n",
    "    v3 = context[:, :, :, 1, 1, 0]*dx*dy*(1-dz)\n",
    "    v4 = context[:, :, :, 0, 0, 1]*(1-dx)*(1-dy)*dz\n",
    "    v5 = context[:, :, :, 1, 0, 1]*dx*(1-dy)*dz\n",
    "    v6 = context[:, :, :, 0, 1, 1]*(1-dx)*dy*dz\n",
    "    v7 = context[:, :, :, 1, 1, 1]*dx*dy*dz\n",
    "    \n",
    "    # b x c x m 1\n",
    "    return v0 + v1 + v2 + v3 + v4 + v5 + v6 + v7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "Epoch:  0\n",
      "Batch:  10 , l1 Loss:  0.6356682235544379 , Time: 12.870596170425415 s\n",
      "Batch:  20 , l1 Loss:  0.26166956722736356 , Time: 24.250309228897095 s\n",
      "Batch:  30 , l1 Loss:  0.14672429114580154 , Time: 35.689682960510254 s\n",
      "Batch:  40 , l1 Loss:  0.12958474606275558 , Time: 47.236165285110474 s\n",
      "Batch:  50 , l1 Loss:  0.12115571945905686 , Time: 58.75198841094971 s\n",
      "Batch:  60 , l1 Loss:  0.1182081013917923 , Time: 70.26559329032898 s\n",
      "Batch:  70 , l1 Loss:  0.11695915758609772 , Time: 81.7999517917633 s\n",
      "Batch:  80 , l1 Loss:  0.11439906805753708 , Time: 93.38381791114807 s\n",
      "Batch:  90 , l1 Loss:  0.11247901022434234 , Time: 104.96345615386963 s\n",
      "Batch:  100 , l1 Loss:  0.11350428611040116 , Time: 116.56965374946594 s\n",
      "Batch:  110 , l1 Loss:  0.11099378541111946 , Time: 128.1645200252533 s\n",
      "Batch:  120 , l1 Loss:  0.11063363701105118 , Time: 139.77182364463806 s\n",
      "Batch:  130 , l1 Loss:  0.11276050209999085 , Time: 151.28039693832397 s\n",
      "Batch:  140 , l1 Loss:  0.11193796023726463 , Time: 163.04855227470398 s\n",
      "Batch:  150 , l1 Loss:  0.10861509069800376 , Time: 174.54571104049683 s\n",
      "Batch:  160 , l1 Loss:  0.10915689319372177 , Time: 186.059663772583 s\n",
      "Batch:  170 , l1 Loss:  0.10976709574460983 , Time: 197.57981967926025 s\n",
      "Batch:  180 , l1 Loss:  0.11044461280107498 , Time: 209.10519576072693 s\n",
      "Batch:  190 , l1 Loss:  0.11057095751166343 , Time: 220.650151014328 s\n",
      "Batch:  200 , l1 Loss:  0.10705622658133507 , Time: 232.22111463546753 s\n",
      "Batch:  210 , l1 Loss:  0.10790127292275428 , Time: 243.79459047317505 s\n",
      "Batch:  220 , l1 Loss:  0.1068395160138607 , Time: 255.42415976524353 s\n",
      "Batch:  230 , l1 Loss:  0.1069942720234394 , Time: 267.1360013484955 s\n",
      "Batch:  240 , l1 Loss:  0.10604516342282296 , Time: 278.87311124801636 s\n",
      "Batch:  250 , l1 Loss:  0.10609544441103935 , Time: 290.7579667568207 s\n",
      "Batch:  260 , l1 Loss:  0.1059676967561245 , Time: 302.64485144615173 s\n",
      "Batch:  270 , l1 Loss:  0.107124575227499 , Time: 314.55757451057434 s\n",
      "Batch:  280 , l1 Loss:  0.10626279711723327 , Time: 326.47712206840515 s\n",
      "Batch:  290 , l1 Loss:  0.10795222893357277 , Time: 338.2759609222412 s\n",
      "Batch:  300 , l1 Loss:  0.10673055872321129 , Time: 350.0729193687439 s\n",
      "Batch:  310 , l1 Loss:  0.10589051246643066 , Time: 361.880571603775 s\n",
      "Batch:  320 , l1 Loss:  0.10562641099095345 , Time: 373.6715199947357 s\n",
      "Batch:  330 , l1 Loss:  0.10640717893838883 , Time: 385.4665322303772 s\n",
      "Batch:  340 , l1 Loss:  0.10858084186911583 , Time: 397.25937581062317 s\n",
      "Batch:  350 , l1 Loss:  0.10796745419502259 , Time: 409.1528778076172 s\n",
      "Batch:  360 , l1 Loss:  0.10714106336236 , Time: 420.94934344291687 s\n",
      "Batch:  370 , l1 Loss:  0.10714433267712593 , Time: 432.7553462982178 s\n",
      "Batch:  380 , l1 Loss:  0.1061105988919735 , Time: 444.56432247161865 s\n",
      "Batch:  390 , l1 Loss:  0.10534497573971749 , Time: 456.35811495780945 s\n",
      "Batch:  400 , l1 Loss:  0.10646792650222778 , Time: 468.1530559062958 s\n",
      "Batch:  410 , l1 Loss:  0.10577559992671012 , Time: 479.966148853302 s\n",
      "Batch:  420 , l1 Loss:  0.10611340776085854 , Time: 491.7595465183258 s\n",
      "Batch:  430 , l1 Loss:  0.1039695218205452 , Time: 503.5812871456146 s\n",
      "Batch:  440 , l1 Loss:  0.10449897348880768 , Time: 515.4026346206665 s\n",
      "Batch:  450 , l1 Loss:  0.10540226623415946 , Time: 527.2678508758545 s\n",
      "Batch:  460 , l1 Loss:  0.10616489052772522 , Time: 539.0812814235687 s\n",
      "Batch:  470 , l1 Loss:  0.10548243597149849 , Time: 550.8915629386902 s\n",
      "Batch:  480 , l1 Loss:  0.1048192948102951 , Time: 562.7026312351227 s\n",
      "Batch:  490 , l1 Loss:  0.10650620609521866 , Time: 574.5298988819122 s\n",
      "Batch:  500 , l1 Loss:  0.10634449943900108 , Time: 586.3512816429138 s\n",
      "Batch:  510 , l1 Loss:  0.10454954952001572 , Time: 598.1864790916443 s\n",
      "Batch:  520 , l1 Loss:  0.10620756223797798 , Time: 609.9927866458893 s\n",
      "Batch:  530 , l1 Loss:  0.10544112250208855 , Time: 621.8177101612091 s\n",
      "Batch:  540 , l1 Loss:  0.10508706495165825 , Time: 633.6331980228424 s\n",
      "Batch:  550 , l1 Loss:  0.10600807294249534 , Time: 645.5113980770111 s\n",
      "Batch:  560 , l1 Loss:  0.10409536063671113 , Time: 657.3239467144012 s\n",
      "Batch:  570 , l1 Loss:  0.1027294635772705 , Time: 669.1456122398376 s\n",
      "Batch:  580 , l1 Loss:  0.10419147163629532 , Time: 680.9352550506592 s\n",
      "Batch:  590 , l1 Loss:  0.10677961409091949 , Time: 692.7368743419647 s\n",
      "Batch:  600 , l1 Loss:  0.10452150106430054 , Time: 704.5467343330383 s\n",
      "Batch:  610 , l1 Loss:  0.10332593694329262 , Time: 716.3561310768127 s\n",
      "Batch:  620 , l1 Loss:  0.10342545136809349 , Time: 728.1721315383911 s\n",
      "Batch:  630 , l1 Loss:  0.10363963469862938 , Time: 739.9794008731842 s\n",
      "Batch:  640 , l1 Loss:  0.10349778980016708 , Time: 751.6535284519196 s\n",
      "Batch:  650 , l1 Loss:  0.10415739044547082 , Time: 763.4133200645447 s\n",
      "Batch:  660 , l1 Loss:  0.10396410599350929 , Time: 775.1053996086121 s\n",
      "Batch:  670 , l1 Loss:  0.10563547387719155 , Time: 786.811217546463 s\n",
      "Batch:  680 , l1 Loss:  0.10497787743806838 , Time: 798.5031073093414 s\n",
      "Batch:  690 , l1 Loss:  0.10271496623754502 , Time: 810.2040019035339 s\n",
      "Batch:  700 , l1 Loss:  0.10360069498419762 , Time: 821.9101285934448 s\n",
      "Batch:  710 , l1 Loss:  0.10215169787406922 , Time: 833.601019859314 s\n",
      "Batch:  720 , l1 Loss:  0.10372732803225518 , Time: 845.2724857330322 s\n",
      "Batch:  730 , l1 Loss:  0.10490779429674149 , Time: 856.9667928218842 s\n",
      "Batch:  740 , l1 Loss:  0.10314029529690742 , Time: 868.6571381092072 s\n",
      "Batch:  750 , l1 Loss:  0.10345110520720482 , Time: 880.3850796222687 s\n",
      "Batch:  760 , l1 Loss:  0.10502400621771812 , Time: 892.0571980476379 s\n",
      "Batch:  770 , l1 Loss:  0.10406707599759102 , Time: 903.7486338615417 s\n",
      "Batch:  780 , l1 Loss:  0.10444537103176117 , Time: 915.4349126815796 s\n",
      "Batch:  790 , l1 Loss:  0.10452366769313812 , Time: 927.0978548526764 s\n",
      "Batch:  800 , l1 Loss:  0.1051872655749321 , Time: 938.7732400894165 s\n",
      "Batch:  810 , l1 Loss:  0.10437916517257691 , Time: 950.4703097343445 s\n",
      "Batch:  820 , l1 Loss:  0.1033204510807991 , Time: 962.1728167533875 s\n",
      "Batch:  830 , l1 Loss:  0.10373248308897018 , Time: 973.8734469413757 s\n",
      "Batch:  840 , l1 Loss:  0.1034771405160427 , Time: 985.5668911933899 s\n",
      "Batch:  850 , l1 Loss:  0.10207932963967323 , Time: 997.2555642127991 s\n",
      "Batch:  860 , l1 Loss:  0.1017102837562561 , Time: 1009.013866186142 s\n",
      "Batch:  870 , l1 Loss:  0.10278828516602516 , Time: 1020.7195115089417 s\n",
      "Batch:  880 , l1 Loss:  0.10566827654838562 , Time: 1032.410406589508 s\n",
      "Batch:  890 , l1 Loss:  0.10499981194734573 , Time: 1044.1198406219482 s\n",
      "Batch:  900 , l1 Loss:  0.10316846221685409 , Time: 1055.8122997283936 s\n",
      "Batch:  910 , l1 Loss:  0.10131279677152634 , Time: 1067.5069417953491 s\n",
      "Batch:  920 , l1 Loss:  0.10181112214922905 , Time: 1079.2153751850128 s\n",
      "Batch:  930 , l1 Loss:  0.10328774973750114 , Time: 1090.9260663986206 s\n",
      "Batch:  940 , l1 Loss:  0.10208048969507218 , Time: 1102.628253698349 s\n",
      "Batch:  950 , l1 Loss:  0.10225476324558258 , Time: 1114.270370721817 s\n",
      "Batch:  960 , l1 Loss:  0.10272022262215615 , Time: 1126.100459098816 s\n",
      "Batch:  970 , l1 Loss:  0.10254314914345741 , Time: 1137.9364559650421 s\n",
      "Batch:  980 , l1 Loss:  0.10343704149127006 , Time: 1149.67702460289 s\n",
      "Batch:  990 , l1 Loss:  0.1028578519821167 , Time: 1161.30149269104 s\n",
      "Batch:  1000 , l1 Loss:  0.10249600037932396 , Time: 1172.9211144447327 s\n",
      "Batch:  1010 , l1 Loss:  0.10334303304553032 , Time: 1184.551894903183 s\n",
      "Batch:  1020 , l1 Loss:  0.10330692231655121 , Time: 1196.1834671497345 s\n",
      "Batch:  1030 , l1 Loss:  0.10285992026329041 , Time: 1207.8142085075378 s\n",
      "Batch:  1040 , l1 Loss:  0.10346993803977966 , Time: 1219.4649875164032 s\n",
      "Batch:  1050 , l1 Loss:  0.10406888499855996 , Time: 1231.1038610935211 s\n",
      "Batch:  1060 , l1 Loss:  0.1052904836833477 , Time: 1242.81294131279 s\n",
      "Batch:  1070 , l1 Loss:  0.10150265991687775 , Time: 1254.502947807312 s\n",
      "Batch:  1080 , l1 Loss:  0.10370857641100883 , Time: 1266.1782793998718 s\n",
      "Batch:  1090 , l1 Loss:  0.10225329026579857 , Time: 1277.88645529747 s\n",
      "Batch:  1100 , l1 Loss:  0.10302511006593704 , Time: 1289.5664265155792 s\n",
      "Batch:  1110 , l1 Loss:  0.10218277722597122 , Time: 1301.2440898418427 s\n",
      "Batch:  1120 , l1 Loss:  0.10344346165657044 , Time: 1312.9103224277496 s\n",
      "Batch:  1130 , l1 Loss:  0.10246820896863937 , Time: 1324.5875244140625 s\n",
      "Batch:  1140 , l1 Loss:  0.10338577702641487 , Time: 1336.261871099472 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  1150 , l1 Loss:  0.10257095545530319 , Time: 1347.9632287025452 s\n",
      "Batch:  1160 , l1 Loss:  0.10255348831415176 , Time: 1359.7036740779877 s\n",
      "Batch:  1170 , l1 Loss:  0.10365713611245156 , Time: 1371.412005186081 s\n",
      "Batch:  1180 , l1 Loss:  0.10360780507326126 , Time: 1383.0767753124237 s\n",
      "Batch:  1190 , l1 Loss:  0.10288463160395622 , Time: 1394.755003452301 s\n",
      "Batch:  1200 , l1 Loss:  0.1023711919784546 , Time: 1406.4381167888641 s\n",
      "Batch:  1210 , l1 Loss:  0.10126769915223122 , Time: 1418.1188027858734 s\n",
      "Batch:  1220 , l1 Loss:  0.10211240127682686 , Time: 1429.8157942295074 s\n",
      "Batch:  1230 , l1 Loss:  0.1044051043689251 , Time: 1441.5042808055878 s\n",
      "Batch:  1240 , l1 Loss:  0.10284226909279823 , Time: 1453.1773653030396 s\n",
      "Batch:  1250 , l1 Loss:  0.1030073568224907 , Time: 1464.8562614917755 s\n",
      "Batch:  1260 , l1 Loss:  0.10184578374028205 , Time: 1476.5433089733124 s\n",
      "Batch:  1270 , l1 Loss:  0.10219207108020782 , Time: 1488.2690043449402 s\n",
      "Batch:  1280 , l1 Loss:  0.10129925459623337 , Time: 1499.9600145816803 s\n",
      "Batch:  1290 , l1 Loss:  0.10162735357880592 , Time: 1511.6428897380829 s\n",
      "Batch:  1300 , l1 Loss:  0.10230489671230317 , Time: 1523.3195447921753 s\n",
      "Batch:  1310 , l1 Loss:  0.10275044962763787 , Time: 1534.99635887146 s\n",
      "Batch:  1320 , l1 Loss:  0.10313331261277199 , Time: 1546.6845638751984 s\n",
      "Batch:  1330 , l1 Loss:  0.10402705892920494 , Time: 1558.4179947376251 s\n",
      "Batch:  1340 , l1 Loss:  0.10386597886681556 , Time: 1570.086862564087 s\n",
      "Batch:  1350 , l1 Loss:  0.10281983464956283 , Time: 1581.753473997116 s\n",
      "Batch:  1360 , l1 Loss:  0.10258769392967224 , Time: 1593.4154014587402 s\n",
      "Batch:  1370 , l1 Loss:  0.10428026765584945 , Time: 1605.1470701694489 s\n",
      "Batch:  1380 , l1 Loss:  0.10211160033941269 , Time: 1616.8059961795807 s\n",
      "Batch:  1390 , l1 Loss:  0.10287519246339798 , Time: 1628.4583849906921 s\n",
      "Batch:  1400 , l1 Loss:  0.10183324217796326 , Time: 1640.382073879242 s\n",
      "Batch:  1410 , l1 Loss:  0.10275390595197678 , Time: 1652.3506262302399 s\n",
      "Batch:  1420 , l1 Loss:  0.10156987458467484 , Time: 1664.291469335556 s\n",
      "Batch:  1430 , l1 Loss:  0.10238910913467407 , Time: 1676.239547252655 s\n",
      "Batch:  1440 , l1 Loss:  0.10218072533607483 , Time: 1688.1669435501099 s\n",
      "Batch:  1450 , l1 Loss:  0.10102517530322075 , Time: 1700.0750648975372 s\n",
      "Batch:  1460 , l1 Loss:  0.10130084902048112 , Time: 1711.9845309257507 s\n",
      "Batch:  1470 , l1 Loss:  0.1007569007575512 , Time: 1723.9373052120209 s\n",
      "Batch:  1480 , l1 Loss:  0.10246905833482742 , Time: 1735.8470675945282 s\n",
      "Batch:  1490 , l1 Loss:  0.10147181749343873 , Time: 1747.7462763786316 s\n",
      "Batch:  1500 , l1 Loss:  0.10147501453757286 , Time: 1759.649248123169 s\n",
      "Batch:  1510 , l1 Loss:  0.10106771886348724 , Time: 1771.238965511322 s\n",
      "Batch:  1520 , l1 Loss:  0.10261770710349083 , Time: 1782.809621334076 s\n",
      "Batch:  1530 , l1 Loss:  0.10205958411097527 , Time: 1794.3880686759949 s\n",
      "Batch:  1540 , l1 Loss:  0.10474971383810043 , Time: 1805.9806187152863 s\n",
      "Batch:  1550 , l1 Loss:  0.10203978046774864 , Time: 1817.5865995883942 s\n",
      "Batch:  1560 , l1 Loss:  0.10081121176481248 , Time: 1829.200091123581 s\n",
      "Batch:  1570 , l1 Loss:  0.10406575947999955 , Time: 1840.8716261386871 s\n",
      "Batch:  1580 , l1 Loss:  0.10359113588929177 , Time: 1852.5072660446167 s\n",
      "Batch:  1590 , l1 Loss:  0.10276741087436676 , Time: 1864.1222350597382 s\n",
      "Batch:  1600 , l1 Loss:  0.1010324127972126 , Time: 1875.7500758171082 s\n",
      "Batch:  1610 , l1 Loss:  0.1026012048125267 , Time: 1887.3856363296509 s\n",
      "Batch:  1620 , l1 Loss:  0.10164429396390914 , Time: 1899.0205471515656 s\n",
      "Batch:  1630 , l1 Loss:  0.10180573761463166 , Time: 1910.6582124233246 s\n",
      "Batch:  1640 , l1 Loss:  0.10230717957019805 , Time: 1922.2852790355682 s\n",
      "Batch:  1650 , l1 Loss:  0.10056792423129082 , Time: 1933.9084429740906 s\n",
      "Batch:  1660 , l1 Loss:  0.10336773321032525 , Time: 1945.5731949806213 s\n",
      "Batch:  1670 , l1 Loss:  0.10119659975171089 , Time: 1957.1642806529999 s\n",
      "Batch:  1680 , l1 Loss:  0.10359450206160545 , Time: 1968.833398103714 s\n",
      "Batch:  1690 , l1 Loss:  0.1009417563676834 , Time: 1980.4270493984222 s\n",
      "Batch:  1700 , l1 Loss:  0.10196043401956559 , Time: 1992.0437605381012 s\n",
      "Batch:  1710 , l1 Loss:  0.10258875787258148 , Time: 2003.6718399524689 s\n",
      "Batch:  1720 , l1 Loss:  0.10358302444219589 , Time: 2015.3021154403687 s\n",
      "Batch:  1730 , l1 Loss:  0.10297543928027153 , Time: 2026.9283056259155 s\n",
      "Batch:  1740 , l1 Loss:  0.10142172798514366 , Time: 2038.569839477539 s\n",
      "Batch:  1750 , l1 Loss:  0.1015342578291893 , Time: 2050.2142798900604 s\n",
      "Batch:  1760 , l1 Loss:  0.10210642144083977 , Time: 2061.8488035202026 s\n",
      "Batch:  1770 , l1 Loss:  0.10151239708065987 , Time: 2073.4924116134644 s\n",
      "Batch:  1780 , l1 Loss:  0.10156877264380455 , Time: 2085.191024541855 s\n",
      "Batch:  1790 , l1 Loss:  0.10140696987509727 , Time: 2096.8430573940277 s\n",
      "Batch:  1800 , l1 Loss:  0.10308939144015312 , Time: 2108.471706867218 s\n",
      "Batch:  1810 , l1 Loss:  0.10218025296926499 , Time: 2120.1049122810364 s\n",
      "Batch:  1820 , l1 Loss:  0.10222491845488549 , Time: 2131.739275932312 s\n",
      "Batch:  1830 , l1 Loss:  0.1024696871638298 , Time: 2143.3791105747223 s\n",
      "Batch:  1840 , l1 Loss:  0.10142536386847496 , Time: 2155.020344734192 s\n",
      "Batch:  1850 , l1 Loss:  0.10202040672302246 , Time: 2166.651796579361 s\n",
      "Batch:  1860 , l1 Loss:  0.10070013478398324 , Time: 2178.296668291092 s\n",
      "Batch:  1870 , l1 Loss:  0.1008502721786499 , Time: 2189.9344096183777 s\n",
      "Batch:  1880 , l1 Loss:  0.10072686448693276 , Time: 2201.647826194763 s\n",
      "Batch:  1890 , l1 Loss:  0.1018594428896904 , Time: 2213.2937245368958 s\n",
      "Batch:  1900 , l1 Loss:  0.1013762578368187 , Time: 2224.9547119140625 s\n",
      "Batch:  1910 , l1 Loss:  0.10175555273890495 , Time: 2236.6174688339233 s\n",
      "Batch:  1920 , l1 Loss:  0.10240208506584167 , Time: 2248.263935804367 s\n",
      "Batch:  1930 , l1 Loss:  0.10238949581980705 , Time: 2259.9123027324677 s\n",
      "Batch:  1940 , l1 Loss:  0.10270747244358062 , Time: 2271.569367170334 s\n",
      "Batch:  1950 , l1 Loss:  0.10261582210659981 , Time: 2283.242943763733 s\n",
      "Batch:  1960 , l1 Loss:  0.1018759436905384 , Time: 2294.893614768982 s\n",
      "Batch:  1970 , l1 Loss:  0.10040217265486717 , Time: 2306.558153152466 s\n",
      "Batch:  1980 , l1 Loss:  0.1024350456893444 , Time: 2318.233847618103 s\n",
      "Batch:  1990 , l1 Loss:  0.10252539440989494 , Time: 2329.92351102829 s\n",
      "Batch:  2000 , l1 Loss:  0.10191695019602776 , Time: 2341.5811202526093 s\n",
      "Batch:  2010 , l1 Loss:  0.10175151899456977 , Time: 2353.245296239853 s\n",
      "Batch:  2020 , l1 Loss:  0.10191965252161025 , Time: 2364.9660906791687 s\n",
      "Batch:  2030 , l1 Loss:  0.10017936304211617 , Time: 2376.6855552196503 s\n",
      "Batch:  2040 , l1 Loss:  0.10282649770379067 , Time: 2388.3933005332947 s\n",
      "Batch:  2050 , l1 Loss:  0.1012264147400856 , Time: 2400.1240572929382 s\n",
      "Batch:  2060 , l1 Loss:  0.1008016049861908 , Time: 2411.835560798645 s\n",
      "Batch:  2070 , l1 Loss:  0.10073867663741112 , Time: 2423.5351848602295 s\n",
      "Batch:  2080 , l1 Loss:  0.10185753107070923 , Time: 2435.2409632205963 s\n",
      "Batch:  2090 , l1 Loss:  0.10140392929315567 , Time: 2446.9867808818817 s\n",
      "Batch:  2100 , l1 Loss:  0.10109057426452636 , Time: 2458.690201282501 s\n",
      "Batch:  2110 , l1 Loss:  0.10138016194105148 , Time: 2470.407546520233 s\n",
      "Batch:  2120 , l1 Loss:  0.10036258473992347 , Time: 2482.0821692943573 s\n",
      "Batch:  2130 , l1 Loss:  0.10148950591683388 , Time: 2493.7786769866943 s\n",
      "Batch:  2140 , l1 Loss:  0.1014990083873272 , Time: 2505.5016696453094 s\n",
      "Batch:  2150 , l1 Loss:  0.10282568484544755 , Time: 2517.235871553421 s\n",
      "Batch:  2160 , l1 Loss:  0.10283474922180176 , Time: 2528.890251159668 s\n",
      "Batch:  2170 , l1 Loss:  0.10067767277359962 , Time: 2540.5721640586853 s\n",
      "Batch:  2180 , l1 Loss:  0.10302142724394799 , Time: 2552.604027748108 s\n",
      "Batch:  2190 , l1 Loss:  0.10343117415904998 , Time: 2564.474686384201 s\n",
      "Batch:  2200 , l1 Loss:  0.10165142565965653 , Time: 2576.0520634651184 s\n",
      "Batch:  2210 , l1 Loss:  0.10038758143782615 , Time: 2587.6954262256622 s\n",
      "Batch:  2220 , l1 Loss:  0.10163115859031677 , Time: 2599.3488676548004 s\n",
      "Batch:  2230 , l1 Loss:  0.10115654096007347 , Time: 2610.9885931015015 s\n",
      "Batch:  2240 , l1 Loss:  0.09975195154547692 , Time: 2622.6346933841705 s\n",
      "Batch:  2250 , l1 Loss:  0.10114874243736267 , Time: 2634.2811262607574 s\n",
      "Batch:  2260 , l1 Loss:  0.10164224207401276 , Time: 2645.911793231964 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  2270 , l1 Loss:  0.10122964456677437 , Time: 2657.5434470176697 s\n",
      "Batch:  2280 , l1 Loss:  0.101145289093256 , Time: 2669.196286916733 s\n",
      "Batch:  2290 , l1 Loss:  0.10093993917107583 , Time: 2680.892108440399 s\n",
      "Batch:  2300 , l1 Loss:  0.10091946497559548 , Time: 2692.5340909957886 s\n",
      "Batch:  2310 , l1 Loss:  0.10063840821385384 , Time: 2704.1932871341705 s\n",
      "Batch:  2320 , l1 Loss:  0.10019042864441871 , Time: 2715.864919900894 s\n",
      "Batch:  2330 , l1 Loss:  0.10168906971812249 , Time: 2727.51092672348 s\n",
      "Batch:  2340 , l1 Loss:  0.10176944360136986 , Time: 2739.1514236927032 s\n",
      "Batch:  2350 , l1 Loss:  0.10123281255364418 , Time: 2750.8056411743164 s\n",
      "Batch:  2360 , l1 Loss:  0.10145051926374435 , Time: 2762.4651079177856 s\n",
      "Batch:  2370 , l1 Loss:  0.10287504866719246 , Time: 2774.173999071121 s\n",
      "Batch:  2380 , l1 Loss:  0.10318695977330208 , Time: 2785.852584838867 s\n",
      "Batch:  2390 , l1 Loss:  0.1008954480290413 , Time: 2797.538878917694 s\n",
      "Batch:  2400 , l1 Loss:  0.10261690616607666 , Time: 2809.2600231170654 s\n",
      "Batch:  2410 , l1 Loss:  0.10434854850172996 , Time: 2820.9524846076965 s\n",
      "Batch:  2420 , l1 Loss:  0.10205004140734672 , Time: 2832.6335825920105 s\n",
      "Batch:  2430 , l1 Loss:  0.10122169479727745 , Time: 2844.330888032913 s\n",
      "Batch:  2440 , l1 Loss:  0.09960094839334488 , Time: 2856.03874540329 s\n",
      "Batch:  2450 , l1 Loss:  0.09997605085372925 , Time: 2867.7429497241974 s\n",
      "Batch:  2460 , l1 Loss:  0.10087968334555626 , Time: 2879.4269127845764 s\n",
      "Batch:  2470 , l1 Loss:  0.10054801255464554 , Time: 2891.136199235916 s\n",
      "Batch:  2480 , l1 Loss:  0.10194445624947548 , Time: 2902.844762802124 s\n",
      "Batch:  2490 , l1 Loss:  0.10116316378116608 , Time: 2914.5386044979095 s\n",
      "Batch:  2500 , l1 Loss:  0.10018957108259201 , Time: 2926.304066181183 s\n",
      "Batch:  2510 , l1 Loss:  0.09925471991300583 , Time: 2938.0174357891083 s\n",
      "Batch:  2520 , l1 Loss:  0.10236844792962074 , Time: 2949.732408285141 s\n",
      "Batch:  2530 , l1 Loss:  0.10127934962511062 , Time: 2961.452131986618 s\n",
      "Batch:  2540 , l1 Loss:  0.10006409585475921 , Time: 2973.1737716197968 s\n",
      "Batch:  2550 , l1 Loss:  0.10105958729982376 , Time: 2984.9053144454956 s\n",
      "Batch:  2560 , l1 Loss:  0.10023724734783172 , Time: 2996.607993364334 s\n",
      "Batch:  2570 , l1 Loss:  0.10121954679489135 , Time: 3008.320923805237 s\n",
      "Batch:  2580 , l1 Loss:  0.10109085366129875 , Time: 3020.0327026844025 s\n",
      "Batch:  2590 , l1 Loss:  0.10183593928813935 , Time: 3031.7549035549164 s\n",
      "Batch:  2600 , l1 Loss:  0.10115025416016579 , Time: 3043.5353767871857 s\n",
      "Batch:  2610 , l1 Loss:  0.10157717615365983 , Time: 3055.2504227161407 s\n",
      "Batch:  2620 , l1 Loss:  0.10349428802728652 , Time: 3066.9576246738434 s\n",
      "Batch:  2630 , l1 Loss:  0.1022924803197384 , Time: 3078.6870670318604 s\n",
      "Epoch:  0 , l1 loss:  0.1065662141235923\n",
      "Epoch:  1\n",
      "Batch:  10 , l1 Loss:  0.10183930600231345 , Time: 3095.871747493744 s\n",
      "Batch:  20 , l1 Loss:  0.10192312896251679 , Time: 3107.807686328888 s\n",
      "Batch:  30 , l1 Loss:  0.10194696336984635 , Time: 3119.6928865909576 s\n",
      "Batch:  40 , l1 Loss:  0.10118772312998772 , Time: 3131.6220536231995 s\n",
      "Batch:  50 , l1 Loss:  0.100919009745121 , Time: 3143.596123933792 s\n",
      "Batch:  60 , l1 Loss:  0.10062802433967591 , Time: 3155.5409739017487 s\n",
      "Batch:  70 , l1 Loss:  0.10110594555735589 , Time: 3167.459914445877 s\n",
      "Batch:  80 , l1 Loss:  0.1006799079477787 , Time: 3179.401064157486 s\n",
      "Batch:  90 , l1 Loss:  0.10069904252886772 , Time: 3191.292103290558 s\n",
      "Batch:  100 , l1 Loss:  0.10051582381129265 , Time: 3203.177896976471 s\n",
      "Batch:  110 , l1 Loss:  0.10018779411911964 , Time: 3215.108788251877 s\n",
      "Batch:  120 , l1 Loss:  0.10092879384756089 , Time: 3227.036762237549 s\n",
      "Batch:  130 , l1 Loss:  0.10083125904202461 , Time: 3238.931361913681 s\n",
      "Batch:  140 , l1 Loss:  0.1015953280031681 , Time: 3250.848741531372 s\n",
      "Batch:  150 , l1 Loss:  0.10062054917216301 , Time: 3262.766905784607 s\n",
      "Batch:  160 , l1 Loss:  0.09939979463815689 , Time: 3274.6779923439026 s\n",
      "Batch:  170 , l1 Loss:  0.10054887905716896 , Time: 3286.5980110168457 s\n",
      "Batch:  180 , l1 Loss:  0.1023118518292904 , Time: 3298.5294308662415 s\n",
      "Batch:  190 , l1 Loss:  0.10196757465600967 , Time: 3310.4775359630585 s\n",
      "Batch:  200 , l1 Loss:  0.10010920614004135 , Time: 3322.405465364456 s\n",
      "Batch:  210 , l1 Loss:  0.1015927255153656 , Time: 3334.3069944381714 s\n",
      "Batch:  220 , l1 Loss:  0.10021889805793763 , Time: 3346.2171766757965 s\n",
      "Batch:  230 , l1 Loss:  0.10022924914956093 , Time: 3358.130788564682 s\n",
      "Batch:  240 , l1 Loss:  0.10126693546772003 , Time: 3370.0952904224396 s\n",
      "Batch:  250 , l1 Loss:  0.10140379816293717 , Time: 3381.985902070999 s\n",
      "Batch:  260 , l1 Loss:  0.10086774006485939 , Time: 3393.8871207237244 s\n",
      "Batch:  270 , l1 Loss:  0.10031628236174583 , Time: 3405.8490993976593 s\n",
      "Batch:  280 , l1 Loss:  0.10056360363960266 , Time: 3417.7514791488647 s\n",
      "Batch:  290 , l1 Loss:  0.10203968808054924 , Time: 3429.641569852829 s\n",
      "Batch:  300 , l1 Loss:  0.10087337717413902 , Time: 3441.556740999222 s\n",
      "Batch:  310 , l1 Loss:  0.10048674270510674 , Time: 3453.480392217636 s\n",
      "Batch:  320 , l1 Loss:  0.10208486542105674 , Time: 3465.391617298126 s\n",
      "Batch:  330 , l1 Loss:  0.10190486684441566 , Time: 3477.2755982875824 s\n",
      "Batch:  340 , l1 Loss:  0.10166472792625428 , Time: 3489.152386188507 s\n",
      "Batch:  350 , l1 Loss:  0.10110381320118904 , Time: 3501.092002391815 s\n",
      "Batch:  360 , l1 Loss:  0.10136639401316642 , Time: 3512.9920501708984 s\n",
      "Batch:  370 , l1 Loss:  0.10077451765537263 , Time: 3524.9868927001953 s\n",
      "Batch:  380 , l1 Loss:  0.10169718861579895 , Time: 3536.9294686317444 s\n",
      "Batch:  390 , l1 Loss:  0.10016045793890953 , Time: 3548.87296462059 s\n",
      "Batch:  400 , l1 Loss:  0.10115907788276672 , Time: 3560.7331845760345 s\n",
      "Batch:  410 , l1 Loss:  0.10191775113344193 , Time: 3572.54163646698 s\n",
      "Batch:  420 , l1 Loss:  0.10033715069293976 , Time: 3584.417201757431 s\n",
      "Batch:  430 , l1 Loss:  0.10066041126847267 , Time: 3596.5876524448395 s\n",
      "Batch:  440 , l1 Loss:  0.10111422017216683 , Time: 3608.729932308197 s\n",
      "Batch:  450 , l1 Loss:  0.09988432601094246 , Time: 3620.900041103363 s\n",
      "Batch:  460 , l1 Loss:  0.10132121667265892 , Time: 3633.079891681671 s\n",
      "Batch:  470 , l1 Loss:  0.09912535026669503 , Time: 3645.2873594760895 s\n",
      "Batch:  480 , l1 Loss:  0.10061863139271736 , Time: 3657.509527683258 s\n",
      "Batch:  490 , l1 Loss:  0.1029645748436451 , Time: 3669.636493206024 s\n",
      "Batch:  500 , l1 Loss:  0.10407541915774346 , Time: 3681.6316618919373 s\n",
      "Batch:  510 , l1 Loss:  0.10099531933665276 , Time: 3693.6075344085693 s\n",
      "Batch:  520 , l1 Loss:  0.10293002128601074 , Time: 3705.6461346149445 s\n",
      "Batch:  530 , l1 Loss:  0.10160724744200707 , Time: 3717.5548555850983 s\n",
      "Batch:  540 , l1 Loss:  0.10252844467759133 , Time: 3729.4893774986267 s\n",
      "Batch:  550 , l1 Loss:  0.1012167364358902 , Time: 3741.44282913208 s\n",
      "Batch:  560 , l1 Loss:  0.10210310891270638 , Time: 3753.7827990055084 s\n",
      "Batch:  570 , l1 Loss:  0.10055286213755607 , Time: 3766.0286886692047 s\n",
      "Batch:  580 , l1 Loss:  0.10106819719076157 , Time: 3778.3218080997467 s\n",
      "Batch:  590 , l1 Loss:  0.0994039461016655 , Time: 3790.551826238632 s\n",
      "Batch:  600 , l1 Loss:  0.10060408562421799 , Time: 3802.761983394623 s\n",
      "Batch:  610 , l1 Loss:  0.10070848166942596 , Time: 3815.0587706565857 s\n",
      "Batch:  620 , l1 Loss:  0.10018012076616287 , Time: 3827.234840631485 s\n",
      "Batch:  630 , l1 Loss:  0.10094058215618133 , Time: 3839.4666752815247 s\n",
      "Batch:  640 , l1 Loss:  0.09995743557810784 , Time: 3851.772875547409 s\n",
      "Batch:  650 , l1 Loss:  0.10079002827405929 , Time: 3863.949917793274 s\n",
      "Batch:  660 , l1 Loss:  0.1012911319732666 , Time: 3876.227611064911 s\n",
      "Batch:  670 , l1 Loss:  0.10112979412078857 , Time: 3888.5236971378326 s\n",
      "Batch:  680 , l1 Loss:  0.10128150433301926 , Time: 3900.769130706787 s\n",
      "Batch:  690 , l1 Loss:  0.10222586989402771 , Time: 3912.9514956474304 s\n",
      "Batch:  700 , l1 Loss:  0.10166099593043328 , Time: 3925.1930692195892 s\n",
      "Batch:  710 , l1 Loss:  0.09988611489534378 , Time: 3937.443136692047 s\n",
      "Batch:  720 , l1 Loss:  0.10140112787485123 , Time: 3949.68386387825 s\n",
      "Batch:  730 , l1 Loss:  0.10075670778751374 , Time: 3961.8935203552246 s\n",
      "Batch:  740 , l1 Loss:  0.101511599868536 , Time: 3974.0580077171326 s\n",
      "Batch:  750 , l1 Loss:  0.10181279331445695 , Time: 3986.36904501915 s\n",
      "Batch:  760 , l1 Loss:  0.1001621812582016 , Time: 3998.5863349437714 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  770 , l1 Loss:  0.09956611394882202 , Time: 4010.910325527191 s\n",
      "Batch:  780 , l1 Loss:  0.09986158534884453 , Time: 4023.1513047218323 s\n",
      "Batch:  790 , l1 Loss:  0.10026874542236328 , Time: 4035.336446046829 s\n",
      "Batch:  800 , l1 Loss:  0.10093663781881332 , Time: 4047.5101838111877 s\n",
      "Batch:  810 , l1 Loss:  0.10096770823001862 , Time: 4059.648444414139 s\n",
      "Batch:  820 , l1 Loss:  0.09967626556754113 , Time: 4071.841958761215 s\n",
      "Batch:  830 , l1 Loss:  0.09932728260755538 , Time: 4083.9532120227814 s\n",
      "Batch:  840 , l1 Loss:  0.09944009184837341 , Time: 4095.9055304527283 s\n",
      "Batch:  850 , l1 Loss:  0.10089885145425796 , Time: 4107.824432134628 s\n",
      "Batch:  860 , l1 Loss:  0.10061604753136635 , Time: 4119.724838256836 s\n",
      "Batch:  870 , l1 Loss:  0.10002379789948464 , Time: 4131.540773391724 s\n",
      "Batch:  880 , l1 Loss:  0.10108595341444016 , Time: 4143.474110841751 s\n",
      "Batch:  890 , l1 Loss:  0.09997587725520134 , Time: 4155.40248966217 s\n",
      "Batch:  900 , l1 Loss:  0.10156461521983147 , Time: 4167.330453634262 s\n",
      "Batch:  910 , l1 Loss:  0.10015681311488152 , Time: 4179.16686797142 s\n",
      "Batch:  920 , l1 Loss:  0.10159038230776787 , Time: 4191.471301078796 s\n",
      "Batch:  930 , l1 Loss:  0.1006177768111229 , Time: 4203.697250127792 s\n",
      "Batch:  940 , l1 Loss:  0.10040356889367104 , Time: 4215.918771028519 s\n",
      "Batch:  950 , l1 Loss:  0.10214351490139961 , Time: 4228.138124704361 s\n",
      "Batch:  960 , l1 Loss:  0.1012640930712223 , Time: 4240.317732095718 s\n",
      "Batch:  970 , l1 Loss:  0.09979137480258941 , Time: 4252.40763258934 s\n",
      "Batch:  980 , l1 Loss:  0.10095259100198746 , Time: 4264.2336440086365 s\n",
      "Batch:  990 , l1 Loss:  0.10118967667222023 , Time: 4276.198426961899 s\n",
      "Batch:  1000 , l1 Loss:  0.10072661712765693 , Time: 4288.078918933868 s\n",
      "Batch:  1010 , l1 Loss:  0.10061483010649681 , Time: 4299.93461728096 s\n",
      "Batch:  1020 , l1 Loss:  0.10117936730384827 , Time: 4311.798681259155 s\n",
      "Batch:  1030 , l1 Loss:  0.10121190324425697 , Time: 4323.678437232971 s\n",
      "Batch:  1040 , l1 Loss:  0.1003032736480236 , Time: 4335.5136132240295 s\n",
      "Batch:  1050 , l1 Loss:  0.10144872590899467 , Time: 4347.538092374802 s\n",
      "Batch:  1060 , l1 Loss:  0.1009144090116024 , Time: 4359.503617048264 s\n",
      "Batch:  1070 , l1 Loss:  0.10293784141540527 , Time: 4371.613538742065 s\n",
      "Batch:  1080 , l1 Loss:  0.10236326977610588 , Time: 4383.459632396698 s\n",
      "Batch:  1090 , l1 Loss:  0.10036918967962265 , Time: 4395.34023475647 s\n",
      "Batch:  1100 , l1 Loss:  0.10008053034543991 , Time: 4407.227869510651 s\n",
      "Batch:  1110 , l1 Loss:  0.10148234441876411 , Time: 4419.22496175766 s\n",
      "Batch:  1120 , l1 Loss:  0.10160944536328316 , Time: 4431.118281841278 s\n",
      "Batch:  1130 , l1 Loss:  0.10037496238946915 , Time: 4443.041835784912 s\n",
      "Batch:  1140 , l1 Loss:  0.10056979060173035 , Time: 4454.974016427994 s\n",
      "Batch:  1150 , l1 Loss:  0.1005534864962101 , Time: 4466.900547027588 s\n",
      "Batch:  1160 , l1 Loss:  0.0989296481013298 , Time: 4478.894902467728 s\n",
      "Batch:  1170 , l1 Loss:  0.10081825479865074 , Time: 4490.863946676254 s\n",
      "Batch:  1180 , l1 Loss:  0.10009922832250595 , Time: 4502.808085680008 s\n",
      "Batch:  1190 , l1 Loss:  0.10388992205262185 , Time: 4514.766152858734 s\n",
      "Batch:  1200 , l1 Loss:  0.10095242708921433 , Time: 4526.641293048859 s\n",
      "Batch:  1210 , l1 Loss:  0.1000183567404747 , Time: 4538.608608007431 s\n",
      "Batch:  1220 , l1 Loss:  0.10068167299032212 , Time: 4550.657033205032 s\n",
      "Batch:  1230 , l1 Loss:  0.1003200426697731 , Time: 4562.710223674774 s\n",
      "Batch:  1240 , l1 Loss:  0.100009935349226 , Time: 4574.680401802063 s\n",
      "Batch:  1250 , l1 Loss:  0.10053194761276245 , Time: 4586.692720651627 s\n",
      "Batch:  1260 , l1 Loss:  0.10074665695428849 , Time: 4598.664875745773 s\n",
      "Batch:  1270 , l1 Loss:  0.09952738955616951 , Time: 4610.657739400864 s\n",
      "Batch:  1280 , l1 Loss:  0.09969280064105987 , Time: 4622.685929298401 s\n",
      "Batch:  1290 , l1 Loss:  0.1007662907242775 , Time: 4634.722304344177 s\n",
      "Batch:  1300 , l1 Loss:  0.10125082433223724 , Time: 4646.768123865128 s\n",
      "Batch:  1310 , l1 Loss:  0.10075769573450089 , Time: 4658.756167650223 s\n",
      "Batch:  1320 , l1 Loss:  0.09950538873672485 , Time: 4670.794979095459 s\n",
      "Batch:  1330 , l1 Loss:  0.10004525631666183 , Time: 4682.753263950348 s\n",
      "Batch:  1340 , l1 Loss:  0.09915090128779411 , Time: 4694.7502908706665 s\n",
      "Batch:  1350 , l1 Loss:  0.1000410221517086 , Time: 4706.750965118408 s\n",
      "Batch:  1360 , l1 Loss:  0.10147781819105148 , Time: 4718.720769405365 s\n",
      "Batch:  1370 , l1 Loss:  0.10087850242853165 , Time: 4730.715995788574 s\n",
      "Batch:  1380 , l1 Loss:  0.09979779198765755 , Time: 4742.70624256134 s\n",
      "Batch:  1390 , l1 Loss:  0.10017274394631386 , Time: 4754.688485383987 s\n",
      "Batch:  1400 , l1 Loss:  0.10058745071291923 , Time: 4766.713513374329 s\n",
      "Batch:  1410 , l1 Loss:  0.10050642564892769 , Time: 4778.708426237106 s\n",
      "Batch:  1420 , l1 Loss:  0.10106481090188027 , Time: 4790.714878320694 s\n",
      "Batch:  1430 , l1 Loss:  0.09897085949778557 , Time: 4802.666568040848 s\n",
      "Batch:  1440 , l1 Loss:  0.0995959110558033 , Time: 4814.581058263779 s\n",
      "Batch:  1450 , l1 Loss:  0.1006308451294899 , Time: 4826.454251527786 s\n",
      "Batch:  1460 , l1 Loss:  0.09943104162812233 , Time: 4838.3887367248535 s\n",
      "Batch:  1470 , l1 Loss:  0.10031875967979431 , Time: 4850.344712972641 s\n",
      "Batch:  1480 , l1 Loss:  0.10093803182244301 , Time: 4862.247493505478 s\n",
      "Batch:  1490 , l1 Loss:  0.0998850166797638 , Time: 4874.1699187755585 s\n",
      "Batch:  1500 , l1 Loss:  0.10138303935527801 , Time: 4886.073926210403 s\n",
      "Batch:  1510 , l1 Loss:  0.1005660392343998 , Time: 4897.98778629303 s\n",
      "Batch:  1520 , l1 Loss:  0.10061201304197312 , Time: 4909.951523065567 s\n",
      "Batch:  1530 , l1 Loss:  0.1012194313108921 , Time: 4921.805926084518 s\n",
      "Batch:  1540 , l1 Loss:  0.10157753005623818 , Time: 4933.7172310352325 s\n",
      "Batch:  1550 , l1 Loss:  0.1009160377085209 , Time: 4945.687575101852 s\n",
      "Batch:  1560 , l1 Loss:  0.10032150000333787 , Time: 4957.716862440109 s\n",
      "Batch:  1570 , l1 Loss:  0.10009701773524285 , Time: 4969.789956569672 s\n",
      "Batch:  1580 , l1 Loss:  0.10180835425853729 , Time: 4981.768982172012 s\n",
      "Batch:  1590 , l1 Loss:  0.1019052430987358 , Time: 4993.736106157303 s\n",
      "Batch:  1600 , l1 Loss:  0.09991951808333396 , Time: 5005.702381134033 s\n",
      "Batch:  1610 , l1 Loss:  0.09947823658585549 , Time: 5017.677852392197 s\n",
      "Batch:  1620 , l1 Loss:  0.10026498660445213 , Time: 5029.685371875763 s\n",
      "Batch:  1630 , l1 Loss:  0.10036882162094116 , Time: 5041.680688619614 s\n",
      "Batch:  1640 , l1 Loss:  0.10137211680412292 , Time: 5053.663069725037 s\n",
      "Batch:  1650 , l1 Loss:  0.09852544292807579 , Time: 5065.600228071213 s\n",
      "Batch:  1660 , l1 Loss:  0.10073182806372642 , Time: 5077.586256027222 s\n",
      "Batch:  1670 , l1 Loss:  0.10224496647715568 , Time: 5089.619711399078 s\n",
      "Batch:  1680 , l1 Loss:  0.10068430677056313 , Time: 5101.657639503479 s\n",
      "Batch:  1690 , l1 Loss:  0.10243389904499053 , Time: 5113.667469024658 s\n",
      "Batch:  1700 , l1 Loss:  0.10213961899280548 , Time: 5125.705520153046 s\n",
      "Batch:  1710 , l1 Loss:  0.10167121440172196 , Time: 5137.731769800186 s\n",
      "Batch:  1720 , l1 Loss:  0.09963316097855568 , Time: 5149.695251464844 s\n",
      "Batch:  1730 , l1 Loss:  0.10128844156861305 , Time: 5161.686503410339 s\n",
      "Batch:  1740 , l1 Loss:  0.10130356177687645 , Time: 5173.648952484131 s\n",
      "Batch:  1750 , l1 Loss:  0.10031345337629319 , Time: 5185.634576797485 s\n",
      "Batch:  1760 , l1 Loss:  0.100195524841547 , Time: 5197.630376338959 s\n",
      "Batch:  1770 , l1 Loss:  0.09926435053348541 , Time: 5209.666397094727 s\n",
      "Batch:  1780 , l1 Loss:  0.09897786378860474 , Time: 5221.659930467606 s\n",
      "Batch:  1790 , l1 Loss:  0.1003719262778759 , Time: 5233.6547865867615 s\n",
      "Batch:  1800 , l1 Loss:  0.09972655177116393 , Time: 5245.705240488052 s\n",
      "Batch:  1810 , l1 Loss:  0.10012245774269105 , Time: 5257.735831737518 s\n",
      "Batch:  1820 , l1 Loss:  0.09896169900894165 , Time: 5269.731748580933 s\n",
      "Batch:  1830 , l1 Loss:  0.10040399879217148 , Time: 5281.778641462326 s\n",
      "Batch:  1840 , l1 Loss:  0.10287042781710624 , Time: 5293.75282740593 s\n",
      "Batch:  1850 , l1 Loss:  0.10106738731265068 , Time: 5305.718766450882 s\n",
      "Batch:  1860 , l1 Loss:  0.10117794126272202 , Time: 5317.731895446777 s\n",
      "Batch:  1870 , l1 Loss:  0.10012572929263115 , Time: 5329.839199304581 s\n",
      "Batch:  1880 , l1 Loss:  0.09960773140192032 , Time: 5341.892611980438 s\n",
      "Batch:  1890 , l1 Loss:  0.1013567678630352 , Time: 5354.093147516251 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  1900 , l1 Loss:  0.09957264587283135 , Time: 5366.2438180446625 s\n",
      "Batch:  1910 , l1 Loss:  0.10050475522875786 , Time: 5378.329997301102 s\n",
      "Batch:  1920 , l1 Loss:  0.10036210119724273 , Time: 5390.439720630646 s\n",
      "Batch:  1930 , l1 Loss:  0.09999601617455482 , Time: 5402.623251438141 s\n",
      "Batch:  1940 , l1 Loss:  0.09928654134273529 , Time: 5414.893968820572 s\n",
      "Batch:  1950 , l1 Loss:  0.10039583966135979 , Time: 5427.18314409256 s\n",
      "Batch:  1960 , l1 Loss:  0.10121290311217308 , Time: 5439.585829496384 s\n",
      "Batch:  1970 , l1 Loss:  0.09936719760298729 , Time: 5451.811643362045 s\n",
      "Batch:  1980 , l1 Loss:  0.10084240660071372 , Time: 5464.061973810196 s\n",
      "Batch:  1990 , l1 Loss:  0.10088977739214897 , Time: 5476.353795051575 s\n",
      "Batch:  2000 , l1 Loss:  0.09937947914004326 , Time: 5488.524446964264 s\n",
      "Batch:  2010 , l1 Loss:  0.09952156394720077 , Time: 5500.785048246384 s\n",
      "Batch:  2020 , l1 Loss:  0.1008484996855259 , Time: 5513.130594730377 s\n",
      "Batch:  2030 , l1 Loss:  0.10073452964425086 , Time: 5525.334704875946 s\n",
      "Batch:  2040 , l1 Loss:  0.10123967006802559 , Time: 5537.535023450851 s\n",
      "Batch:  2050 , l1 Loss:  0.09944877475500107 , Time: 5549.722718238831 s\n",
      "Batch:  2060 , l1 Loss:  0.09922331050038338 , Time: 5561.978504657745 s\n",
      "Batch:  2070 , l1 Loss:  0.1000559464097023 , Time: 5574.1664090156555 s\n",
      "Batch:  2080 , l1 Loss:  0.0998069778084755 , Time: 5586.398874998093 s\n",
      "Batch:  2090 , l1 Loss:  0.09988984912633896 , Time: 5598.626223325729 s\n",
      "Batch:  2100 , l1 Loss:  0.09985496252775192 , Time: 5610.831987380981 s\n",
      "Batch:  2110 , l1 Loss:  0.10084279328584671 , Time: 5623.022847652435 s\n",
      "Batch:  2120 , l1 Loss:  0.10096763521432876 , Time: 5635.158513784409 s\n",
      "Batch:  2130 , l1 Loss:  0.10043743401765823 , Time: 5647.295369148254 s\n",
      "Batch:  2140 , l1 Loss:  0.1008396439254284 , Time: 5659.410634994507 s\n",
      "Batch:  2150 , l1 Loss:  0.1013665333390236 , Time: 5671.565377473831 s\n",
      "Batch:  2160 , l1 Loss:  0.09980124235153198 , Time: 5683.780894041061 s\n",
      "Batch:  2170 , l1 Loss:  0.09946491494774819 , Time: 5696.002710342407 s\n",
      "Batch:  2180 , l1 Loss:  0.09967118874192238 , Time: 5708.1843185424805 s\n",
      "Batch:  2190 , l1 Loss:  0.10020282939076423 , Time: 5720.3684911727905 s\n",
      "Batch:  2200 , l1 Loss:  0.09940598979592323 , Time: 5732.461825370789 s\n",
      "Batch:  2210 , l1 Loss:  0.10053555220365525 , Time: 5744.591086387634 s\n",
      "Batch:  2220 , l1 Loss:  0.10061402395367622 , Time: 5756.804478645325 s\n",
      "Batch:  2230 , l1 Loss:  0.10054867565631867 , Time: 5769.004826068878 s\n",
      "Batch:  2240 , l1 Loss:  0.10010037645697593 , Time: 5781.170336723328 s\n",
      "Batch:  2250 , l1 Loss:  0.10054706782102585 , Time: 5793.364268779755 s\n",
      "Batch:  2260 , l1 Loss:  0.10037344470620155 , Time: 5805.641605377197 s\n",
      "Batch:  2270 , l1 Loss:  0.1009699322283268 , Time: 5817.813951730728 s\n",
      "Batch:  2280 , l1 Loss:  0.09968976452946662 , Time: 5829.942925930023 s\n",
      "Batch:  2290 , l1 Loss:  0.09864926338195801 , Time: 5842.135694980621 s\n",
      "Batch:  2300 , l1 Loss:  0.10021373629570007 , Time: 5854.3481957912445 s\n",
      "Batch:  2310 , l1 Loss:  0.1007367990911007 , Time: 5866.574294090271 s\n",
      "Batch:  2320 , l1 Loss:  0.10039608478546143 , Time: 5878.750401258469 s\n",
      "Batch:  2330 , l1 Loss:  0.09934725388884544 , Time: 5890.936338424683 s\n",
      "Batch:  2340 , l1 Loss:  0.10003862679004669 , Time: 5902.990173578262 s\n",
      "Batch:  2350 , l1 Loss:  0.10125708356499671 , Time: 5914.917751550674 s\n",
      "Batch:  2360 , l1 Loss:  0.10114786699414254 , Time: 5926.853650331497 s\n",
      "Batch:  2370 , l1 Loss:  0.09845392405986786 , Time: 5938.824814796448 s\n",
      "Batch:  2380 , l1 Loss:  0.10081770643591881 , Time: 5950.8320598602295 s\n",
      "Batch:  2390 , l1 Loss:  0.09896761476993561 , Time: 5962.919904708862 s\n",
      "Batch:  2400 , l1 Loss:  0.09967791512608529 , Time: 5974.920441627502 s\n",
      "Batch:  2410 , l1 Loss:  0.1003366231918335 , Time: 5986.929268121719 s\n",
      "Batch:  2420 , l1 Loss:  0.09966301321983337 , Time: 5998.909852027893 s\n",
      "Batch:  2430 , l1 Loss:  0.09988675564527512 , Time: 6010.894214630127 s\n",
      "Batch:  2440 , l1 Loss:  0.10175353959202767 , Time: 6022.92384147644 s\n",
      "Batch:  2450 , l1 Loss:  0.10123327895998954 , Time: 6034.879699707031 s\n",
      "Batch:  2460 , l1 Loss:  0.09921551570296287 , Time: 6046.949537754059 s\n",
      "Batch:  2470 , l1 Loss:  0.09897250980138779 , Time: 6058.941638469696 s\n",
      "Batch:  2480 , l1 Loss:  0.09952757284045219 , Time: 6070.9788517951965 s\n",
      "Batch:  2490 , l1 Loss:  0.10067056268453597 , Time: 6083.192266702652 s\n",
      "Batch:  2500 , l1 Loss:  0.10038539618253708 , Time: 6095.4481985569 s\n",
      "Batch:  2510 , l1 Loss:  0.0997673176229 , Time: 6107.710999250412 s\n",
      "Batch:  2520 , l1 Loss:  0.10014744400978089 , Time: 6119.955544471741 s\n",
      "Batch:  2530 , l1 Loss:  0.100776307284832 , Time: 6132.264958143234 s\n",
      "Batch:  2540 , l1 Loss:  0.09977190643548965 , Time: 6144.618958950043 s\n",
      "Batch:  2550 , l1 Loss:  0.09941394627094269 , Time: 6156.967586517334 s\n",
      "Batch:  2560 , l1 Loss:  0.0996803104877472 , Time: 6169.26164150238 s\n",
      "Batch:  2570 , l1 Loss:  0.09978545606136321 , Time: 6181.572882890701 s\n",
      "Batch:  2580 , l1 Loss:  0.10052685514092445 , Time: 6193.781997919083 s\n",
      "Batch:  2590 , l1 Loss:  0.09967242851853371 , Time: 6205.693281650543 s\n",
      "Batch:  2600 , l1 Loss:  0.09970469698309899 , Time: 6217.578869104385 s\n",
      "Batch:  2610 , l1 Loss:  0.10031269863247871 , Time: 6229.533281803131 s\n",
      "Batch:  2620 , l1 Loss:  0.10005726292729378 , Time: 6241.492087125778 s\n",
      "Batch:  2630 , l1 Loss:  0.09990793839097023 , Time: 6253.4815492630005 s\n",
      "Epoch:  1 , l1 loss:  0.1006099270711863\n",
      "Epoch:  2\n",
      "Batch:  10 , l1 Loss:  0.09993880242109299 , Time: 6270.635652780533 s\n",
      "Batch:  20 , l1 Loss:  0.09965480789542198 , Time: 6282.446371555328 s\n",
      "Batch:  30 , l1 Loss:  0.09890653118491173 , Time: 6294.208927154541 s\n",
      "Batch:  40 , l1 Loss:  0.09916473850607872 , Time: 6305.97945356369 s\n",
      "Batch:  50 , l1 Loss:  0.10052267760038376 , Time: 6317.764231920242 s\n",
      "Batch:  60 , l1 Loss:  0.10226889923214913 , Time: 6329.541809082031 s\n",
      "Batch:  70 , l1 Loss:  0.1027097798883915 , Time: 6341.32900929451 s\n",
      "Batch:  80 , l1 Loss:  0.10131597071886063 , Time: 6353.120280742645 s\n",
      "Batch:  90 , l1 Loss:  0.10014597624540329 , Time: 6364.928530931473 s\n",
      "Batch:  100 , l1 Loss:  0.0999627873301506 , Time: 6376.73434472084 s\n",
      "Batch:  110 , l1 Loss:  0.10059628263115883 , Time: 6388.530021905899 s\n",
      "Batch:  120 , l1 Loss:  0.10082096233963966 , Time: 6400.355131387711 s\n",
      "Batch:  130 , l1 Loss:  0.09883641451597214 , Time: 6412.141604423523 s\n",
      "Batch:  140 , l1 Loss:  0.09899151399731636 , Time: 6423.968500852585 s\n",
      "Batch:  150 , l1 Loss:  0.0993362583220005 , Time: 6435.797780752182 s\n",
      "Batch:  160 , l1 Loss:  0.10049630105495452 , Time: 6447.604045629501 s\n",
      "Batch:  170 , l1 Loss:  0.10035796687006951 , Time: 6459.404795408249 s\n",
      "Batch:  180 , l1 Loss:  0.10014020428061485 , Time: 6471.213809013367 s\n",
      "Batch:  190 , l1 Loss:  0.10043568462133408 , Time: 6483.023898124695 s\n",
      "Batch:  200 , l1 Loss:  0.10049723163247108 , Time: 6494.839794635773 s\n",
      "Batch:  210 , l1 Loss:  0.09954327642917633 , Time: 6506.647420406342 s\n",
      "Batch:  220 , l1 Loss:  0.10069033801555634 , Time: 6518.462173938751 s\n",
      "Batch:  230 , l1 Loss:  0.09942161291837692 , Time: 6530.311245203018 s\n",
      "Batch:  240 , l1 Loss:  0.10024080947041511 , Time: 6542.14319729805 s\n",
      "Batch:  250 , l1 Loss:  0.10013089701533318 , Time: 6553.992975473404 s\n",
      "Batch:  260 , l1 Loss:  0.09976419359445572 , Time: 6565.7995636463165 s\n",
      "Batch:  270 , l1 Loss:  0.09931958988308906 , Time: 6577.597340583801 s\n",
      "Batch:  280 , l1 Loss:  0.10059471055865288 , Time: 6589.427923440933 s\n",
      "Batch:  290 , l1 Loss:  0.09918468743562699 , Time: 6601.247117757797 s\n",
      "Batch:  300 , l1 Loss:  0.09837331920862198 , Time: 6613.0525851249695 s\n",
      "Batch:  310 , l1 Loss:  0.09865440279245377 , Time: 6624.883538246155 s\n",
      "Batch:  320 , l1 Loss:  0.1004012294113636 , Time: 6636.715726852417 s\n",
      "Batch:  330 , l1 Loss:  0.10028281509876251 , Time: 6648.56588768959 s\n",
      "Batch:  340 , l1 Loss:  0.10038478299975395 , Time: 6660.401544809341 s\n",
      "Batch:  350 , l1 Loss:  0.09908031299710274 , Time: 6672.225799322128 s\n",
      "Batch:  360 , l1 Loss:  0.0996007464826107 , Time: 6684.101810455322 s\n",
      "Batch:  370 , l1 Loss:  0.10022002384066582 , Time: 6696.014801502228 s\n",
      "Batch:  380 , l1 Loss:  0.09999911114573479 , Time: 6707.925232887268 s\n",
      "Batch:  390 , l1 Loss:  0.10055084154009819 , Time: 6719.845895767212 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  400 , l1 Loss:  0.09857395738363266 , Time: 6731.731207609177 s\n",
      "Batch:  410 , l1 Loss:  0.09985497742891311 , Time: 6743.604747772217 s\n",
      "Batch:  420 , l1 Loss:  0.09956611916422844 , Time: 6755.483067989349 s\n",
      "Batch:  430 , l1 Loss:  0.1002014510333538 , Time: 6767.431567430496 s\n",
      "Batch:  440 , l1 Loss:  0.0992838516831398 , Time: 6779.333445072174 s\n",
      "Batch:  450 , l1 Loss:  0.09856216087937356 , Time: 6791.199228048325 s\n",
      "Batch:  460 , l1 Loss:  0.09912454336881638 , Time: 6803.089158296585 s\n",
      "Batch:  470 , l1 Loss:  0.10022744908928871 , Time: 6814.9557819366455 s\n",
      "Batch:  480 , l1 Loss:  0.09863841459155083 , Time: 6826.815460443497 s\n",
      "Batch:  490 , l1 Loss:  0.09987311959266662 , Time: 6838.567478179932 s\n",
      "Batch:  500 , l1 Loss:  0.09993821531534194 , Time: 6850.337361812592 s\n",
      "Batch:  510 , l1 Loss:  0.09772551953792571 , Time: 6862.1086275577545 s\n",
      "Batch:  520 , l1 Loss:  0.09980422481894494 , Time: 6873.940417051315 s\n",
      "Batch:  530 , l1 Loss:  0.09820955023169517 , Time: 6885.792990922928 s\n",
      "Batch:  540 , l1 Loss:  0.09943126067519188 , Time: 6897.577538728714 s\n",
      "Batch:  550 , l1 Loss:  0.09971872866153716 , Time: 6909.3894147872925 s\n",
      "Batch:  560 , l1 Loss:  0.10046688914299011 , Time: 6921.201226234436 s\n",
      "Batch:  570 , l1 Loss:  0.10038955137133598 , Time: 6933.003946065903 s\n",
      "Batch:  580 , l1 Loss:  0.09911953955888748 , Time: 6944.812678098679 s\n",
      "Batch:  590 , l1 Loss:  0.09903636798262597 , Time: 6956.606549739838 s\n",
      "Batch:  600 , l1 Loss:  0.09963971227407456 , Time: 6968.4159462451935 s\n",
      "Batch:  610 , l1 Loss:  0.09967462196946145 , Time: 6980.241077184677 s\n",
      "Batch:  620 , l1 Loss:  0.1001701109111309 , Time: 6992.077739477158 s\n",
      "Batch:  630 , l1 Loss:  0.10074389204382897 , Time: 7003.945357561111 s\n",
      "Batch:  640 , l1 Loss:  0.10061897560954094 , Time: 7015.758787155151 s\n",
      "Batch:  650 , l1 Loss:  0.10066639631986618 , Time: 7027.577800035477 s\n",
      "Batch:  660 , l1 Loss:  0.09995032995939254 , Time: 7039.425678014755 s\n",
      "Batch:  670 , l1 Loss:  0.1010028749704361 , Time: 7051.2710592746735 s\n",
      "Batch:  680 , l1 Loss:  0.09941553100943565 , Time: 7063.1231009960175 s\n",
      "Batch:  690 , l1 Loss:  0.09925586208701134 , Time: 7074.95280790329 s\n",
      "Batch:  700 , l1 Loss:  0.10039884820580483 , Time: 7086.796019792557 s\n",
      "Batch:  710 , l1 Loss:  0.09931019321084023 , Time: 7098.628171443939 s\n",
      "Batch:  720 , l1 Loss:  0.099082463234663 , Time: 7110.477336168289 s\n",
      "Batch:  730 , l1 Loss:  0.10037646144628525 , Time: 7122.359802484512 s\n",
      "Batch:  740 , l1 Loss:  0.09919072464108467 , Time: 7134.2070553302765 s\n",
      "Batch:  750 , l1 Loss:  0.09888930395245552 , Time: 7146.080680131912 s\n",
      "Batch:  760 , l1 Loss:  0.10186420977115632 , Time: 7157.934469461441 s\n",
      "Batch:  770 , l1 Loss:  0.10048216432332993 , Time: 7169.8000655174255 s\n",
      "Batch:  780 , l1 Loss:  0.10122205466032028 , Time: 7181.65279841423 s\n",
      "Batch:  790 , l1 Loss:  0.0995842270553112 , Time: 7193.672911167145 s\n",
      "Batch:  800 , l1 Loss:  0.10037260800600052 , Time: 7205.472509384155 s\n",
      "Batch:  810 , l1 Loss:  0.09844157248735427 , Time: 7217.289435148239 s\n",
      "Batch:  820 , l1 Loss:  0.0996066763997078 , Time: 7229.125331163406 s\n",
      "Batch:  830 , l1 Loss:  0.09886162430047989 , Time: 7241.018950223923 s\n",
      "Batch:  840 , l1 Loss:  0.10010551437735557 , Time: 7252.8635404109955 s\n",
      "Batch:  850 , l1 Loss:  0.09949339553713799 , Time: 7264.7457773685455 s\n",
      "Batch:  860 , l1 Loss:  0.09904887825250626 , Time: 7276.598376989365 s\n",
      "Batch:  870 , l1 Loss:  0.10021038725972176 , Time: 7288.507525682449 s\n",
      "Batch:  880 , l1 Loss:  0.09827517420053482 , Time: 7300.396176338196 s\n",
      "Batch:  890 , l1 Loss:  0.09850000739097595 , Time: 7312.298645973206 s\n",
      "Batch:  900 , l1 Loss:  0.09950564578175544 , Time: 7324.170619726181 s\n",
      "Batch:  910 , l1 Loss:  0.09970283284783363 , Time: 7336.035234451294 s\n",
      "Batch:  920 , l1 Loss:  0.09861552640795708 , Time: 7348.03125 s\n",
      "Batch:  930 , l1 Loss:  0.09878559559583663 , Time: 7360.345326423645 s\n",
      "Batch:  940 , l1 Loss:  0.09907898902893067 , Time: 7372.5490000247955 s\n",
      "Batch:  950 , l1 Loss:  0.0991237923502922 , Time: 7384.734762907028 s\n",
      "Batch:  960 , l1 Loss:  0.0998454324901104 , Time: 7396.914771556854 s\n",
      "Batch:  970 , l1 Loss:  0.09913373216986657 , Time: 7409.100755929947 s\n",
      "Batch:  980 , l1 Loss:  0.1001487709581852 , Time: 7421.227032423019 s\n",
      "Batch:  990 , l1 Loss:  0.099784454703331 , Time: 7433.3502242565155 s\n",
      "Batch:  1000 , l1 Loss:  0.09875556528568268 , Time: 7445.481791257858 s\n",
      "Batch:  1010 , l1 Loss:  0.09890837445855141 , Time: 7457.629440069199 s\n",
      "Batch:  1020 , l1 Loss:  0.10232306942343712 , Time: 7469.765178203583 s\n",
      "Batch:  1030 , l1 Loss:  0.09992984607815743 , Time: 7481.923334598541 s\n",
      "Batch:  1040 , l1 Loss:  0.10006226971745491 , Time: 7494.069802045822 s\n",
      "Batch:  1050 , l1 Loss:  0.09973527416586876 , Time: 7506.174450159073 s\n",
      "Batch:  1060 , l1 Loss:  0.09995702877640725 , Time: 7518.292288780212 s\n",
      "Batch:  1070 , l1 Loss:  0.10026219487190247 , Time: 7530.419532299042 s\n",
      "Batch:  1080 , l1 Loss:  0.09988034740090371 , Time: 7542.563479185104 s\n",
      "Batch:  1090 , l1 Loss:  0.0996958188712597 , Time: 7554.7039613723755 s\n",
      "Batch:  1100 , l1 Loss:  0.09953383654356003 , Time: 7566.787171125412 s\n",
      "Batch:  1110 , l1 Loss:  0.09956713691353798 , Time: 7578.836778879166 s\n",
      "Batch:  1120 , l1 Loss:  0.09817391484975815 , Time: 7590.926338672638 s\n",
      "Batch:  1130 , l1 Loss:  0.09921463429927826 , Time: 7603.104019165039 s\n",
      "Batch:  1140 , l1 Loss:  0.10004261285066604 , Time: 7615.212204456329 s\n",
      "Batch:  1150 , l1 Loss:  0.09906687662005424 , Time: 7627.297739267349 s\n",
      "Batch:  1160 , l1 Loss:  0.10010050237178802 , Time: 7639.431681394577 s\n",
      "Batch:  1170 , l1 Loss:  0.09907233342528343 , Time: 7651.569548368454 s\n",
      "Batch:  1180 , l1 Loss:  0.09934550002217293 , Time: 7663.640711307526 s\n",
      "Batch:  1190 , l1 Loss:  0.09805267602205277 , Time: 7675.700284957886 s\n",
      "Batch:  1200 , l1 Loss:  0.0994682028889656 , Time: 7687.78225851059 s\n",
      "Batch:  1210 , l1 Loss:  0.09941176325082779 , Time: 7699.809982538223 s\n",
      "Batch:  1220 , l1 Loss:  0.10022766143083572 , Time: 7711.499775648117 s\n",
      "Batch:  1230 , l1 Loss:  0.09958195835351943 , Time: 7723.301059007645 s\n",
      "Batch:  1240 , l1 Loss:  0.10081111937761307 , Time: 7735.063478708267 s\n",
      "Batch:  1250 , l1 Loss:  0.09911646023392677 , Time: 7746.833917379379 s\n",
      "Batch:  1260 , l1 Loss:  0.09987095072865486 , Time: 7758.66450214386 s\n",
      "Batch:  1270 , l1 Loss:  0.09926583543419838 , Time: 7770.4478595256805 s\n",
      "Batch:  1280 , l1 Loss:  0.099159474670887 , Time: 7782.246026992798 s\n",
      "Batch:  1290 , l1 Loss:  0.0985034428536892 , Time: 7794.072763204575 s\n",
      "Batch:  1300 , l1 Loss:  0.0995997205376625 , Time: 7805.880087614059 s\n",
      "Batch:  1310 , l1 Loss:  0.1003559872508049 , Time: 7817.694949150085 s\n",
      "Batch:  1320 , l1 Loss:  0.09915737137198448 , Time: 7829.511517763138 s\n",
      "Batch:  1330 , l1 Loss:  0.09947353675961494 , Time: 7841.379241228104 s\n",
      "Batch:  1340 , l1 Loss:  0.10021946504712105 , Time: 7853.202640533447 s\n",
      "Batch:  1350 , l1 Loss:  0.09970938190817832 , Time: 7865.011258602142 s\n",
      "Batch:  1360 , l1 Loss:  0.10077400207519531 , Time: 7876.818871021271 s\n",
      "Batch:  1370 , l1 Loss:  0.10114720836281776 , Time: 7888.649472475052 s\n",
      "Batch:  1380 , l1 Loss:  0.0987894132733345 , Time: 7900.476556062698 s\n",
      "Batch:  1390 , l1 Loss:  0.09967306926846504 , Time: 7912.303471803665 s\n",
      "Batch:  1400 , l1 Loss:  0.0982660971581936 , Time: 7924.12975358963 s\n",
      "Batch:  1410 , l1 Loss:  0.09911844953894615 , Time: 7935.940510749817 s\n",
      "Batch:  1420 , l1 Loss:  0.09935722053050995 , Time: 7947.792967557907 s\n",
      "Batch:  1430 , l1 Loss:  0.10148608908057213 , Time: 7959.636925697327 s\n",
      "Batch:  1440 , l1 Loss:  0.10185001492500305 , Time: 7971.497406721115 s\n",
      "Batch:  1450 , l1 Loss:  0.09999886602163315 , Time: 7983.347998142242 s\n",
      "Batch:  1460 , l1 Loss:  0.10067732408642768 , Time: 7995.202338933945 s\n",
      "Batch:  1470 , l1 Loss:  0.10023440346121788 , Time: 8007.048605918884 s\n",
      "Batch:  1480 , l1 Loss:  0.09948144778609276 , Time: 8018.887769460678 s\n",
      "Batch:  1490 , l1 Loss:  0.09897754415869713 , Time: 8030.752179145813 s\n",
      "Batch:  1500 , l1 Loss:  0.09840530157089233 , Time: 8042.626175403595 s\n",
      "Batch:  1510 , l1 Loss:  0.0989959217607975 , Time: 8054.504695653915 s\n",
      "Batch:  1520 , l1 Loss:  0.09879663586616516 , Time: 8066.388348340988 s\n",
      "Batch:  1530 , l1 Loss:  0.09885671958327294 , Time: 8078.288999557495 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  1540 , l1 Loss:  0.0997310921549797 , Time: 8090.241664648056 s\n",
      "Batch:  1550 , l1 Loss:  0.09986224174499511 , Time: 8102.133373498917 s\n",
      "Batch:  1560 , l1 Loss:  0.09982054308056831 , Time: 8114.026735067368 s\n",
      "Batch:  1570 , l1 Loss:  0.10010933354496956 , Time: 8125.903761386871 s\n",
      "Batch:  1580 , l1 Loss:  0.0992144450545311 , Time: 8137.773485898972 s\n",
      "Batch:  1590 , l1 Loss:  0.09896508604288101 , Time: 8149.643887281418 s\n",
      "Batch:  1600 , l1 Loss:  0.09966051205992699 , Time: 8161.520415067673 s\n",
      "Batch:  1610 , l1 Loss:  0.10041618272662163 , Time: 8173.407382726669 s\n",
      "Batch:  1620 , l1 Loss:  0.09931881353259087 , Time: 8185.280114650726 s\n",
      "Batch:  1630 , l1 Loss:  0.1002419576048851 , Time: 8197.135855674744 s\n",
      "Batch:  1640 , l1 Loss:  0.09978322982788086 , Time: 8209.048544883728 s\n",
      "Batch:  1650 , l1 Loss:  0.09841089025139808 , Time: 8220.910330295563 s\n",
      "Batch:  1660 , l1 Loss:  0.09873040989041329 , Time: 8232.747718572617 s\n",
      "Batch:  1670 , l1 Loss:  0.09847219735383987 , Time: 8244.635663986206 s\n",
      "Batch:  1680 , l1 Loss:  0.09896840378642083 , Time: 8256.52427148819 s\n",
      "Batch:  1690 , l1 Loss:  0.09947663769125939 , Time: 8268.378113985062 s\n",
      "Batch:  1700 , l1 Loss:  0.09980314075946808 , Time: 8280.391912937164 s\n",
      "Batch:  1710 , l1 Loss:  0.09942065849900246 , Time: 8292.4246134758 s\n",
      "Batch:  1720 , l1 Loss:  0.09960708171129226 , Time: 8304.479483604431 s\n",
      "Batch:  1730 , l1 Loss:  0.09912015795707703 , Time: 8316.515822172165 s\n",
      "Batch:  1740 , l1 Loss:  0.10022371113300324 , Time: 8328.583400011063 s\n",
      "Batch:  1750 , l1 Loss:  0.09993842095136643 , Time: 8340.616451978683 s\n",
      "Batch:  1760 , l1 Loss:  0.09964660927653313 , Time: 8352.661130666733 s\n",
      "Batch:  1770 , l1 Loss:  0.09940351024270058 , Time: 8364.700010061264 s\n",
      "Batch:  1780 , l1 Loss:  0.09912527278065682 , Time: 8376.785975456238 s\n",
      "Batch:  1790 , l1 Loss:  0.0991246871650219 , Time: 8388.851465463638 s\n",
      "Batch:  1800 , l1 Loss:  0.09954382330179215 , Time: 8400.936613559723 s\n",
      "Batch:  1810 , l1 Loss:  0.09982620999217033 , Time: 8413.00013589859 s\n",
      "Batch:  1820 , l1 Loss:  0.09943440854549408 , Time: 8425.029495716095 s\n",
      "Batch:  1830 , l1 Loss:  0.10032126158475876 , Time: 8437.061403036118 s\n",
      "Batch:  1840 , l1 Loss:  0.09958847388625144 , Time: 8449.181650400162 s\n",
      "Batch:  1850 , l1 Loss:  0.09934438988566399 , Time: 8461.262478351593 s\n",
      "Batch:  1860 , l1 Loss:  0.09955845400691032 , Time: 8473.33480167389 s\n",
      "Batch:  1870 , l1 Loss:  0.09864199832081795 , Time: 8485.357525348663 s\n",
      "Batch:  1880 , l1 Loss:  0.09980651810765266 , Time: 8497.425504684448 s\n",
      "Batch:  1890 , l1 Loss:  0.09948312714695931 , Time: 8509.480886220932 s\n",
      "Batch:  1900 , l1 Loss:  0.09814629405736923 , Time: 8521.562978982925 s\n",
      "Batch:  1910 , l1 Loss:  0.0978645920753479 , Time: 8533.576949834824 s\n",
      "Batch:  1920 , l1 Loss:  0.09994106888771057 , Time: 8545.447132349014 s\n",
      "Batch:  1930 , l1 Loss:  0.0994487002491951 , Time: 8557.252070426941 s\n",
      "Batch:  1940 , l1 Loss:  0.0980202704668045 , Time: 8569.08852815628 s\n",
      "Batch:  1950 , l1 Loss:  0.09897743910551071 , Time: 8580.8502202034 s\n",
      "Batch:  1960 , l1 Loss:  0.09863904044032097 , Time: 8592.66627407074 s\n",
      "Batch:  1970 , l1 Loss:  0.09836623594164848 , Time: 8604.441222429276 s\n",
      "Batch:  1980 , l1 Loss:  0.0989638015627861 , Time: 8616.234292507172 s\n",
      "Batch:  1990 , l1 Loss:  0.09911816641688347 , Time: 8628.047090291977 s\n",
      "Batch:  2000 , l1 Loss:  0.09839901998639107 , Time: 8639.849921226501 s\n",
      "Batch:  2010 , l1 Loss:  0.09874817207455636 , Time: 8651.666420698166 s\n",
      "Batch:  2020 , l1 Loss:  0.098907982558012 , Time: 8663.483285188675 s\n",
      "Batch:  2030 , l1 Loss:  0.09900574162602424 , Time: 8675.330157756805 s\n",
      "Batch:  2040 , l1 Loss:  0.09887506738305092 , Time: 8687.228556871414 s\n",
      "Batch:  2050 , l1 Loss:  0.09937015026807786 , Time: 8699.066174268723 s\n",
      "Batch:  2060 , l1 Loss:  0.09891279637813569 , Time: 8710.882739067078 s\n",
      "Batch:  2070 , l1 Loss:  0.09936064556241035 , Time: 8722.7110080719 s\n",
      "Batch:  2080 , l1 Loss:  0.09958435893058777 , Time: 8734.565410614014 s\n",
      "Batch:  2090 , l1 Loss:  0.09868074953556061 , Time: 8746.398802995682 s\n",
      "Batch:  2100 , l1 Loss:  0.09810425490140914 , Time: 8758.23678779602 s\n",
      "Batch:  2110 , l1 Loss:  0.09837229773402215 , Time: 8770.070445537567 s\n",
      "Batch:  2120 , l1 Loss:  0.09835676774382592 , Time: 8781.944143772125 s\n",
      "Batch:  2130 , l1 Loss:  0.09816434904932976 , Time: 8793.79956650734 s\n",
      "Batch:  2140 , l1 Loss:  0.09859994351863861 , Time: 8806.090330123901 s\n",
      "Batch:  2150 , l1 Loss:  0.09969856664538383 , Time: 8818.308326482773 s\n",
      "Batch:  2160 , l1 Loss:  0.09846607372164726 , Time: 8830.709854364395 s\n",
      "Batch:  2170 , l1 Loss:  0.098707415163517 , Time: 8842.947320699692 s\n",
      "Batch:  2180 , l1 Loss:  0.09817801341414452 , Time: 8854.894020080566 s\n",
      "Batch:  2190 , l1 Loss:  0.09895075559616089 , Time: 8866.712464571 s\n",
      "Batch:  2200 , l1 Loss:  0.10095115900039672 , Time: 8878.495418071747 s\n",
      "Batch:  2210 , l1 Loss:  0.09933632463216782 , Time: 8890.297430038452 s\n",
      "Batch:  2220 , l1 Loss:  0.09798594638705253 , Time: 8902.106063604355 s\n",
      "Batch:  2230 , l1 Loss:  0.09868518188595772 , Time: 8913.915842533112 s\n",
      "Batch:  2240 , l1 Loss:  0.098346296697855 , Time: 8925.831283569336 s\n",
      "Batch:  2250 , l1 Loss:  0.09794795960187912 , Time: 8937.711710214615 s\n",
      "Batch:  2260 , l1 Loss:  0.09920486882328987 , Time: 8949.55948638916 s\n",
      "Batch:  2270 , l1 Loss:  0.09872974008321762 , Time: 8961.425415277481 s\n",
      "Batch:  2280 , l1 Loss:  0.0977221205830574 , Time: 8973.298511505127 s\n",
      "Batch:  2290 , l1 Loss:  0.09887010157108307 , Time: 8985.151928901672 s\n",
      "Batch:  2300 , l1 Loss:  0.0986974999308586 , Time: 8997.022018671036 s\n",
      "Batch:  2310 , l1 Loss:  0.09793787226080894 , Time: 9008.879426240921 s\n",
      "Batch:  2320 , l1 Loss:  0.09810332581400871 , Time: 9020.756884098053 s\n",
      "Batch:  2330 , l1 Loss:  0.09832351729273796 , Time: 9032.623654842377 s\n",
      "Batch:  2340 , l1 Loss:  0.09980835914611816 , Time: 9044.580443143845 s\n",
      "Batch:  2350 , l1 Loss:  0.10050639435648918 , Time: 9056.427003622055 s\n",
      "Batch:  2360 , l1 Loss:  0.09923653826117515 , Time: 9068.286939382553 s\n",
      "Batch:  2370 , l1 Loss:  0.09935149550437927 , Time: 9080.147414922714 s\n",
      "Batch:  2380 , l1 Loss:  0.09895403832197189 , Time: 9092.044600009918 s\n",
      "Batch:  2390 , l1 Loss:  0.09903475865721703 , Time: 9103.929735422134 s\n",
      "Batch:  2400 , l1 Loss:  0.09858727306127549 , Time: 9115.85962677002 s\n",
      "Batch:  2410 , l1 Loss:  0.09882008582353592 , Time: 9127.770498991013 s\n",
      "Batch:  2420 , l1 Loss:  0.09881955459713936 , Time: 9139.661548376083 s\n",
      "Batch:  2430 , l1 Loss:  0.10009464994072914 , Time: 9151.509328126907 s\n",
      "Batch:  2440 , l1 Loss:  0.09926329553127289 , Time: 9163.378268003464 s\n",
      "Batch:  2450 , l1 Loss:  0.09881066605448723 , Time: 9175.26458311081 s\n",
      "Batch:  2460 , l1 Loss:  0.09892281219363212 , Time: 9187.147770881653 s\n",
      "Batch:  2470 , l1 Loss:  0.09880246371030807 , Time: 9199.021676301956 s\n",
      "Batch:  2480 , l1 Loss:  0.10003185421228408 , Time: 9210.882843732834 s\n",
      "Batch:  2490 , l1 Loss:  0.10014579147100448 , Time: 9222.801441907883 s\n",
      "Batch:  2500 , l1 Loss:  0.09899112656712532 , Time: 9234.672733545303 s\n",
      "Batch:  2510 , l1 Loss:  0.09800634756684304 , Time: 9246.553518533707 s\n",
      "Batch:  2520 , l1 Loss:  0.09802008718252182 , Time: 9258.462774276733 s\n",
      "Batch:  2530 , l1 Loss:  0.09877851381897926 , Time: 9270.384602546692 s\n",
      "Batch:  2540 , l1 Loss:  0.0988940104842186 , Time: 9282.295379161835 s\n",
      "Batch:  2550 , l1 Loss:  0.09932241886854172 , Time: 9294.167329072952 s\n",
      "Batch:  2560 , l1 Loss:  0.09913084656000137 , Time: 9306.035228013992 s\n",
      "Batch:  2570 , l1 Loss:  0.09893884137272835 , Time: 9317.88917684555 s\n",
      "Batch:  2580 , l1 Loss:  0.09871601685881615 , Time: 9329.79305768013 s\n",
      "Batch:  2590 , l1 Loss:  0.10016501545906067 , Time: 9341.681803941727 s\n",
      "Batch:  2600 , l1 Loss:  0.09880799576640129 , Time: 9353.548742771149 s\n",
      "Batch:  2610 , l1 Loss:  0.09877814054489135 , Time: 9365.442306995392 s\n",
      "Batch:  2620 , l1 Loss:  0.0985302411019802 , Time: 9377.317836284637 s\n",
      "Batch:  2630 , l1 Loss:  0.09914620295166969 , Time: 9389.208379983902 s\n",
      "Epoch:  2 , l1 loss:  0.09945846489300399\n",
      "Epoch:  3\n",
      "Batch:  10 , l1 Loss:  0.09851264479485425 , Time: 9406.417348146439 s\n",
      "Batch:  20 , l1 Loss:  0.09817203432321549 , Time: 9418.212870836258 s\n",
      "Batch:  30 , l1 Loss:  0.09813023507595062 , Time: 9430.025238752365 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  40 , l1 Loss:  0.09871150851249695 , Time: 9441.85818362236 s\n",
      "Batch:  50 , l1 Loss:  0.09887349084019662 , Time: 9453.691535711288 s\n",
      "Batch:  60 , l1 Loss:  0.09985054060816764 , Time: 9465.516493797302 s\n",
      "Batch:  70 , l1 Loss:  0.09965771287679673 , Time: 9477.724455595016 s\n",
      "Batch:  80 , l1 Loss:  0.09971566200256347 , Time: 9489.955788612366 s\n",
      "Batch:  90 , l1 Loss:  0.09877900034189224 , Time: 9502.134913921356 s\n",
      "Batch:  100 , l1 Loss:  0.09867423549294471 , Time: 9514.338024377823 s\n",
      "Batch:  110 , l1 Loss:  0.09978807494044303 , Time: 9526.24976015091 s\n",
      "Batch:  120 , l1 Loss:  0.09892596676945686 , Time: 9537.988258123398 s\n",
      "Batch:  130 , l1 Loss:  0.0989707313477993 , Time: 9549.740361690521 s\n",
      "Batch:  140 , l1 Loss:  0.09947738125920295 , Time: 9561.82054233551 s\n",
      "Batch:  150 , l1 Loss:  0.09883525520563126 , Time: 9574.02545928955 s\n",
      "Batch:  160 , l1 Loss:  0.09808789044618607 , Time: 9586.202939987183 s\n",
      "Batch:  170 , l1 Loss:  0.09864782691001892 , Time: 9598.352454662323 s\n",
      "Batch:  180 , l1 Loss:  0.0986387513577938 , Time: 9610.505016326904 s\n",
      "Batch:  190 , l1 Loss:  0.09866233170032501 , Time: 9622.65527844429 s\n",
      "Batch:  200 , l1 Loss:  0.09863244816660881 , Time: 9634.798645496368 s\n",
      "Batch:  210 , l1 Loss:  0.09809354841709136 , Time: 9646.7391974926 s\n",
      "Batch:  220 , l1 Loss:  0.09911260902881622 , Time: 9658.557740211487 s\n",
      "Batch:  230 , l1 Loss:  0.09913152903318405 , Time: 9670.418730974197 s\n",
      "Batch:  240 , l1 Loss:  0.09849406704306603 , Time: 9682.251066446304 s\n",
      "Batch:  250 , l1 Loss:  0.09898093864321708 , Time: 9694.088268995285 s\n",
      "Batch:  260 , l1 Loss:  0.09919946789741516 , Time: 9705.931458711624 s\n",
      "Batch:  270 , l1 Loss:  0.10038541480898858 , Time: 9717.781242609024 s\n",
      "Batch:  280 , l1 Loss:  0.0991054967045784 , Time: 9729.636193037033 s\n",
      "Batch:  290 , l1 Loss:  0.09904317110776902 , Time: 9741.471702098846 s\n",
      "Batch:  300 , l1 Loss:  0.09812480509281159 , Time: 9753.30099773407 s\n",
      "Batch:  310 , l1 Loss:  0.0981365017592907 , Time: 9765.559307336807 s\n",
      "Batch:  320 , l1 Loss:  0.09817446544766426 , Time: 9777.77011680603 s\n",
      "Batch:  330 , l1 Loss:  0.09836108088493348 , Time: 9789.907294034958 s\n",
      "Batch:  340 , l1 Loss:  0.09841431081295013 , Time: 9802.129060029984 s\n",
      "Batch:  350 , l1 Loss:  0.09812236800789834 , Time: 9814.284622907639 s\n",
      "Batch:  360 , l1 Loss:  0.09840013906359672 , Time: 9826.446204662323 s\n",
      "Batch:  370 , l1 Loss:  0.09885839149355888 , Time: 9838.583948373795 s\n",
      "Batch:  380 , l1 Loss:  0.09907851070165634 , Time: 9850.728673696518 s\n",
      "Batch:  390 , l1 Loss:  0.09876334220170975 , Time: 9862.813661575317 s\n",
      "Batch:  400 , l1 Loss:  0.09944202229380608 , Time: 9874.889374732971 s\n",
      "Batch:  410 , l1 Loss:  0.09844398126006126 , Time: 9886.815156698227 s\n",
      "Batch:  420 , l1 Loss:  0.09654067158699035 , Time: 9898.923877954483 s\n",
      "Batch:  430 , l1 Loss:  0.0979885533452034 , Time: 9911.019852638245 s\n",
      "Batch:  440 , l1 Loss:  0.09912505075335502 , Time: 9923.143185853958 s\n",
      "Batch:  450 , l1 Loss:  0.0981671467423439 , Time: 9935.48740363121 s\n",
      "Batch:  460 , l1 Loss:  0.09889826327562332 , Time: 9947.549482584 s\n",
      "Batch:  470 , l1 Loss:  0.0990358680486679 , Time: 9959.580813646317 s\n",
      "Batch:  480 , l1 Loss:  0.09784897640347481 , Time: 9971.626778364182 s\n",
      "Batch:  490 , l1 Loss:  0.09869444221258164 , Time: 9983.669003248215 s\n",
      "Batch:  500 , l1 Loss:  0.09736471101641656 , Time: 9995.728005886078 s\n",
      "Batch:  510 , l1 Loss:  0.09878103658556939 , Time: 10007.828756093979 s\n",
      "Batch:  520 , l1 Loss:  0.09776970520615577 , Time: 10019.854141235352 s\n",
      "Batch:  530 , l1 Loss:  0.0991725742816925 , Time: 10031.884138822556 s\n",
      "Batch:  540 , l1 Loss:  0.09798777773976326 , Time: 10043.899758815765 s\n",
      "Batch:  550 , l1 Loss:  0.09873874112963676 , Time: 10055.938065052032 s\n",
      "Batch:  560 , l1 Loss:  0.09918831959366799 , Time: 10067.95337152481 s\n",
      "Batch:  570 , l1 Loss:  0.0985041081905365 , Time: 10079.962313175201 s\n",
      "Batch:  580 , l1 Loss:  0.0997855819761753 , Time: 10091.965428352356 s\n",
      "Batch:  590 , l1 Loss:  0.09888471141457558 , Time: 10103.996103525162 s\n",
      "Batch:  600 , l1 Loss:  0.09764770343899727 , Time: 10116.007395744324 s\n",
      "Batch:  610 , l1 Loss:  0.09838586375117302 , Time: 10128.063061714172 s\n",
      "Batch:  620 , l1 Loss:  0.09781373962759972 , Time: 10140.11508488655 s\n",
      "Batch:  630 , l1 Loss:  0.09791714698076248 , Time: 10152.153038263321 s\n",
      "Batch:  640 , l1 Loss:  0.09780171662569045 , Time: 10164.19078040123 s\n",
      "Batch:  650 , l1 Loss:  0.09854589477181434 , Time: 10176.235285043716 s\n",
      "Batch:  660 , l1 Loss:  0.09785757809877396 , Time: 10188.277972459793 s\n",
      "Batch:  670 , l1 Loss:  0.09739268347620963 , Time: 10200.286441087723 s\n",
      "Batch:  680 , l1 Loss:  0.09758904129266739 , Time: 10212.18394613266 s\n",
      "Batch:  690 , l1 Loss:  0.09803315699100494 , Time: 10224.243000507355 s\n",
      "Batch:  700 , l1 Loss:  0.0976026326417923 , Time: 10236.314462900162 s\n",
      "Batch:  710 , l1 Loss:  0.09964964315295219 , Time: 10248.423426866531 s\n",
      "Batch:  720 , l1 Loss:  0.0984397478401661 , Time: 10260.479736804962 s\n",
      "Batch:  730 , l1 Loss:  0.0980321653187275 , Time: 10272.56367278099 s\n",
      "Batch:  740 , l1 Loss:  0.09875164702534675 , Time: 10284.645486831665 s\n",
      "Batch:  750 , l1 Loss:  0.09867424890398979 , Time: 10296.721538066864 s\n",
      "Batch:  760 , l1 Loss:  0.09978448003530502 , Time: 10308.769242048264 s\n",
      "Batch:  770 , l1 Loss:  0.0989908143877983 , Time: 10320.839846849442 s\n",
      "Batch:  780 , l1 Loss:  0.09943957775831222 , Time: 10332.930053472519 s\n",
      "Batch:  790 , l1 Loss:  0.09800448343157768 , Time: 10344.830823659897 s\n",
      "Batch:  800 , l1 Loss:  0.09779255390167237 , Time: 10356.574172019958 s\n",
      "Batch:  810 , l1 Loss:  0.09851291105151176 , Time: 10368.34739112854 s\n",
      "Batch:  820 , l1 Loss:  0.09757475182414055 , Time: 10380.04405617714 s\n",
      "Batch:  830 , l1 Loss:  0.09924406260251999 , Time: 10391.77199792862 s\n",
      "Batch:  840 , l1 Loss:  0.09814645051956176 , Time: 10403.50124168396 s\n",
      "Batch:  850 , l1 Loss:  0.09772333279252052 , Time: 10415.261667251587 s\n",
      "Batch:  860 , l1 Loss:  0.09842536970973015 , Time: 10427.088119983673 s\n",
      "Batch:  870 , l1 Loss:  0.0990055188536644 , Time: 10438.893765687943 s\n",
      "Batch:  880 , l1 Loss:  0.09868284612894059 , Time: 10450.764071941376 s\n",
      "Batch:  890 , l1 Loss:  0.09929248467087745 , Time: 10462.592286348343 s\n",
      "Batch:  900 , l1 Loss:  0.09794533625245094 , Time: 10474.435289859772 s\n",
      "Batch:  910 , l1 Loss:  0.09823917672038078 , Time: 10486.282326936722 s\n",
      "Batch:  920 , l1 Loss:  0.09921506196260452 , Time: 10498.091738700867 s\n",
      "Batch:  930 , l1 Loss:  0.09879145547747611 , Time: 10509.921195983887 s\n",
      "Batch:  940 , l1 Loss:  0.0981733426451683 , Time: 10521.780796289444 s\n",
      "Batch:  950 , l1 Loss:  0.09775430336594582 , Time: 10533.62045454979 s\n",
      "Batch:  960 , l1 Loss:  0.09845770299434661 , Time: 10545.455203294754 s\n",
      "Batch:  970 , l1 Loss:  0.09832083061337471 , Time: 10557.31967329979 s\n",
      "Batch:  980 , l1 Loss:  0.09884038865566254 , Time: 10569.18854522705 s\n",
      "Batch:  990 , l1 Loss:  0.09823361858725548 , Time: 10581.177842378616 s\n",
      "Batch:  1000 , l1 Loss:  0.09869271591305732 , Time: 10593.450437545776 s\n",
      "Batch:  1010 , l1 Loss:  0.09860237687826157 , Time: 10605.739811182022 s\n",
      "Batch:  1020 , l1 Loss:  0.09955522045493126 , Time: 10617.91497850418 s\n",
      "Batch:  1030 , l1 Loss:  0.09813857823610306 , Time: 10629.919828891754 s\n",
      "Batch:  1040 , l1 Loss:  0.09852679595351219 , Time: 10642.127697467804 s\n",
      "Batch:  1050 , l1 Loss:  0.09776352792978286 , Time: 10654.301663637161 s\n",
      "Batch:  1060 , l1 Loss:  0.09871198385953903 , Time: 10666.465388536453 s\n",
      "Batch:  1070 , l1 Loss:  0.09817937016487122 , Time: 10678.614371299744 s\n",
      "Batch:  1080 , l1 Loss:  0.09803119376301765 , Time: 10690.822316408157 s\n",
      "Batch:  1090 , l1 Loss:  0.09870912060141564 , Time: 10702.976752281189 s\n",
      "Batch:  1100 , l1 Loss:  0.09873850420117378 , Time: 10715.110083818436 s\n",
      "Batch:  1110 , l1 Loss:  0.09764866307377815 , Time: 10727.251690387726 s\n",
      "Batch:  1120 , l1 Loss:  0.09824406132102012 , Time: 10739.362841844559 s\n",
      "Batch:  1130 , l1 Loss:  0.09824459478259087 , Time: 10751.515084266663 s\n",
      "Batch:  1140 , l1 Loss:  0.09823024719953537 , Time: 10763.638659000397 s\n",
      "Batch:  1150 , l1 Loss:  0.09811936393380165 , Time: 10775.732155561447 s\n",
      "Batch:  1160 , l1 Loss:  0.09825282618403434 , Time: 10787.868250608444 s\n",
      "Batch:  1170 , l1 Loss:  0.09740207120776176 , Time: 10799.98763537407 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  1180 , l1 Loss:  0.09789760708808899 , Time: 10812.03312087059 s\n",
      "Batch:  1190 , l1 Loss:  0.09823333099484444 , Time: 10824.139057159424 s\n",
      "Batch:  1200 , l1 Loss:  0.09769949689507484 , Time: 10836.229548215866 s\n",
      "Batch:  1210 , l1 Loss:  0.09922126531600953 , Time: 10848.379180908203 s\n",
      "Batch:  1220 , l1 Loss:  0.09796006456017495 , Time: 10860.350600719452 s\n",
      "Batch:  1230 , l1 Loss:  0.09897981211543083 , Time: 10872.093367099762 s\n",
      "Batch:  1240 , l1 Loss:  0.09829192087054253 , Time: 10883.837620735168 s\n",
      "Batch:  1250 , l1 Loss:  0.09819738939404488 , Time: 10895.587580442429 s\n",
      "Batch:  1260 , l1 Loss:  0.09759861454367638 , Time: 10907.338278770447 s\n",
      "Batch:  1270 , l1 Loss:  0.097577565908432 , Time: 10919.168296813965 s\n",
      "Batch:  1280 , l1 Loss:  0.09819739982485771 , Time: 10930.950378894806 s\n",
      "Batch:  1290 , l1 Loss:  0.09732119217514992 , Time: 10942.74713563919 s\n",
      "Batch:  1300 , l1 Loss:  0.09879650101065636 , Time: 10954.563338756561 s\n",
      "Batch:  1310 , l1 Loss:  0.09709429889917373 , Time: 10966.447535276413 s\n",
      "Batch:  1320 , l1 Loss:  0.09802358075976372 , Time: 10978.263490915298 s\n",
      "Batch:  1330 , l1 Loss:  0.09788955450057983 , Time: 10990.13673710823 s\n",
      "Batch:  1340 , l1 Loss:  0.09843359142541885 , Time: 11002.007468700409 s\n",
      "Batch:  1350 , l1 Loss:  0.09885508343577384 , Time: 11013.851547241211 s\n",
      "Batch:  1360 , l1 Loss:  0.09891552329063416 , Time: 11025.652418613434 s\n",
      "Batch:  1370 , l1 Loss:  0.09927730485796929 , Time: 11037.491805553436 s\n",
      "Batch:  1380 , l1 Loss:  0.09835951700806618 , Time: 11049.317150592804 s\n",
      "Batch:  1390 , l1 Loss:  0.09873266741633416 , Time: 11061.184633493423 s\n",
      "Batch:  1400 , l1 Loss:  0.0977391928434372 , Time: 11073.118296384811 s\n",
      "Batch:  1410 , l1 Loss:  0.09887544140219688 , Time: 11085.068676233292 s\n",
      "Batch:  1420 , l1 Loss:  0.0990785650908947 , Time: 11096.948446273804 s\n",
      "Batch:  1430 , l1 Loss:  0.09960927814245224 , Time: 11108.840709209442 s\n",
      "Batch:  1440 , l1 Loss:  0.0980347901582718 , Time: 11120.791947364807 s\n",
      "Batch:  1450 , l1 Loss:  0.0984075479209423 , Time: 11132.662730932236 s\n",
      "Batch:  1460 , l1 Loss:  0.09900409206748009 , Time: 11144.605096578598 s\n",
      "Batch:  1470 , l1 Loss:  0.09862043485045432 , Time: 11156.517756700516 s\n",
      "Batch:  1480 , l1 Loss:  0.10052722841501235 , Time: 11168.441978931427 s\n",
      "Batch:  1490 , l1 Loss:  0.09794129058718681 , Time: 11180.333961725235 s\n",
      "Batch:  1500 , l1 Loss:  0.09991230815649033 , Time: 11192.217091083527 s\n",
      "Batch:  1510 , l1 Loss:  0.0978306233882904 , Time: 11204.165577888489 s\n",
      "Batch:  1520 , l1 Loss:  0.09805369451642036 , Time: 11216.090712308884 s\n",
      "Batch:  1530 , l1 Loss:  0.09893182665109634 , Time: 11228.001757383347 s\n",
      "Batch:  1540 , l1 Loss:  0.09863674044609069 , Time: 11239.892259836197 s\n",
      "Batch:  1550 , l1 Loss:  0.09769463315606117 , Time: 11251.832678318024 s\n",
      "Batch:  1560 , l1 Loss:  0.09867383018136025 , Time: 11263.737559318542 s\n",
      "Batch:  1570 , l1 Loss:  0.09827550128102303 , Time: 11275.654436588287 s\n",
      "Batch:  1580 , l1 Loss:  0.09930907562375069 , Time: 11287.560346126556 s\n",
      "Batch:  1590 , l1 Loss:  0.09895510450005532 , Time: 11299.446263551712 s\n",
      "Batch:  1600 , l1 Loss:  0.0978143185377121 , Time: 11311.515384674072 s\n",
      "Batch:  1610 , l1 Loss:  0.09817693829536438 , Time: 11323.891469955444 s\n",
      "Batch:  1620 , l1 Loss:  0.09833425357937813 , Time: 11336.152440786362 s\n",
      "Batch:  1630 , l1 Loss:  0.09824216738343239 , Time: 11348.36925983429 s\n",
      "Batch:  1640 , l1 Loss:  0.09830269291996956 , Time: 11360.594878435135 s\n",
      "Batch:  1650 , l1 Loss:  0.09779517576098443 , Time: 11372.80879020691 s\n",
      "Batch:  1660 , l1 Loss:  0.09904125109314918 , Time: 11385.022987604141 s\n",
      "Batch:  1670 , l1 Loss:  0.09874761775135994 , Time: 11397.196669340134 s\n",
      "Batch:  1680 , l1 Loss:  0.09781772419810295 , Time: 11409.371693134308 s\n",
      "Batch:  1690 , l1 Loss:  0.09729803204536439 , Time: 11421.477249622345 s\n",
      "Batch:  1700 , l1 Loss:  0.09830960780382156 , Time: 11433.563318490982 s\n",
      "Batch:  1710 , l1 Loss:  0.098166224360466 , Time: 11445.746292829514 s\n",
      "Batch:  1720 , l1 Loss:  0.09738840162754059 , Time: 11457.879519224167 s\n",
      "Batch:  1730 , l1 Loss:  0.09839554578065872 , Time: 11470.032189130783 s\n",
      "Batch:  1740 , l1 Loss:  0.09801022484898567 , Time: 11482.187811851501 s\n",
      "Batch:  1750 , l1 Loss:  0.09808772876858711 , Time: 11494.366973400116 s\n",
      "Batch:  1760 , l1 Loss:  0.09829536601901054 , Time: 11506.500715732574 s\n",
      "Batch:  1770 , l1 Loss:  0.097396170347929 , Time: 11518.59857225418 s\n",
      "Batch:  1780 , l1 Loss:  0.09725062176585197 , Time: 11530.647203445435 s\n",
      "Batch:  1790 , l1 Loss:  0.09919888153672218 , Time: 11542.626465797424 s\n",
      "Batch:  1800 , l1 Loss:  0.09829576388001442 , Time: 11554.335468053818 s\n",
      "Batch:  1810 , l1 Loss:  0.0979065552353859 , Time: 11566.109137296677 s\n",
      "Batch:  1820 , l1 Loss:  0.09778697937726974 , Time: 11577.81941819191 s\n",
      "Batch:  1830 , l1 Loss:  0.09738724008202553 , Time: 11589.598546504974 s\n",
      "Batch:  1840 , l1 Loss:  0.09734902307391166 , Time: 11601.392184019089 s\n",
      "Batch:  1850 , l1 Loss:  0.09792386069893837 , Time: 11613.208749771118 s\n",
      "Batch:  1860 , l1 Loss:  0.09768610149621963 , Time: 11625.030455350876 s\n",
      "Batch:  1870 , l1 Loss:  0.0991970494389534 , Time: 11636.862213373184 s\n",
      "Batch:  1880 , l1 Loss:  0.09877971857786179 , Time: 11648.667286634445 s\n",
      "Batch:  1890 , l1 Loss:  0.09898657724261284 , Time: 11660.499429941177 s\n",
      "Batch:  1900 , l1 Loss:  0.09775130078196526 , Time: 11672.372855424881 s\n",
      "Batch:  1910 , l1 Loss:  0.09764869958162307 , Time: 11684.26433968544 s\n",
      "Batch:  1920 , l1 Loss:  0.0987678349018097 , Time: 11696.098546266556 s\n",
      "Batch:  1930 , l1 Loss:  0.09801131933927536 , Time: 11707.995116472244 s\n",
      "Batch:  1940 , l1 Loss:  0.09861145317554473 , Time: 11719.913289785385 s\n",
      "Batch:  1950 , l1 Loss:  0.09829891100525856 , Time: 11731.815687656403 s\n",
      "Batch:  1960 , l1 Loss:  0.09859552159905434 , Time: 11743.701995372772 s\n",
      "Batch:  1970 , l1 Loss:  0.09822407066822052 , Time: 11755.593732595444 s\n",
      "Batch:  1980 , l1 Loss:  0.09795176908373833 , Time: 11767.500020503998 s\n",
      "Batch:  1990 , l1 Loss:  0.09894826486706734 , Time: 11779.375767469406 s\n",
      "Batch:  2000 , l1 Loss:  0.09820131063461304 , Time: 11791.266377210617 s\n",
      "Batch:  2010 , l1 Loss:  0.09741067290306091 , Time: 11803.238338947296 s\n",
      "Batch:  2020 , l1 Loss:  0.09869558364152908 , Time: 11815.149086236954 s\n",
      "Batch:  2030 , l1 Loss:  0.09772013798356056 , Time: 11826.981678247452 s\n",
      "Batch:  2040 , l1 Loss:  0.09742494076490402 , Time: 11838.890450716019 s\n",
      "Batch:  2050 , l1 Loss:  0.09753221794962882 , Time: 11850.809724330902 s\n",
      "Batch:  2060 , l1 Loss:  0.09872986748814583 , Time: 11862.661056756973 s\n",
      "Batch:  2070 , l1 Loss:  0.09847962036728859 , Time: 11874.5252327919 s\n",
      "Batch:  2080 , l1 Loss:  0.09840013310313225 , Time: 11886.461941480637 s\n",
      "Batch:  2090 , l1 Loss:  0.09768805578351021 , Time: 11898.315855026245 s\n",
      "Batch:  2100 , l1 Loss:  0.09783668667078019 , Time: 11910.228957891464 s\n",
      "Batch:  2110 , l1 Loss:  0.09931639060378075 , Time: 11922.144093513489 s\n",
      "Batch:  2120 , l1 Loss:  0.09823037385940551 , Time: 11934.028854131699 s\n",
      "Batch:  2130 , l1 Loss:  0.09796089604496956 , Time: 11945.904114484787 s\n",
      "Batch:  2140 , l1 Loss:  0.09858290702104569 , Time: 11957.772067308426 s\n",
      "Batch:  2150 , l1 Loss:  0.09777847602963448 , Time: 11969.70314359665 s\n",
      "Batch:  2160 , l1 Loss:  0.09741735085844994 , Time: 11981.611913919449 s\n",
      "Batch:  2170 , l1 Loss:  0.09878605157136917 , Time: 11993.546446800232 s\n",
      "Batch:  2180 , l1 Loss:  0.09889321625232697 , Time: 12005.493335485458 s\n",
      "Batch:  2190 , l1 Loss:  0.09812453910708427 , Time: 12017.405094623566 s\n",
      "Batch:  2200 , l1 Loss:  0.09777751788496972 , Time: 12029.323491096497 s\n",
      "Batch:  2210 , l1 Loss:  0.0983241319656372 , Time: 12041.25369644165 s\n",
      "Batch:  2220 , l1 Loss:  0.09804044216871262 , Time: 12053.145313978195 s\n",
      "Batch:  2230 , l1 Loss:  0.09797882586717606 , Time: 12065.006848573685 s\n",
      "Batch:  2240 , l1 Loss:  0.09839770272374153 , Time: 12076.916632413864 s\n",
      "Batch:  2250 , l1 Loss:  0.09846013858914375 , Time: 12088.903775930405 s\n",
      "Batch:  2260 , l1 Loss:  0.09877057746052742 , Time: 12100.815469026566 s\n",
      "Batch:  2270 , l1 Loss:  0.0980736643075943 , Time: 12112.8023250103 s\n",
      "Batch:  2280 , l1 Loss:  0.09834314957261085 , Time: 12124.750055551529 s\n",
      "Batch:  2290 , l1 Loss:  0.09826588705182075 , Time: 12136.647678136826 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  2300 , l1 Loss:  0.09856067821383477 , Time: 12148.551580190659 s\n",
      "Batch:  2310 , l1 Loss:  0.09846526831388473 , Time: 12160.525727510452 s\n",
      "Batch:  2320 , l1 Loss:  0.09758670702576637 , Time: 12172.472474575043 s\n",
      "Batch:  2330 , l1 Loss:  0.09854372516274452 , Time: 12184.374491930008 s\n",
      "Batch:  2340 , l1 Loss:  0.09913661554455758 , Time: 12196.30502486229 s\n",
      "Batch:  2350 , l1 Loss:  0.09844968467950821 , Time: 12208.21138381958 s\n",
      "Batch:  2360 , l1 Loss:  0.09831609502434731 , Time: 12220.16304898262 s\n",
      "Batch:  2370 , l1 Loss:  0.09917841255664825 , Time: 12232.08529829979 s\n",
      "Batch:  2380 , l1 Loss:  0.09924081116914749 , Time: 12244.026213169098 s\n",
      "Batch:  2390 , l1 Loss:  0.0991397425532341 , Time: 12255.96628832817 s\n",
      "Batch:  2400 , l1 Loss:  0.09796633720397949 , Time: 12267.872453212738 s\n",
      "Batch:  2410 , l1 Loss:  0.09789662137627601 , Time: 12279.825081825256 s\n",
      "Batch:  2420 , l1 Loss:  0.09792011082172394 , Time: 12291.795195817947 s\n",
      "Batch:  2430 , l1 Loss:  0.09775489196181297 , Time: 12303.687405824661 s\n",
      "Batch:  2440 , l1 Loss:  0.09823366850614548 , Time: 12315.600113868713 s\n",
      "Batch:  2450 , l1 Loss:  0.09746184125542641 , Time: 12327.53543996811 s\n",
      "Batch:  2460 , l1 Loss:  0.09811702445149421 , Time: 12339.439069747925 s\n",
      "Batch:  2470 , l1 Loss:  0.09892183691263198 , Time: 12351.383372306824 s\n",
      "Batch:  2480 , l1 Loss:  0.09803114384412766 , Time: 12363.321210384369 s\n",
      "Batch:  2490 , l1 Loss:  0.09802814349532127 , Time: 12375.286437511444 s\n",
      "Batch:  2500 , l1 Loss:  0.09842828959226609 , Time: 12387.276814699173 s\n",
      "Batch:  2510 , l1 Loss:  0.09845899119973182 , Time: 12399.270385503769 s\n",
      "Batch:  2520 , l1 Loss:  0.09864335730671883 , Time: 12411.261530160904 s\n",
      "Batch:  2530 , l1 Loss:  0.09824779257178307 , Time: 12423.530202388763 s\n",
      "Batch:  2540 , l1 Loss:  0.0987561896443367 , Time: 12435.843601942062 s\n",
      "Batch:  2550 , l1 Loss:  0.0984489344060421 , Time: 12448.13997220993 s\n",
      "Batch:  2560 , l1 Loss:  0.09778034314513206 , Time: 12460.367827653885 s\n",
      "Batch:  2570 , l1 Loss:  0.09791098684072494 , Time: 12472.593761444092 s\n",
      "Batch:  2580 , l1 Loss:  0.0974844790995121 , Time: 12484.828874588013 s\n",
      "Batch:  2590 , l1 Loss:  0.09761808142066002 , Time: 12496.987019062042 s\n",
      "Batch:  2600 , l1 Loss:  0.09781016111373901 , Time: 12509.122235298157 s\n",
      "Batch:  2610 , l1 Loss:  0.0973922461271286 , Time: 12521.315868616104 s\n",
      "Batch:  2620 , l1 Loss:  0.09867199584841728 , Time: 12533.412063598633 s\n",
      "Batch:  2630 , l1 Loss:  0.09754386693239211 , Time: 12545.367226362228 s\n",
      "Epoch:  3 , l1 loss:  0.09838743642787184\n",
      "Epoch:  4\n",
      "Batch:  10 , l1 Loss:  0.09796105122024362 , Time: 12562.365471124649 s\n",
      "Batch:  20 , l1 Loss:  0.09715210869908333 , Time: 12574.167923927307 s\n",
      "Batch:  30 , l1 Loss:  0.09805322736501694 , Time: 12585.992755174637 s\n",
      "Batch:  40 , l1 Loss:  0.0976044163107872 , Time: 12597.815084457397 s\n",
      "Batch:  50 , l1 Loss:  0.09694279357790947 , Time: 12609.612256526947 s\n",
      "Batch:  60 , l1 Loss:  0.098055899143219 , Time: 12621.43343615532 s\n",
      "Batch:  70 , l1 Loss:  0.09736699461936951 , Time: 12633.246374845505 s\n",
      "Batch:  80 , l1 Loss:  0.09745746552944183 , Time: 12645.097959041595 s\n",
      "Batch:  90 , l1 Loss:  0.09699137806892395 , Time: 12656.939556360245 s\n",
      "Batch:  100 , l1 Loss:  0.09723684340715408 , Time: 12668.75079536438 s\n",
      "Batch:  110 , l1 Loss:  0.09847589284181595 , Time: 12680.576241731644 s\n",
      "Batch:  120 , l1 Loss:  0.09768727496266365 , Time: 12692.398743391037 s\n",
      "Batch:  130 , l1 Loss:  0.09756828248500823 , Time: 12704.218315124512 s\n",
      "Batch:  140 , l1 Loss:  0.09756391122937202 , Time: 12716.04095172882 s\n",
      "Batch:  150 , l1 Loss:  0.09835923910140991 , Time: 12727.866256475449 s\n",
      "Batch:  160 , l1 Loss:  0.09817877635359765 , Time: 12739.70205950737 s\n",
      "Batch:  170 , l1 Loss:  0.09902090951800346 , Time: 12751.489137411118 s\n",
      "Batch:  180 , l1 Loss:  0.0988576240837574 , Time: 12763.317048311234 s\n",
      "Batch:  190 , l1 Loss:  0.09795239716768264 , Time: 12775.129221916199 s\n",
      "Batch:  200 , l1 Loss:  0.09710087850689889 , Time: 12787.158332109451 s\n",
      "Batch:  210 , l1 Loss:  0.09776555672287941 , Time: 12799.232119560242 s\n",
      "Batch:  220 , l1 Loss:  0.09739949107170105 , Time: 12811.423541784286 s\n",
      "Batch:  230 , l1 Loss:  0.09810882210731506 , Time: 12823.476171731949 s\n",
      "Batch:  240 , l1 Loss:  0.09684401974081994 , Time: 12835.5372672081 s\n",
      "Batch:  250 , l1 Loss:  0.0984300546348095 , Time: 12847.58182668686 s\n",
      "Batch:  260 , l1 Loss:  0.09808385446667671 , Time: 12859.592443466187 s\n",
      "Batch:  270 , l1 Loss:  0.09903832748532296 , Time: 12871.59592461586 s\n",
      "Batch:  280 , l1 Loss:  0.09740413725376129 , Time: 12883.66866850853 s\n",
      "Batch:  290 , l1 Loss:  0.09717560559511185 , Time: 12895.68467259407 s\n",
      "Batch:  300 , l1 Loss:  0.09741439670324326 , Time: 12907.685569047928 s\n",
      "Batch:  310 , l1 Loss:  0.09845339134335518 , Time: 12919.683275461197 s\n",
      "Batch:  320 , l1 Loss:  0.09928026348352433 , Time: 12931.683370351791 s\n",
      "Batch:  330 , l1 Loss:  0.09826832190155983 , Time: 12943.67768406868 s\n",
      "Batch:  340 , l1 Loss:  0.09755106121301652 , Time: 12955.679279088974 s\n",
      "Batch:  350 , l1 Loss:  0.09807281568646431 , Time: 12967.69056224823 s\n",
      "Batch:  360 , l1 Loss:  0.097750823199749 , Time: 12979.690237045288 s\n",
      "Batch:  370 , l1 Loss:  0.09708394855260849 , Time: 12991.703700304031 s\n",
      "Batch:  380 , l1 Loss:  0.09752117544412613 , Time: 13003.723903894424 s\n",
      "Batch:  390 , l1 Loss:  0.09811112061142921 , Time: 13015.708220481873 s\n",
      "Batch:  400 , l1 Loss:  0.09808147251605988 , Time: 13027.688734531403 s\n",
      "Batch:  410 , l1 Loss:  0.096891950070858 , Time: 13039.641903162003 s\n",
      "Batch:  420 , l1 Loss:  0.09708905071020127 , Time: 13051.603676319122 s\n",
      "Batch:  430 , l1 Loss:  0.09661718979477882 , Time: 13063.587813854218 s\n",
      "Batch:  440 , l1 Loss:  0.09768010377883911 , Time: 13075.551726579666 s\n",
      "Batch:  450 , l1 Loss:  0.09727138578891754 , Time: 13087.551811695099 s\n",
      "Batch:  460 , l1 Loss:  0.09774812385439872 , Time: 13099.560852766037 s\n",
      "Batch:  470 , l1 Loss:  0.09783672019839287 , Time: 13111.536166906357 s\n",
      "Batch:  480 , l1 Loss:  0.09760093316435814 , Time: 13123.547828674316 s\n",
      "Batch:  490 , l1 Loss:  0.0973567321896553 , Time: 13135.302482128143 s\n",
      "Batch:  500 , l1 Loss:  0.09712024703621865 , Time: 13147.106259584427 s\n",
      "Batch:  510 , l1 Loss:  0.09799202159047127 , Time: 13158.86650109291 s\n",
      "Batch:  520 , l1 Loss:  0.09751272723078727 , Time: 13170.627847671509 s\n",
      "Batch:  530 , l1 Loss:  0.09770157113671303 , Time: 13182.405434846878 s\n",
      "Batch:  540 , l1 Loss:  0.09764904752373696 , Time: 13194.202211380005 s\n",
      "Batch:  550 , l1 Loss:  0.098204255849123 , Time: 13205.993706703186 s\n",
      "Batch:  560 , l1 Loss:  0.09853533282876015 , Time: 13217.822013378143 s\n",
      "Batch:  570 , l1 Loss:  0.09795908406376838 , Time: 13229.644204378128 s\n",
      "Batch:  580 , l1 Loss:  0.09772497937083244 , Time: 13241.503487110138 s\n",
      "Batch:  590 , l1 Loss:  0.0980272077023983 , Time: 13253.354831933975 s\n",
      "Batch:  600 , l1 Loss:  0.09795616194605827 , Time: 13265.195328474045 s\n",
      "Batch:  610 , l1 Loss:  0.09802667498588562 , Time: 13277.015716552734 s\n",
      "Batch:  620 , l1 Loss:  0.09797055274248123 , Time: 13288.846789360046 s\n",
      "Batch:  630 , l1 Loss:  0.09797589033842087 , Time: 13300.682600975037 s\n",
      "Batch:  640 , l1 Loss:  0.09724316000938416 , Time: 13312.531826972961 s\n",
      "Batch:  650 , l1 Loss:  0.09702847972512245 , Time: 13324.372669935226 s\n",
      "Batch:  660 , l1 Loss:  0.0969003289937973 , Time: 13336.244966983795 s\n",
      "Batch:  670 , l1 Loss:  0.09753325060009957 , Time: 13347.979228019714 s\n",
      "Batch:  680 , l1 Loss:  0.0981641061604023 , Time: 13359.745131492615 s\n",
      "Batch:  690 , l1 Loss:  0.09714562073349953 , Time: 13371.506892442703 s\n",
      "Batch:  700 , l1 Loss:  0.09858649447560311 , Time: 13383.262261390686 s\n",
      "Batch:  710 , l1 Loss:  0.09810768812894821 , Time: 13395.00809621811 s\n",
      "Batch:  720 , l1 Loss:  0.0972254902124405 , Time: 13406.777159452438 s\n",
      "Batch:  730 , l1 Loss:  0.09835346788167953 , Time: 13418.528786420822 s\n",
      "Batch:  740 , l1 Loss:  0.09706878438591957 , Time: 13430.285502910614 s\n",
      "Batch:  750 , l1 Loss:  0.09708530455827713 , Time: 13442.066765785217 s\n",
      "Batch:  760 , l1 Loss:  0.09715372398495674 , Time: 13453.85254740715 s\n",
      "Batch:  770 , l1 Loss:  0.09756754711270332 , Time: 13465.64025759697 s\n",
      "Batch:  780 , l1 Loss:  0.09789796769618989 , Time: 13477.434278726578 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  790 , l1 Loss:  0.09883271604776382 , Time: 13489.263092041016 s\n",
      "Batch:  800 , l1 Loss:  0.0975725919008255 , Time: 13501.032339572906 s\n",
      "Batch:  810 , l1 Loss:  0.09833245128393173 , Time: 13512.805270671844 s\n",
      "Batch:  820 , l1 Loss:  0.09795412868261337 , Time: 13524.571369409561 s\n",
      "Batch:  830 , l1 Loss:  0.09727412834763527 , Time: 13536.39691567421 s\n",
      "Batch:  840 , l1 Loss:  0.09787286669015885 , Time: 13548.234284162521 s\n",
      "Batch:  850 , l1 Loss:  0.097813730686903 , Time: 13560.12653017044 s\n",
      "Batch:  860 , l1 Loss:  0.09710708633065224 , Time: 13572.053849220276 s\n",
      "Batch:  870 , l1 Loss:  0.09699229747056962 , Time: 13583.990653276443 s\n",
      "Batch:  880 , l1 Loss:  0.09822850301861763 , Time: 13595.8990213871 s\n",
      "Batch:  890 , l1 Loss:  0.09822874665260314 , Time: 13607.831624507904 s\n",
      "Batch:  900 , l1 Loss:  0.09749066010117531 , Time: 13619.743229866028 s\n",
      "Batch:  910 , l1 Loss:  0.09811577200889587 , Time: 13631.670124053955 s\n",
      "Batch:  920 , l1 Loss:  0.09783555418252946 , Time: 13643.588313817978 s\n",
      "Batch:  930 , l1 Loss:  0.09811850115656853 , Time: 13655.51513338089 s\n",
      "Batch:  940 , l1 Loss:  0.09734036698937416 , Time: 13667.35476231575 s\n",
      "Batch:  950 , l1 Loss:  0.09873192086815834 , Time: 13679.183916568756 s\n",
      "Batch:  960 , l1 Loss:  0.09717471823096276 , Time: 13691.043746471405 s\n",
      "Batch:  970 , l1 Loss:  0.09778183624148369 , Time: 13702.898743391037 s\n",
      "Batch:  980 , l1 Loss:  0.09778385236859322 , Time: 13714.717883348465 s\n",
      "Batch:  990 , l1 Loss:  0.09788148328661919 , Time: 13726.604863882065 s\n",
      "Batch:  1000 , l1 Loss:  0.09662853181362152 , Time: 13738.43656873703 s\n",
      "Batch:  1010 , l1 Loss:  0.0976234070956707 , Time: 13750.251782655716 s\n",
      "Batch:  1020 , l1 Loss:  0.09747330397367478 , Time: 13762.101863145828 s\n",
      "Batch:  1030 , l1 Loss:  0.09764606431126595 , Time: 13773.93517279625 s\n",
      "Batch:  1040 , l1 Loss:  0.09805925637483597 , Time: 13785.78817486763 s\n",
      "Batch:  1050 , l1 Loss:  0.09732747301459313 , Time: 13797.650109291077 s\n",
      "Batch:  1060 , l1 Loss:  0.09745839610695839 , Time: 13809.485501527786 s\n",
      "Batch:  1070 , l1 Loss:  0.09810462668538093 , Time: 13821.343859434128 s\n",
      "Batch:  1080 , l1 Loss:  0.09713251665234565 , Time: 13833.20369887352 s\n",
      "Batch:  1090 , l1 Loss:  0.09800300747156143 , Time: 13845.063347578049 s\n",
      "Batch:  1100 , l1 Loss:  0.09845237508416176 , Time: 13856.952443122864 s\n",
      "Batch:  1110 , l1 Loss:  0.09756108075380325 , Time: 13868.787554264069 s\n",
      "Batch:  1120 , l1 Loss:  0.09716082140803337 , Time: 13880.637925386429 s\n",
      "Batch:  1130 , l1 Loss:  0.09742105156183242 , Time: 13892.513768911362 s\n",
      "Batch:  1140 , l1 Loss:  0.09816383868455887 , Time: 13904.3845911026 s\n",
      "Batch:  1150 , l1 Loss:  0.0981180228292942 , Time: 13916.254763364792 s\n",
      "Batch:  1160 , l1 Loss:  0.09879403188824654 , Time: 13928.112555265427 s\n",
      "Batch:  1170 , l1 Loss:  0.09712929949164391 , Time: 13940.01031756401 s\n",
      "Batch:  1180 , l1 Loss:  0.09690101519227028 , Time: 13951.898651123047 s\n",
      "Batch:  1190 , l1 Loss:  0.0984862931072712 , Time: 13963.80108499527 s\n",
      "Batch:  1200 , l1 Loss:  0.09757291302084922 , Time: 13975.673528432846 s\n",
      "Batch:  1210 , l1 Loss:  0.09702030494809151 , Time: 13987.578165531158 s\n",
      "Batch:  1220 , l1 Loss:  0.09704108387231827 , Time: 13999.451153039932 s\n",
      "Batch:  1230 , l1 Loss:  0.09748383462429047 , Time: 14011.369873285294 s\n",
      "Batch:  1240 , l1 Loss:  0.09832650721073151 , Time: 14023.240060806274 s\n",
      "Batch:  1250 , l1 Loss:  0.0976934239268303 , Time: 14035.150363445282 s\n",
      "Batch:  1260 , l1 Loss:  0.09763029739260673 , Time: 14047.064816951752 s\n",
      "Batch:  1270 , l1 Loss:  0.0968853659927845 , Time: 14058.980525970459 s\n",
      "Batch:  1280 , l1 Loss:  0.0980487547814846 , Time: 14070.886486768723 s\n",
      "Batch:  1290 , l1 Loss:  0.09809102416038513 , Time: 14082.858968496323 s\n",
      "Batch:  1300 , l1 Loss:  0.09678215384483338 , Time: 14094.791063785553 s\n",
      "Batch:  1310 , l1 Loss:  0.09745198637247085 , Time: 14106.70177936554 s\n",
      "Batch:  1320 , l1 Loss:  0.09748364165425301 , Time: 14118.635805130005 s\n",
      "Batch:  1330 , l1 Loss:  0.09757042378187179 , Time: 14130.547616243362 s\n",
      "Batch:  1340 , l1 Loss:  0.096590656042099 , Time: 14142.461389303207 s\n",
      "Batch:  1350 , l1 Loss:  0.09724080935120583 , Time: 14154.3742582798 s\n",
      "Batch:  1360 , l1 Loss:  0.09751448184251785 , Time: 14166.287984609604 s\n",
      "Batch:  1370 , l1 Loss:  0.097960364818573 , Time: 14178.20385313034 s\n",
      "Batch:  1380 , l1 Loss:  0.09834769144654273 , Time: 14190.0766685009 s\n",
      "Batch:  1390 , l1 Loss:  0.09791593179106713 , Time: 14201.992131471634 s\n",
      "Batch:  1400 , l1 Loss:  0.09714806526899337 , Time: 14213.900384902954 s\n",
      "Batch:  1410 , l1 Loss:  0.0972310334444046 , Time: 14225.796672344208 s\n",
      "Batch:  1420 , l1 Loss:  0.09774600937962533 , Time: 14237.70683503151 s\n",
      "Batch:  1430 , l1 Loss:  0.09785810858011246 , Time: 14249.59909749031 s\n",
      "Batch:  1440 , l1 Loss:  0.09710844233632088 , Time: 14261.513181686401 s\n",
      "Batch:  1450 , l1 Loss:  0.09798073619604111 , Time: 14273.429280519485 s\n",
      "Batch:  1460 , l1 Loss:  0.09752265438437462 , Time: 14285.363298892975 s\n",
      "Batch:  1470 , l1 Loss:  0.09704194068908692 , Time: 14297.287839889526 s\n",
      "Batch:  1480 , l1 Loss:  0.09754014387726784 , Time: 14309.19464635849 s\n",
      "Batch:  1490 , l1 Loss:  0.09812291786074638 , Time: 14321.14423584938 s\n",
      "Batch:  1500 , l1 Loss:  0.0974484845995903 , Time: 14333.107447385788 s\n",
      "Batch:  1510 , l1 Loss:  0.09737908095121384 , Time: 14345.04903960228 s\n",
      "Batch:  1520 , l1 Loss:  0.09773973003029823 , Time: 14356.964420557022 s\n",
      "Batch:  1530 , l1 Loss:  0.0970859557390213 , Time: 14368.8935713768 s\n",
      "Batch:  1540 , l1 Loss:  0.09707400351762771 , Time: 14380.830761909485 s\n",
      "Batch:  1550 , l1 Loss:  0.09717095419764518 , Time: 14392.722575426102 s\n",
      "Batch:  1560 , l1 Loss:  0.09705058038234711 , Time: 14404.633716583252 s\n",
      "Batch:  1570 , l1 Loss:  0.09781602174043655 , Time: 14416.587959051132 s\n",
      "Batch:  1580 , l1 Loss:  0.09754824042320251 , Time: 14428.50878238678 s\n",
      "Batch:  1590 , l1 Loss:  0.09804042130708694 , Time: 14440.484528064728 s\n",
      "Batch:  1600 , l1 Loss:  0.09723982959985733 , Time: 14452.379171848297 s\n",
      "Batch:  1610 , l1 Loss:  0.09662679359316825 , Time: 14464.214238643646 s\n",
      "Batch:  1620 , l1 Loss:  0.09737391322851181 , Time: 14476.067016839981 s\n",
      "Batch:  1630 , l1 Loss:  0.09686775505542755 , Time: 14487.909301757812 s\n",
      "Batch:  1640 , l1 Loss:  0.09777150973677635 , Time: 14499.783399105072 s\n",
      "Batch:  1650 , l1 Loss:  0.09718134701251983 , Time: 14511.737379074097 s\n",
      "Batch:  1660 , l1 Loss:  0.09693442583084107 , Time: 14523.651478767395 s\n",
      "Batch:  1670 , l1 Loss:  0.09845754727721215 , Time: 14535.545026779175 s\n",
      "Batch:  1680 , l1 Loss:  0.09698126465082169 , Time: 14547.552414894104 s\n",
      "Batch:  1690 , l1 Loss:  0.09723580926656723 , Time: 14559.521762609482 s\n",
      "Batch:  1700 , l1 Loss:  0.09855657517910003 , Time: 14571.480165243149 s\n",
      "Batch:  1710 , l1 Loss:  0.09777260571718216 , Time: 14583.407519578934 s\n",
      "Batch:  1720 , l1 Loss:  0.09809442609548569 , Time: 14595.347401618958 s\n",
      "Batch:  1730 , l1 Loss:  0.09703571572899819 , Time: 14607.244567394257 s\n",
      "Batch:  1740 , l1 Loss:  0.09719063490629196 , Time: 14619.118208646774 s\n",
      "Batch:  1750 , l1 Loss:  0.09877712801098823 , Time: 14631.007327318192 s\n",
      "Batch:  1760 , l1 Loss:  0.09780877754092217 , Time: 14642.900753736496 s\n",
      "Batch:  1770 , l1 Loss:  0.09767075181007386 , Time: 14654.77202796936 s\n",
      "Batch:  1780 , l1 Loss:  0.09707675725221634 , Time: 14666.654772043228 s\n",
      "Batch:  1790 , l1 Loss:  0.09683486819267273 , Time: 14678.554976701736 s\n",
      "Batch:  1800 , l1 Loss:  0.09646088853478432 , Time: 14690.485295057297 s\n",
      "Batch:  1810 , l1 Loss:  0.096783796697855 , Time: 14702.354765415192 s\n",
      "Batch:  1820 , l1 Loss:  0.09759504646062851 , Time: 14714.231174468994 s\n",
      "Batch:  1830 , l1 Loss:  0.09752146825194359 , Time: 14726.107741117477 s\n",
      "Batch:  1840 , l1 Loss:  0.09658036082983017 , Time: 14737.974878549576 s\n",
      "Batch:  1850 , l1 Loss:  0.09722826853394509 , Time: 14749.871832370758 s\n",
      "Batch:  1860 , l1 Loss:  0.09694397523999214 , Time: 14761.756478071213 s\n",
      "Batch:  1870 , l1 Loss:  0.09739468023180961 , Time: 14773.656780481339 s\n",
      "Batch:  1880 , l1 Loss:  0.09649109318852425 , Time: 14785.546958208084 s\n",
      "Batch:  1890 , l1 Loss:  0.09749876335263252 , Time: 14797.461118936539 s\n",
      "Batch:  1900 , l1 Loss:  0.09729297384619713 , Time: 14809.418855905533 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  1910 , l1 Loss:  0.09669868648052216 , Time: 14821.291342020035 s\n",
      "Batch:  1920 , l1 Loss:  0.09828607514500617 , Time: 14833.203172206879 s\n",
      "Batch:  1930 , l1 Loss:  0.0979889489710331 , Time: 14845.055113077164 s\n",
      "Batch:  1940 , l1 Loss:  0.09672467336058617 , Time: 14856.957318782806 s\n",
      "Batch:  1950 , l1 Loss:  0.0968216374516487 , Time: 14868.831486701965 s\n",
      "Batch:  1960 , l1 Loss:  0.09732453525066376 , Time: 14880.747684240341 s\n",
      "Batch:  1970 , l1 Loss:  0.09680458754301072 , Time: 14892.625725507736 s\n",
      "Batch:  1980 , l1 Loss:  0.09801888391375542 , Time: 14904.532778978348 s\n",
      "Batch:  1990 , l1 Loss:  0.09778067097067833 , Time: 14916.413763284683 s\n",
      "Batch:  2000 , l1 Loss:  0.09692433550953865 , Time: 14928.34209227562 s\n",
      "Batch:  2010 , l1 Loss:  0.09695871323347091 , Time: 14940.585692882538 s\n",
      "Batch:  2020 , l1 Loss:  0.09815188571810722 , Time: 14952.805101394653 s\n",
      "Batch:  2030 , l1 Loss:  0.09714054465293884 , Time: 14964.988294839859 s\n",
      "Batch:  2040 , l1 Loss:  0.09653128683567047 , Time: 14976.789849281311 s\n",
      "Batch:  2050 , l1 Loss:  0.09625973254442215 , Time: 14988.600696086884 s\n",
      "Batch:  2060 , l1 Loss:  0.09698544815182686 , Time: 15000.471588373184 s\n",
      "Batch:  2070 , l1 Loss:  0.09699256643652916 , Time: 15012.386903524399 s\n",
      "Batch:  2080 , l1 Loss:  0.09803287833929061 , Time: 15024.312255620956 s\n",
      "Batch:  2090 , l1 Loss:  0.09847587049007415 , Time: 15036.194108009338 s\n",
      "Batch:  2100 , l1 Loss:  0.09627007842063903 , Time: 15048.156309366226 s\n",
      "Batch:  2110 , l1 Loss:  0.0980371281504631 , Time: 15060.04898929596 s\n",
      "Batch:  2120 , l1 Loss:  0.09799903556704521 , Time: 15071.97922039032 s\n",
      "Batch:  2130 , l1 Loss:  0.09659993126988412 , Time: 15083.859185218811 s\n",
      "Batch:  2140 , l1 Loss:  0.09775684997439385 , Time: 15095.753792762756 s\n",
      "Batch:  2150 , l1 Loss:  0.09755134955048561 , Time: 15107.636468410492 s\n",
      "Batch:  2160 , l1 Loss:  0.09709619060158729 , Time: 15119.488152265549 s\n",
      "Batch:  2170 , l1 Loss:  0.09744521230459213 , Time: 15131.374458789825 s\n",
      "Batch:  2180 , l1 Loss:  0.09784225225448609 , Time: 15143.260944843292 s\n",
      "Batch:  2190 , l1 Loss:  0.09746767729520797 , Time: 15155.102155685425 s\n",
      "Batch:  2200 , l1 Loss:  0.09707099869847298 , Time: 15167.055037975311 s\n",
      "Batch:  2210 , l1 Loss:  0.09704535081982613 , Time: 15178.957973003387 s\n",
      "Batch:  2220 , l1 Loss:  0.09688382744789123 , Time: 15190.810628414154 s\n",
      "Batch:  2230 , l1 Loss:  0.09660190865397453 , Time: 15202.647509336472 s\n",
      "Batch:  2240 , l1 Loss:  0.09635223597288131 , Time: 15214.508730173111 s\n",
      "Batch:  2250 , l1 Loss:  0.09670925959944725 , Time: 15226.368409395218 s\n",
      "Batch:  2260 , l1 Loss:  0.09679967984557152 , Time: 15238.23312830925 s\n",
      "Batch:  2270 , l1 Loss:  0.09764547497034073 , Time: 15250.10846209526 s\n",
      "Batch:  2280 , l1 Loss:  0.09656100124120712 , Time: 15262.017853498459 s\n",
      "Batch:  2290 , l1 Loss:  0.09789631068706513 , Time: 15273.8923163414 s\n",
      "Batch:  2300 , l1 Loss:  0.09720249772071839 , Time: 15285.884545564651 s\n",
      "Batch:  2310 , l1 Loss:  0.09695478081703186 , Time: 15297.760385990143 s\n",
      "Batch:  2320 , l1 Loss:  0.09803381264209747 , Time: 15309.616228342056 s\n",
      "Batch:  2330 , l1 Loss:  0.09729580283164978 , Time: 15321.486229658127 s\n",
      "Batch:  2340 , l1 Loss:  0.09713209867477417 , Time: 15333.739452838898 s\n",
      "Batch:  2350 , l1 Loss:  0.09765034690499305 , Time: 15345.984380722046 s\n",
      "Batch:  2360 , l1 Loss:  0.0974097952246666 , Time: 15358.209681034088 s\n",
      "Batch:  2370 , l1 Loss:  0.09790916070342064 , Time: 15370.343321800232 s\n",
      "Batch:  2380 , l1 Loss:  0.09823264330625534 , Time: 15382.426319360733 s\n",
      "Batch:  2390 , l1 Loss:  0.0972770482301712 , Time: 15394.509945869446 s\n",
      "Batch:  2400 , l1 Loss:  0.09764952957630157 , Time: 15406.568196058273 s\n",
      "Batch:  2410 , l1 Loss:  0.09649556130170822 , Time: 15418.55426311493 s\n",
      "Batch:  2420 , l1 Loss:  0.0965627945959568 , Time: 15430.790286064148 s\n",
      "Batch:  2430 , l1 Loss:  0.09731010720133781 , Time: 15442.989183664322 s\n",
      "Batch:  2440 , l1 Loss:  0.09814636185765266 , Time: 15455.16182255745 s\n",
      "Batch:  2450 , l1 Loss:  0.09717224091291428 , Time: 15467.313346385956 s\n",
      "Batch:  2460 , l1 Loss:  0.09684109389781952 , Time: 15479.500521421432 s\n",
      "Batch:  2470 , l1 Loss:  0.09756611213088036 , Time: 15491.637130260468 s\n",
      "Batch:  2480 , l1 Loss:  0.09706635922193527 , Time: 15503.52395772934 s\n",
      "Batch:  2490 , l1 Loss:  0.09743558913469315 , Time: 15515.24860405922 s\n",
      "Batch:  2500 , l1 Loss:  0.09762076959013939 , Time: 15527.088310956955 s\n",
      "Batch:  2510 , l1 Loss:  0.09698996022343635 , Time: 15538.863449811935 s\n",
      "Batch:  2520 , l1 Loss:  0.0969984158873558 , Time: 15550.669396162033 s\n",
      "Batch:  2530 , l1 Loss:  0.0968551941215992 , Time: 15562.479395866394 s\n",
      "Batch:  2540 , l1 Loss:  0.09667810797691345 , Time: 15574.295304775238 s\n",
      "Batch:  2550 , l1 Loss:  0.09741857722401619 , Time: 15586.207558870316 s\n",
      "Batch:  2560 , l1 Loss:  0.097349613904953 , Time: 15598.422989845276 s\n",
      "Batch:  2570 , l1 Loss:  0.09700636863708496 , Time: 15610.592077493668 s\n",
      "Batch:  2580 , l1 Loss:  0.09808510914444923 , Time: 15622.788350105286 s\n",
      "Batch:  2590 , l1 Loss:  0.0969911552965641 , Time: 15635.011528968811 s\n",
      "Batch:  2600 , l1 Loss:  0.09660364165902138 , Time: 15647.213048696518 s\n",
      "Batch:  2610 , l1 Loss:  0.09751809164881706 , Time: 15659.359914302826 s\n",
      "Batch:  2620 , l1 Loss:  0.09730282723903656 , Time: 15671.493817090988 s\n",
      "Batch:  2630 , l1 Loss:  0.09695803821086883 , Time: 15683.60098195076 s\n",
      "Epoch:  4 , l1 loss:  0.09752436921045739\n",
      "Epoch:  5\n",
      "Batch:  10 , l1 Loss:  0.09754114327105609 , Time: 15700.946200847626 s\n",
      "Batch:  20 , l1 Loss:  0.09705566689372062 , Time: 15712.939415216446 s\n",
      "Batch:  30 , l1 Loss:  0.09742646217346192 , Time: 15724.767238855362 s\n",
      "Batch:  40 , l1 Loss:  0.09700682610273362 , Time: 15736.844792604446 s\n",
      "Batch:  50 , l1 Loss:  0.09720430597662925 , Time: 15748.93497300148 s\n",
      "Batch:  60 , l1 Loss:  0.09772012084722519 , Time: 15761.027313232422 s\n",
      "Batch:  70 , l1 Loss:  0.09791687875986099 , Time: 15773.10726904869 s\n",
      "Batch:  80 , l1 Loss:  0.09662207439541817 , Time: 15785.124157190323 s\n",
      "Batch:  90 , l1 Loss:  0.09733749628067016 , Time: 15797.138630867004 s\n",
      "Batch:  100 , l1 Loss:  0.09619168043136597 , Time: 15809.214799880981 s\n",
      "Batch:  110 , l1 Loss:  0.0954429991543293 , Time: 15821.292660713196 s\n",
      "Batch:  120 , l1 Loss:  0.09674468412995338 , Time: 15833.361977815628 s\n",
      "Batch:  130 , l1 Loss:  0.09667629227042199 , Time: 15845.41063952446 s\n",
      "Batch:  140 , l1 Loss:  0.09684796258807182 , Time: 15857.497468233109 s\n",
      "Batch:  150 , l1 Loss:  0.0968160904943943 , Time: 15869.554126501083 s\n",
      "Batch:  160 , l1 Loss:  0.09668095856904983 , Time: 15881.68480873108 s\n",
      "Batch:  170 , l1 Loss:  0.09639732390642167 , Time: 15893.700772762299 s\n",
      "Batch:  180 , l1 Loss:  0.09650287479162216 , Time: 15905.743644475937 s\n",
      "Batch:  190 , l1 Loss:  0.0960377350449562 , Time: 15917.792902708054 s\n",
      "Batch:  200 , l1 Loss:  0.09694162756204605 , Time: 15929.77072429657 s\n",
      "Batch:  210 , l1 Loss:  0.09684029296040535 , Time: 15941.78692150116 s\n",
      "Batch:  220 , l1 Loss:  0.09608606696128845 , Time: 15953.768898963928 s\n",
      "Batch:  230 , l1 Loss:  0.0973891168832779 , Time: 15965.740099191666 s\n",
      "Batch:  240 , l1 Loss:  0.09776100739836693 , Time: 15978.333228349686 s\n",
      "Batch:  250 , l1 Loss:  0.09807297885417939 , Time: 15991.143624544144 s\n",
      "Batch:  260 , l1 Loss:  0.09730513766407967 , Time: 16003.274813175201 s\n",
      "Batch:  270 , l1 Loss:  0.09721753969788552 , Time: 16015.157371044159 s\n",
      "Batch:  280 , l1 Loss:  0.09747455269098282 , Time: 16026.857577323914 s\n",
      "Batch:  290 , l1 Loss:  0.09713635072112084 , Time: 16038.57188487053 s\n",
      "Batch:  300 , l1 Loss:  0.09805173799395561 , Time: 16050.447197675705 s\n",
      "Batch:  310 , l1 Loss:  0.09666646495461464 , Time: 16062.270426034927 s\n",
      "Batch:  320 , l1 Loss:  0.09623293280601501 , Time: 16074.10406947136 s\n",
      "Batch:  330 , l1 Loss:  0.09697040542960167 , Time: 16085.890721082687 s\n",
      "Batch:  340 , l1 Loss:  0.09628818556666374 , Time: 16097.720493078232 s\n",
      "Batch:  350 , l1 Loss:  0.0978511780500412 , Time: 16109.583538532257 s\n",
      "Batch:  360 , l1 Loss:  0.09689781963825225 , Time: 16121.559308290482 s\n",
      "Batch:  370 , l1 Loss:  0.09710634425282479 , Time: 16133.400833129883 s\n",
      "Batch:  380 , l1 Loss:  0.09690817147493362 , Time: 16145.249346017838 s\n",
      "Batch:  390 , l1 Loss:  0.09680442586541176 , Time: 16157.139197349548 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  400 , l1 Loss:  0.09726045280694962 , Time: 16168.936507701874 s\n",
      "Batch:  410 , l1 Loss:  0.09758597984910011 , Time: 16180.813372135162 s\n",
      "Batch:  420 , l1 Loss:  0.0976669579744339 , Time: 16192.72688984871 s\n",
      "Batch:  430 , l1 Loss:  0.09675105884671212 , Time: 16204.674311637878 s\n",
      "Batch:  440 , l1 Loss:  0.09660834968090057 , Time: 16216.549914360046 s\n",
      "Batch:  450 , l1 Loss:  0.09608095288276672 , Time: 16228.439908027649 s\n",
      "Batch:  460 , l1 Loss:  0.09758634939789772 , Time: 16240.46865606308 s\n",
      "Batch:  470 , l1 Loss:  0.09664669707417488 , Time: 16252.347853422165 s\n",
      "Batch:  480 , l1 Loss:  0.09641780480742454 , Time: 16264.212922096252 s\n",
      "Batch:  490 , l1 Loss:  0.09723957255482674 , Time: 16276.081236362457 s\n",
      "Batch:  500 , l1 Loss:  0.09670391827821731 , Time: 16288.035796165466 s\n",
      "Batch:  510 , l1 Loss:  0.09788425788283348 , Time: 16300.1062874794 s\n",
      "Batch:  520 , l1 Loss:  0.0968261905014515 , Time: 16312.050725460052 s\n",
      "Batch:  530 , l1 Loss:  0.09667059630155564 , Time: 16324.000107765198 s\n",
      "Batch:  540 , l1 Loss:  0.09680362567305564 , Time: 16335.914719104767 s\n",
      "Batch:  550 , l1 Loss:  0.09648397415876389 , Time: 16347.790281295776 s\n",
      "Batch:  560 , l1 Loss:  0.09595516324043274 , Time: 16360.060063838959 s\n",
      "Batch:  570 , l1 Loss:  0.09715311527252198 , Time: 16372.296476602554 s\n",
      "Batch:  580 , l1 Loss:  0.09728443995118141 , Time: 16384.402784347534 s\n",
      "Batch:  590 , l1 Loss:  0.09701074436306953 , Time: 16396.667358875275 s\n",
      "Batch:  600 , l1 Loss:  0.0968098796904087 , Time: 16408.858533859253 s\n",
      "Batch:  610 , l1 Loss:  0.09850238859653473 , Time: 16420.927229642868 s\n",
      "Batch:  620 , l1 Loss:  0.09729237332940102 , Time: 16433.01963210106 s\n",
      "Batch:  630 , l1 Loss:  0.09694946184754372 , Time: 16445.08575820923 s\n",
      "Batch:  640 , l1 Loss:  0.0972325436770916 , Time: 16457.15069246292 s\n",
      "Batch:  650 , l1 Loss:  0.09585326984524727 , Time: 16469.250143289566 s\n",
      "Batch:  660 , l1 Loss:  0.09686058908700942 , Time: 16481.406024217606 s\n",
      "Batch:  670 , l1 Loss:  0.09710847213864326 , Time: 16493.619374275208 s\n",
      "Batch:  680 , l1 Loss:  0.09675724282860756 , Time: 16505.668070793152 s\n",
      "Batch:  690 , l1 Loss:  0.09757066518068314 , Time: 16517.758458137512 s\n",
      "Batch:  700 , l1 Loss:  0.09648684114217758 , Time: 16529.845691919327 s\n",
      "Batch:  710 , l1 Loss:  0.09616192653775216 , Time: 16542.01403951645 s\n",
      "Batch:  720 , l1 Loss:  0.09751812890172004 , Time: 16554.047156333923 s\n",
      "Batch:  730 , l1 Loss:  0.09683913290500641 , Time: 16566.103098869324 s\n",
      "Batch:  740 , l1 Loss:  0.09649232253432274 , Time: 16578.162386655807 s\n",
      "Batch:  750 , l1 Loss:  0.09692273736000061 , Time: 16590.273128032684 s\n",
      "Batch:  760 , l1 Loss:  0.09742843359708786 , Time: 16602.385555028915 s\n",
      "Batch:  770 , l1 Loss:  0.09621793180704116 , Time: 16614.47451376915 s\n",
      "Batch:  780 , l1 Loss:  0.09742027372121811 , Time: 16626.620956897736 s\n",
      "Batch:  790 , l1 Loss:  0.09700833708047867 , Time: 16638.79542517662 s\n",
      "Batch:  800 , l1 Loss:  0.09845835119485855 , Time: 16650.88365793228 s\n",
      "Batch:  810 , l1 Loss:  0.09732186123728752 , Time: 16663.000689983368 s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-1bf67f6e20d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_l1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mloss_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_l1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "#test sub module\n",
    "\n",
    "import time\n",
    "\n",
    "vox_size = 32\n",
    "latent_dim = 256\n",
    "con_dim = 32\n",
    "\n",
    "batch_len = len(train_sdf_dataloader)\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(start_epoch, num_epoch):\n",
    "    \n",
    "    loss_list = []\n",
    "    loss_batch = []\n",
    "    \n",
    "    print(\"Epoch: \", epoch)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for i, data in enumerate(train_sdf_dataloader):\n",
    "        \n",
    "        ####################\n",
    "        # Data preparation #\n",
    "        ####################\n",
    "        \n",
    "        # b x 1 x 256 x 256\n",
    "        depth_img = data['depth_img'].to(device)\n",
    "        # b x 128 x 1 x 1\n",
    "        z = discrete_encoder(depth_img)\n",
    "        # b x n x 3\n",
    "        # DO NOT scale by np.sqrt(3)\n",
    "        sample_pt = data['sample_pt']\n",
    "        # b x n x 1\n",
    "        sample_sdf = data['sample_sdf']\n",
    "        \n",
    "        # b x 16 x 64 x 64 x 64\n",
    "        target_vox = data['target_vox'].to(device)\n",
    "        vox_feature = unet(target_vox, z)\n",
    "        #vox_feature = unet(torch.sigmoid(discrete_decoder(mapping(z))))\n",
    "        \n",
    "        ####################\n",
    "        # indexing context #\n",
    "        ####################\n",
    "        \n",
    "        # stay with cpu for v-ram efficiency\n",
    "        sample_pt_normalized = sample_pt + torch.tensor([0.5, 0.5, 0.5])\n",
    "        # (0, vox_size-1)\n",
    "        sample_pt_scale = torch.clamp(sample_pt_normalized* (vox_size-1), 0, (vox_size-1)-1e-5)\n",
    "        # (0, vox_size-2)\n",
    "        sample_pt_query = torch.clamp((sample_pt_scale).int(), 0, (vox_size-2))\n",
    "        sample_pt_distance = sample_pt_scale - sample_pt_query\n",
    "        \n",
    "        context = getContext(sample_pt_query, vox_feature)\n",
    "        \n",
    "        dx = sample_pt_distance[:, :, 0].unsqueeze(1)\n",
    "        dy = sample_pt_distance[:, :, 1].unsqueeze(1)\n",
    "        dz = sample_pt_distance[:, :, 2].unsqueeze(1)\n",
    "        # local feature\n",
    "        con = trilinearInterpolation(context, dx, dy, dz)\n",
    "        \n",
    "        ################################\n",
    "        # Reshape input & forward pass #\n",
    "        ################################\n",
    "        \n",
    "        sample_pt = sample_pt.transpose(-1, -2).to(device)\n",
    "        con = con.to(device)\n",
    "        z = z.squeeze(-1).squeeze(-1).repeat(1, 1, sample_size)\n",
    "        sample_sdf = sample_sdf.transpose(-1, -2).to(device)\n",
    "        \n",
    "        \n",
    "        sample_pt = sample_pt.transpose(-1, -2).reshape(-1, 3)\n",
    "        con = con.transpose(-1, -2).reshape(-1, con_dim)\n",
    "        z = z.transpose(-1, -2).reshape(-1, latent_dim)\n",
    "        sample_sdf = sample_sdf.transpose(-1, -2).reshape(-1, 1)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred_sdf = model(sample_pt, con, z)\n",
    "        \n",
    "        loss_l1 = l1loss(pred_sdf, sample_sdf)\n",
    "        \n",
    "        loss = loss_l1\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        loss_list.append(loss_l1.item())\n",
    "        loss_batch.append(loss_l1.item())\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        #scheduler.step()\n",
    "        \n",
    "        if count != 0 and count % 10 == 0:\n",
    "            loss_batch_avg = np.average(loss_batch)\n",
    "            \n",
    "            print(\"Batch: \", count, \", l1 Loss: \", loss_batch_avg, \", Time: %s s\" % (time.time() - start_time))\n",
    "            \n",
    "            if count % 500 == 0:\n",
    "                torch.save(model.state_dict(), continuous_model_path)\n",
    "                \n",
    "            loss_batch.clear()\n",
    "            \n",
    "        count += 1\n",
    "        \n",
    "    print(\"Epoch: \", epoch, ', l1 loss: ', np.average(loss_list))\n",
    "    \n",
    "    loss_list.clear()\n",
    "    \n",
    "    torch.save(model.state_dict(), continuous_model_path)\n",
    "    \n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'continuous_state_dict': model.state_dict(),\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    })\n",
    "    \n",
    "print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
